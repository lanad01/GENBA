{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key, temperature=0.0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ {ability} ì— ëŠ¥ìˆ™í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 20ì ì´ë‚´ë¡œ ì‘ë‹µí•˜ì„¸ìš”\",\n",
    "        ),\n",
    "        # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, history ê°€ MessageHistory ì˜ key ê°€ ë¨\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # ì‚¬ìš©ì ì…ë ¥ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model  # í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ runnable ê°ì²´ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import traceback\n",
    "import streamlit as st\n",
    "from typing import Dict, Any, Optional, Union\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "# ì‚¬ìš©ì íŒ¨í‚¤ì§€\n",
    "from utils.vector_handler import save_chat_to_vector_db, search_similar_questions\n",
    "from utils.thread_handler import rename_thread, save_thread\n",
    "from common_txt import logo\n",
    "\n",
    "# âœ… MongoDB Atlas ì—°ê²° ì„¤ì •\n",
    "uri = \"mongodb+srv://swkwon:1q2w3e$r@cluster0.3rvbn.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client[\"chat_history\"]\n",
    "collection = db[\"conversations\"]\n",
    "\n",
    "# âœ… ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (thread_idë³„ë¡œ ê´€ë¦¬)\n",
    "memory_store = {}\n",
    "\n",
    "def get_memory(thread_id: str) -> ConversationBufferMemory:\n",
    "    \"\"\"\n",
    "    íŠ¹ì • thread_idì— ëŒ€í•œ ConversationBufferMemoryë¥¼ ë°˜í™˜.\n",
    "    ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±.\n",
    "    \"\"\"\n",
    "    if thread_id not in memory_store:\n",
    "        memory_store[thread_id] = ConversationBufferMemory(memory_key=f\"history_{thread_id}\", return_messages=True)\n",
    "    \n",
    "        # âœ… MongoDBì—ì„œ ì´ì „ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        existing_messages = collection.find({\"internal_id\": thread_id}).sort(\"timestamp\", 1)  # ì‹œê°„ìˆœ ì •ë ¬\n",
    "        if existing_messages:\n",
    "            for document in existing_messages:\n",
    "                for msg in document.get(\"messages\", []):\n",
    "                    if msg[\"role\"] == \"user\":\n",
    "                        memory_store[thread_id].chat_memory.add_user_message(msg[\"content\"])\n",
    "                    elif msg[\"role\"] == \"assistant\":\n",
    "                        memory_store[thread_id].chat_memory.add_ai_message(msg[\"content\"])\n",
    "\n",
    "    return memory_store[thread_id]\n",
    "\n",
    "# âœ… ì±„íŒ… ì‘ë‹µ ì²˜ë¦¬\n",
    "def handle_chat_response(assistant: Any,query: str,internal_id: str) -> tuple[Optional[Dict[str, Any]], ConversationBufferMemory]:\n",
    "    # print(\"=\"*100)\n",
    "    # print(logo)\n",
    "    # print(\"=\"*100)\n",
    "    print(f\"ğŸ¤µ ì§ˆë¬¸ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"\"\"ğŸ¤µ ìƒˆë¡œìš´ ì§ˆë¬¸ : \"{query}\"ì— ëŒ€í•œ  Context Window ì²˜ë¦¬ ì‹œì‘\"\"\")\n",
    "\n",
    "    # âœ… thread_idë³„ memory ê°€ì ¸ì˜¤ê¸°\n",
    "    memory = get_memory(internal_id)\n",
    "\n",
    "    # âœ… ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "    messages = memory.load_memory_variables({}).get(f\"history_{internal_id}\", \"\")\n",
    "\n",
    "    # ë©”ì‹œì§€ ê°ì²´ë¥¼ ì½ê¸° ì‰¬ìš´ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    previous_context = \"\"\n",
    "    if messages:\n",
    "        for msg in messages:\n",
    "            if msg.type == 'human':\n",
    "                previous_context += f\"ì‚¬ìš©ì: {msg.content}\\n\"\n",
    "            elif msg.type == 'ai':\n",
    "                previous_context += f\"ì–´ì‹œìŠ¤í„´íŠ¸: {msg.content}\\n\"\n",
    "\n",
    "    ##########################################################################################\n",
    "    # âœ… Context Window ì²˜ë¦¬\n",
    "    # ** í•´ë‹¹ ì“°ë ˆë“œì˜ ì§ˆë¬¸-ë‹µë³€ ì´ë ¥ì´ ìŒ“ì—¬ìˆëŠ” ë²¡í„°DBì—ì„œ ì‚¬ìš©ìì˜ í˜„ì¬ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì§ˆë¬¸ ê²€ìƒ‰\n",
    "    ##########################################################################################\n",
    "    model = assistant.llm\n",
    "    filtered_results = search_similar_questions(internal_id, query)\n",
    "    if not filtered_results:\n",
    "        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ìš”ì•½ ê³¼ì • ê±´ë„ˆë›°ê¸°\n",
    "        summarized_result = \"\"\n",
    "    else:\n",
    "        document_texts = \"\\n\\n\".join([\n",
    "            f\"[ìœ ì‚¬ë„: {score:.2f}]\\n{doc.page_content}\" \n",
    "            for doc, score in filtered_results\n",
    "        ])\n",
    "\n",
    "        # LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½ (ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ìˆì„ ë•Œë§Œ ì‹¤í–‰)\n",
    "        prompt = f\"\"\"\n",
    "ë‹¤ìŒì€ ì´ì „ ëŒ€í™” ë‚´ì—­ì—ì„œ í˜„ì¬ ì§ˆë¬¸ \"{query}\"ì™€ ê´€ë ¨ì„±ì´ ë†’ì€ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤.\n",
    "ì´ë¥¼ ì°¸ê³ í•˜ì—¬ í˜„ì¬ ì§ˆë¬¸ê³¼ ì§ì ‘ ì—°ê²°ë˜ëŠ” í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ì„¸ìš”.\n",
    "\n",
    "1. ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” ì •ë³´ë§Œ ë‚¨ê¸°ê³  ë¶ˆí•„ìš”í•œ ë‚´ìš©ì€ ì œê±°\n",
    "2. ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì½”ë“œê°€ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "3. ë¶„ì„ ê²°ê³¼ë‚˜ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ëŠ” ì •ë¦¬í•´ì„œ í¬í•¨\n",
    "4. ì •ë³´ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”:\n",
    "    - í•µì‹¬ ì—°ê´€ ë‚´ìš©\n",
    "    - ê´€ë ¨ ì½”ë“œ\n",
    "    - ì£¼ìš” ì¸ì‚¬ì´íŠ¸(3ì¤„ ì´ë‚´)\n",
    "\n",
    "{document_texts}\n",
    "        \"\"\"\n",
    "        summarized_result = model.invoke(prompt).content.strip()\n",
    "\n",
    "    print(f\"ğŸ¤µ ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½:\\n{summarized_result}\")\n",
    "    \n",
    "    ##########################################################################################\n",
    "    # âœ… Query Rewriting\n",
    "    #  \"\"\" ê¸°ì¡´ ë¬¸ë§¥ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°˜ì˜í•˜ì—¬ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒì„± \"\"\"\n",
    "    ##########################################################################################\n",
    "    # ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ì—†ê³  ê²€ìƒ‰ëœ ë¬¸ì„œë„ ì—†ìœ¼ë©´ ì›ë³¸ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "    if not previous_context or not summarized_result:\n",
    "        final_query = query  \n",
    "    # ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ìˆê³  ê²€ìƒ‰ëœ ë¬¸ì„œë„ ìˆìœ¼ë©´ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°˜ì˜í•˜ì—¬ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒì„±\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ LLMì˜ ë‹µë³€ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ Context Windowë¥¼ ì œê³µí•´ì£¼ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "'ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½'ì€ ì‚¬ìš©ìì˜ ì´ì „ ëŒ€í™” ê¸°ë¡ ì¤‘, ì‚¬ìš©ìì˜ ì›ë˜ ì§ˆë¬¸ê³¼ì˜ ì—°ê´€ì„±ì´ ë†’ì€ ì§ˆë¬¸ë“¤ì„ ìš”ì•½í•œ ê²ƒì…ë‹ˆë‹¤.\n",
    "'ì‚¬ìš©ìì˜ í˜„ì¬ ì§ˆë¬¸'ê³¼ 'ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½'ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ í˜„ì¬ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•œ ë’¤ ì°¸ê³  ì‚¬í•­ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "ë‹¨, 'ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½'ì— ì½”ë“œê°€ ìˆì„ ê²½ìš° ë°˜ë“œì‹œ ì°¸ê³  ì‚¬í•­ì— ë„£ì–´ì£¼ì„¸ìš”.\n",
    "\n",
    "[ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½]\n",
    "{summarized_result}\n",
    "\n",
    "[ì‚¬ìš©ìì˜ í˜„ì¬ ì§ˆë¬¸]\n",
    "{query}\n",
    "\n",
    "[ì¬êµ¬ì„±ëœ ì§ˆë¬¸ ë° ì°¸ê³  ì‚¬í•­]\n",
    "        \"\"\"\n",
    "        final_query = model.invoke(prompt).content.strip()\n",
    "\n",
    "    print(f\"ğŸ¤µ ì¬êµ¬ì„±ëœ ì§ˆë¬¸:\\n{final_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "# âœ… MongoDB ì—°ê²° ì„¤ì •\n",
    "uri = \"mongodb+srv://swkwon:1q2w3e$r@cluster0.3rvbn.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "client = MongoClient(uri)\n",
    "db = client[\"chat_history\"]\n",
    "collection = db[\"conversations\"]\n",
    "\n",
    "def get_memory(thread_id: str) -> ConversationBufferMemory:\n",
    "    \"\"\"\n",
    "    íŠ¹ì • thread_idì— ëŒ€í•œ ConversationBufferMemoryë¥¼ ë°˜í™˜.\n",
    "    ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±.\n",
    "    \"\"\"\n",
    "    # âœ… íŠ¹ì • thread_idì˜ ëŒ€í™” ì´ë ¥ ê°€ì ¸ì˜¤ê¸°\n",
    "    existing_messages = collection.find({\"internal_id\": thread_id}).sort(\"timestamp\", -1).limit(5)  \n",
    "\n",
    "    # âœ… ë°ì´í„° ë³€í™˜\n",
    "    chat_history = []\n",
    "\n",
    "    if existing_messages:\n",
    "        for document in existing_messages:\n",
    "            messages = document.get(\"messages\", [])\n",
    "            \n",
    "            for i in range(len(messages) - 1):\n",
    "                user_msg = messages[i]\n",
    "                assistant_msg = messages[i + 1]\n",
    "\n",
    "                # âœ… ì‚¬ìš©ì ì§ˆë¬¸ê³¼ AI ë‹µë³€ì„ ë§¤ì¹­\n",
    "                if user_msg.get(\"role\") == \"user\" and assistant_msg.get(\"role\") == \"assistant\":\n",
    "                    # ê¸°ë³¸ ì‘ë‹µ êµ¬ì¡° ìƒì„±\n",
    "                    response_dict = {\n",
    "                        \"content\": assistant_msg.get(\"content\", \"\")\n",
    "                    }\n",
    "                    \n",
    "                    # validated_codeê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€\n",
    "                    if assistant_msg.get(\"validated_code\"):\n",
    "                        response_dict[\"code\"] = assistant_msg[\"validated_code\"]\n",
    "                        response_dict[\"insights\"] = assistant_msg.get(\"insights\", \"ì¸ì‚¬ì´íŠ¸ ì—†ìŒ\")\n",
    "                    \n",
    "                    chat_history.append({\n",
    "                        \"query\": user_msg.get(\"content\", \"\"),\n",
    "                        \"response\": response_dict\n",
    "                    })\n",
    "    return chat_history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "íŠ¹ì • ì—°ë ¹ëŒ€(ì˜ˆ: 20~30ëŒ€)ì˜ ì£¼ìš” ê¸ˆìœµ íŒ¨í„´ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”. \n",
      "../img/chart_20250227140558.png \n",
      "```python\n",
      "# íŠ¹ì • ì—°ë ¹ëŒ€(20~30ëŒ€) ë°ì´í„° í•„í„°ë§\n",
      "age_filtered_df = df[df['ë‚˜ì´'].isin(['20ëŒ€', '30ëŒ€'])]\n",
      "\n",
      "# ì£¼ìš” ê¸ˆìœµ íŒ¨í„´ ë¶„ì„\n",
      "# 1. í‰ê·  CBì‹ ìš©í‰ì \n",
      "avg_credit_score = age_filtered_df['CBì‹ ìš©í‰ì '].mean()\n",
      "\n",
      "# 2. ì„±ë³„ì— ë”°ë¥¸ ìˆ˜ìµì ì—¬ë¶€ ë¹„ìœ¨\n",
      "beneficiary_by_gender = age_filtered_df.groupby('ì„±ë³„')['ìˆ˜ìµìì—¬ë¶€'].mean().round(2)\n",
      "\n",
      "# 3. ìš´ì „ì½”ë“œëª…ì— ë”°ë¥¸ ë³€ì•¡ê¸°ë‚©ì…ë³´í—˜ë£Œ í‰ê· \n",
      "avg_insurance_by_drive = age_filtered_df.groupby('ìš´ì „ì½”ë“œëª…')['ë³€ì•¡ê¸°ë‚©ì…ë³´í—˜ë£Œ'].mean().round(2)\n",
      "\n",
      "# 4. ë³€ì•¡ì¢…ì‹ ë³´ìœ ì—¬ë¶€ì— ë”°ë¥¸ CBì‹ ìš©ë“±ê¸‰ í‰ê· \n",
      "avg_credit_grade_by_life_insurance = age_filtered_df.groupby('ë³€ì•¡ì¢…ì‹ ë³´ìœ ì—¬ë¶€')['CBì‹ ìš©ë“±ê¸‰'].mean().round(2)\n",
      "\n",
      "# 5. ë‘ë‚«ì½œì—¬ë¶€ì— ë”°ë¥¸ ë³€ì•¡ì¢…ì‹ ê¸°ë‚©ì…ë³´í—˜ë£Œ í‰ê· \n",
      "avg_life_insurance_by_donotcall = age_filtered_df.groupby('ë‘ë‚«ì½œì—¬ë¶€')['ë³€ì•¡ì¢…ì‹ ê¸°ë‚©ì…ë³´í—˜ë£Œ'].mean().round(2)\n",
      "\n",
      "# ê²°ê³¼ ì €ì¥\n",
      "analytic_results = {\n",
      "    'avg_credit_score': round(avg_credit_score, 2),\n",
      "    'beneficiary_by_gender': beneficiary_by_gender.head().to_dict(),\n",
      "    'avg_insurance_by_drive': avg_insurance_by_drive.head().to_dict(),\n",
      "    'avg_credit_grade_by_life_insurance': avg_credit_grade_by_life_insurance.head().to_dict(),\n",
      "    'avg_life_insurance_by_donotcall': avg_life_insurance_by_donotcall.head().to_dict()\n",
      "}\n",
      "\n",
      "print(analytic_results)\n",
      "``` \n",
      "1. ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
      "- 20~30ëŒ€ì˜ í‰ê·  ì‹ ìš© ì ìˆ˜ëŠ” 321.93ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŠ” í•´ë‹¹ ì—°ë ¹ëŒ€ì˜ ê¸ˆìœµ ì‹ ë¢°ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¤‘ìš”í•œ ì§€í‘œì…ë‹ˆë‹¤.\n",
      "- ë³´í—˜ ìˆ˜í˜œì ë¹„ìœ¨ì€ ë‚¨ì„±ê³¼ ì—¬ì„± ëª¨ë‘ 0.88ë¡œ ë™ì¼í•˜ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŠ” ì„±ë³„ì— ë”°ë¥¸ ë³´í—˜ ìˆ˜í˜œì ë¹„ìœ¨ì´ ê· ë“±í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.\n",
      "- ì°¨ëŸ‰ ìœ í˜•ë³„ í‰ê·  ë³´í—˜ë£Œë¥¼ ì‚´í´ë³´ë©´, ë†ê¸°ê³„ê°€ ê°€ì¥ ë†’ì€ í‰ê·  ë³´í—˜ë£Œ(45,512.7)ë¥¼ ê¸°ë¡í•˜ê³  ìˆìœ¼ë©°, ê·¸ ë‹¤ìŒìœ¼ë¡œ ìŠ¹í•©ì°¨(ìê°€ìš©)ì™€ ìŠ¹ìš©ì°¨(ì˜ì—…ìš©)ê°€ ë’¤ë¥¼ ì‡ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "- ìƒëª… ë³´í—˜ ê°€ì… ì—¬ë¶€ì— ë”°ë¥¸ í‰ê·  ì‹ ìš© ë“±ê¸‰ì€ ìƒëª… ë³´í—˜ì— ê°€ì…í•˜ì§€ ì•Šì€ ê²½ìš°(0)ê°€ 4.42, ê°€ì…í•œ ê²½ìš°(1)ê°€ 11.29ë¡œ, ìƒëª… ë³´í—˜ ê°€ì…ì´ ì‹ ìš© ë“±ê¸‰ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "- 'ìˆ˜ì‹ ê±°ë¶€' ì—¬ë¶€ì— ë”°ë¥¸ í‰ê·  ìƒëª… ë³´í—˜ ê¸ˆì•¡ì€ ìˆ˜ì‹ ê±°ë¶€ë¥¼ í•˜ì§€ ì•Šì€ ê²½ìš°(0.0)ê°€ 3,156,412.81, ìˆ˜ì‹ ê±°ë¶€ë¥¼ í•œ ê²½ìš°(1.0)ê°€ 3,111,849.88ë¡œ, ìˆ˜ì‹ ê±°ë¶€ ì—¬ë¶€ê°€ ìƒëª… ë³´í—˜ ê¸ˆì•¡ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. íŠ¹ì´ì \n",
      "- ë†ê¸°ê³„ì˜ í‰ê·  ë³´í—˜ë£Œê°€ ë‹¤ë¥¸ ì°¨ëŸ‰ ìœ í˜•ì— ë¹„í•´ ìƒë‹¹íˆ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŠ” ë†ê¸°ê³„ì˜ íŠ¹ì„±ìƒ ë³´í—˜ë£Œê°€ ë†’ê²Œ ì±…ì •ë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.\n",
      "- ìƒëª… ë³´í—˜ ê°€ì… ì—¬ë¶€ì— ë”°ë¥¸ ì‹ ìš© ë“±ê¸‰ ì°¨ì´ê°€ ìƒë‹¹íˆ í½ë‹ˆë‹¤. ì´ëŠ” ìƒëª… ë³´í—˜ ê°€ì…ì´ ì‹ ìš© ë“±ê¸‰ í–¥ìƒì— ê¸°ì—¬í•  ìˆ˜ ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "3. ì¶”ì²œ ì‚¬í•­\n",
      "- ë³´í—˜ ìƒí’ˆ ì„¤ê³„ ì‹œ, 20~30ëŒ€ì˜ í‰ê·  ì‹ ìš© ì ìˆ˜ë¥¼ ê³ ë ¤í•˜ì—¬ ë§ì¶¤í˜• ìƒí’ˆì„ ê°œë°œí•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì‹ ìš© ì ìˆ˜ê°€ ë‚®ì€ ê³ ê°ì„ ìœ„í•œ ìœ ì¸ì±…ì„ ë§ˆë ¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "- ì„±ë³„ì— ë”°ë¥¸ ë³´í—˜ ìˆ˜í˜œì ë¹„ìœ¨ì´ ê· ë“±í•˜ë¯€ë¡œ, ì„±ë³„ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ì¤‘ë¦½ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•©ë‹ˆë‹¤.\n",
      "- ë†ê¸°ê³„ ë³´í—˜ë£Œê°€ ë†’ì€ ì ì„ ê³ ë ¤í•˜ì—¬, ë†ê¸°ê³„ ì†Œìœ ìë¥¼ ìœ„í•œ íŠ¹ë³„ í• ì¸ì´ë‚˜ í˜œíƒì„ ì œê³µí•˜ëŠ” ë°©ì•ˆì„ ê²€í† í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- ìƒëª… ë³´í—˜ ê°€ì…ì´ ì‹ ìš© ë“±ê¸‰ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì ì„ í™œìš©í•˜ì—¬, ìƒëª… ë³´í—˜ ê°€ì…ì„ ìœ ë„í•˜ëŠ” ìº í˜ì¸ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- ìˆ˜ì‹ ê±°ë¶€ ì—¬ë¶€ê°€ ìƒëª… ë³´í—˜ ê¸ˆì•¡ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ìˆ˜ì‹ ê±°ë¶€ ê³ ê°ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì¶”ê°€ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•  í•„ìš”ëŠ” ë‚®ì•„ ë³´ì…ë‹ˆë‹¤. \n",
      "1. ìš”ì•½\n",
      "20~30ëŒ€ ê¸ˆìœµ íŒ¨í„´ ë¶„ì„: ì‹ ìš© ì ìˆ˜, ë³´í—˜ ìˆ˜í˜œ, ë³´í—˜ë£Œ ë“±.\n",
      "\n",
      "2. ë¶„ì„ ë°©ë²•\n",
      "ë°ì´í„° ë¶„ì„ì„ í†µí•´ ì—°ë ¹ëŒ€ë³„ ê¸ˆìœµ íŒ¨í„´ ë° ë³´í—˜ ê´€ë ¨ ì§€í‘œ ë„ì¶œ.\n",
      "\n",
      "3. ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
      "í‰ê·  ì‹ ìš© ì ìˆ˜ 321.93, ì„±ë³„ ë³´í—˜ ìˆ˜í˜œ ê· ë“±, ë†ê¸°ê³„ ë³´í—˜ë£Œ ë†’ìŒ.\n",
      "\n",
      "4. ê²°ë¡  ë° ì œì–¸\n",
      "ë§ì¶¤í˜• ë³´í—˜ ìƒí’ˆ ê°œë°œ, ì¤‘ë¦½ì  ë§ˆì¼€íŒ…, ë†ê¸°ê³„ í• ì¸ ê²€í† . \n",
      "None \n",
      "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. \n"
     ]
    }
   ],
   "source": [
    "thread_id = 'temp_KSW_20250227_1403'\n",
    "existing_messages = collection.find({\"internal_id\": 'temp_KSW_20250227_1403'}).sort(\"timestamp\", -1).limit(5)  \n",
    "# ìµœê·¼ 5ê°œë§Œ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "if existing_messages:\n",
    "    for document in existing_messages:\n",
    "        for msg in document.get(\"messages\", []):\n",
    "            print(msg.get('chart_filename'), '')\n",
    "            print(msg.get('validated_code'), '')\n",
    "            print(msg.get('insights'), '')\n",
    "            print(msg.get('report'), '')\n",
    "            print(msg.get('analytic_result'), '')\n",
    "            print(msg.get('content'), '')\n",
    "# memory_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ í˜„ì¬ ì ‘ê·¼ ê°€ëŠ¥ ë§ˆíŠ¸ ëª©ë¡: ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "âœ… ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ\n",
      "ğŸ¤µ ì§ˆë¬¸ì‹œê°: 2025-02-27 14:32:00\n",
      "ğŸ¤µ ìƒˆë¡œìš´ ì§ˆë¬¸ : \"df_top_products ëŠ” ë¬´ì—‡ì¸ì§€ ë‹¤ì‹œ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"ì— ëŒ€í•œ  Context Window ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ¤µ ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½:\n",
      "- **í•µì‹¬ ì—°ê´€ ë‚´ìš©**: df_top_productsì— ëŒ€í•œ ì§ì ‘ì ì¸ ì„¤ëª…ì€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, íŠ¹ì • ì—°ë ¹ëŒ€ì˜ ê¸ˆìœµ íŒ¨í„´ ë¶„ì„ê³¼ ê´€ë ¨ëœ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ ë°©ë²•ì´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” df_top_productsê°€ íŠ¹ì • ì—°ë ¹ëŒ€ì˜ ì£¼ìš” ê¸ˆìœµ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ëœ ë°ì´í„°í”„ë ˆì„ì¼ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "- **ê´€ë ¨ ì½”ë“œ**:\n",
      "  ```python\n",
      "  # íŠ¹ì • ì—°ë ¹ëŒ€(20~30ëŒ€) ë°ì´í„° í•„í„°ë§\n",
      "  age_filtered_df = df[df['ë‚˜ì´'].isin(['20ëŒ€', '30ëŒ€'])]\n",
      "\n",
      "  # ì£¼ìš” ê¸ˆìœµ íŒ¨í„´ ë¶„ì„\n",
      "  # 1. í‰ê·  CBì‹ ìš©í‰ì \n",
      "  avg_credit_score = age_filtered_df['CBì‹ ìš©í‰ì '].mean()\n",
      "\n",
      "  # 2. ì„±ë³„ì— ë”°ë¥¸ ìˆ˜ìµì ì—¬ë¶€ ë¹„ìœ¨\n",
      "  beneficiary_by_gender = age_filtered_df.groupby('ì„±ë³„')['ìˆ˜ìµìì—¬ë¶€'].mean().round(2)\n",
      "\n",
      "  # 3. ìš´ì „ì½”ë“œëª…ì— ë”°ë¥¸ ë³€ì•¡ê¸°ë‚©ì…ë³´í—˜ë£Œ í‰ê· \n",
      "  avg_insurance_by_drive = age_filtered_df.groupby('ìš´ì „ì½”ë“œëª…')['ë³€ì•¡ê¸°ë‚©ì…ë³´í—˜ë£Œ'].mean().round(2)\n",
      "\n",
      "  # 4. ë³€ì•¡ì¢…ì‹ ë³´ìœ ì—¬ë¶€ì— ë”°ë¥¸ CBì‹ ìš©ë“±ê¸‰ í‰ê· \n",
      "  avg_credit_grade_by_life_insurance = age_filtered_df.groupby('ë³€ì•¡ì¢…ì‹ ë³´ìœ ì—¬ë¶€')['CBì‹ ìš©ë“±ê¸‰'].mean().round(2)\n",
      "\n",
      "  # 5. ë‘ë‚«ì½œì—¬ë¶€ì— ë”°ë¥¸ ë³€ì•¡ì¢…ì‹ ê¸°ë‚©ì…ë³´í—˜ë£Œ í‰ê· \n",
      "  avg_life_insurance_by_donotcall = age_filtered_df.groupby('ë‘ë‚«ì½œì—¬ë¶€')['ë³€ì•¡ì¢…ì‹ ê¸°ë‚©ì…ë³´í—˜ë£Œ'].mean().round(2)\n",
      "\n",
      "  # ê²°ê³¼ ì €ì¥\n",
      "  analytic_results = {\n",
      "      'avg_credit_score': round(avg_credit_score, 2),\n",
      "      'beneficiary_by_gender': beneficiary_by_gender.head().to_dict(),\n",
      "      'avg_insurance_by_drive': avg_insurance_by_drive.head().to_dict(),\n",
      "      'avg_credit_grade_by_life_insurance': avg_credit_grade_by_life_insurance.head().to_dict(),\n",
      "      'avg_life_insurance_by_donotcall': avg_life_insurance_by_donotcall.head().to_dict()\n",
      "  }\n",
      "\n",
      "  print(analytic_results)\n",
      "  ```\n",
      "\n",
      "- **ì£¼ìš” ì¸ì‚¬ì´íŠ¸**: \n",
      "  1. 20~30ëŒ€ì˜ í‰ê·  ì‹ ìš© ì ìˆ˜ëŠ” 321.93ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "  2. ì„±ë³„ì— ë”°ë¥¸ ë³´í—˜ ìˆ˜í˜œì ë¹„ìœ¨ì€ ê· ë“±í•˜ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "  3. ë†ê¸°ê³„ì˜ í‰ê·  ë³´í—˜ë£Œê°€ ë‹¤ë¥¸ ì°¨ëŸ‰ ìœ í˜•ì— ë¹„í•´ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "ğŸ¤µ ì¬êµ¬ì„±ëœ ì§ˆë¬¸:\n",
      "**ì¬êµ¬ì„±ëœ ì§ˆë¬¸**: df_top_products ë°ì´í„°í”„ë ˆì„ì˜ êµ¬ì²´ì ì¸ ë‚´ìš©ê³¼ ëª©ì ì— ëŒ€í•´ ì„¤ëª…í•´ ì£¼ì„¸ìš”. íŠ¹íˆ, ì´ ë°ì´í„°í”„ë ˆì„ì´ íŠ¹ì • ì—°ë ¹ëŒ€ì˜ ê¸ˆìœµ íŒ¨í„´ ë¶„ì„ì— ì–´ë–»ê²Œ ì‚¬ìš©ë˜ëŠ”ì§€ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ì°¸ê³  ì‚¬í•­**:\n",
      "- df_top_productsì— ëŒ€í•œ ì§ì ‘ì ì¸ ì„¤ëª…ì€ ì œê³µë˜ì§€ ì•Šì•˜ì§€ë§Œ, íŠ¹ì • ì—°ë ¹ëŒ€ì˜ ê¸ˆìœµ íŒ¨í„´ ë¶„ì„ê³¼ ê´€ë ¨ëœ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ ë°©ë²•ì´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "- df_top_productsëŠ” íŠ¹ì • ì—°ë ¹ëŒ€ì˜ ì£¼ìš” ê¸ˆìœµ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ëœ ë°ì´í„°í”„ë ˆì„ì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "- ê´€ë ¨ ì½”ë“œ:\n",
      "  ```python\n",
      "  # íŠ¹ì • ì—°ë ¹ëŒ€(20~30ëŒ€) ë°ì´í„° í•„í„°ë§\n",
      "  age_filtered_df = df[df['ë‚˜ì´'].isin(['20ëŒ€', '30ëŒ€'])]\n",
      "\n",
      "  # ì£¼ìš” ê¸ˆìœµ íŒ¨í„´ ë¶„ì„\n",
      "  # 1. í‰ê·  CBì‹ ìš©í‰ì \n",
      "  avg_credit_score = age_filtered_df['CBì‹ ìš©í‰ì '].mean()\n",
      "\n",
      "  # 2. ì„±ë³„ì— ë”°ë¥¸ ìˆ˜ìµì ì—¬ë¶€ ë¹„ìœ¨\n",
      "  beneficiary_by_gender = age_filtered_df.groupby('ì„±ë³„')['ìˆ˜ìµìì—¬ë¶€'].mean().round(2)\n",
      "\n",
      "  # 3. ìš´ì „ì½”ë“œëª…ì— ë”°ë¥¸ ë³€ì•¡ê¸°ë‚©ì…ë³´í—˜ë£Œ í‰ê· \n",
      "  avg_insurance_by_drive = age_filtered_df.groupby('ìš´ì „ì½”ë“œëª…')['ë³€ì•¡ê¸°ë‚©ì…ë³´í—˜ë£Œ'].mean().round(2)\n",
      "\n",
      "  # 4. ë³€ì•¡ì¢…ì‹ ë³´ìœ ì—¬ë¶€ì— ë”°ë¥¸ CBì‹ ìš©ë“±ê¸‰ í‰ê· \n",
      "  avg_credit_grade_by_life_insurance = age_filtered_df.groupby('ë³€ì•¡ì¢…ì‹ ë³´ìœ ì—¬ë¶€')['CBì‹ ìš©ë“±ê¸‰'].mean().round(2)\n",
      "\n",
      "  # 5. ë‘ë‚«ì½œì—¬ë¶€ì— ë”°ë¥¸ ë³€ì•¡ì¢…ì‹ ê¸°ë‚©ì…ë³´í—˜ë£Œ í‰ê· \n",
      "  avg_life_insurance_by_donotcall = age_filtered_df.groupby('ë‘ë‚«ì½œì—¬ë¶€')['ë³€ì•¡ì¢…ì‹ ê¸°ë‚©ì…ë³´í—˜ë£Œ'].mean().round(2)\n",
      "\n",
      "  # ê²°ê³¼ ì €ì¥\n",
      "  analytic_results = {\n",
      "      'avg_credit_score': round(avg_credit_score, 2),\n",
      "      'beneficiary_by_gender': beneficiary_by_gender.head().to_dict(),\n",
      "      'avg_insurance_by_drive': avg_insurance_by_drive.head().to_dict(),\n",
      "      'avg_credit_grade_by_life_insurance': avg_credit_grade_by_life_insurance.head().to_dict(),\n",
      "      'avg_life_insurance_by_donotcall': avg_life_insurance_by_donotcall.head().to_dict()\n",
      "  }\n",
      "\n",
      "  print(analytic_results)\n",
      "  ```\n",
      "- ì£¼ìš” ì¸ì‚¬ì´íŠ¸:\n",
      "  1. 20~30ëŒ€ì˜ í‰ê·  ì‹ ìš© ì ìˆ˜ëŠ” 321.93ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "  2. ì„±ë³„ì— ë”°ë¥¸ ë³´í—˜ ìˆ˜í˜œì ë¹„ìœ¨ì€ ê· ë“±í•˜ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "  3. ë†ê¸°ê³„ì˜ í‰ê·  ë³´í—˜ë£Œê°€ ë‹¤ë¥¸ ì°¨ëŸ‰ ìœ í˜•ì— ë¹„í•´ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.Archive.ai_agent_v2 import DataAnayticsAssistant\n",
    "\n",
    "# OpenAI API í‚¤ ë¡œë“œ\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "PROCESSED_DATA_PATH = \"../output/stage1/processed_data_info.xlsx\"\n",
    "mart_name = \"cust_intg\"\n",
    "def load_processed_data_info():\n",
    "    \"\"\"ì‚¬ì „ì— ë¶„ì„ëœ ë°ì´í„° ì •ë³´ ë¡œë“œ\"\"\"\n",
    "    if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "        return None\n",
    "    else:\n",
    "        # ëª¨ë“  ì‹œíŠ¸ ë¡œë“œ\n",
    "        return pd.read_excel(PROCESSED_DATA_PATH, sheet_name=mart_name)\n",
    "\n",
    "# âœ… Streamlit ì‹¤í–‰ ì‹œ ë°ì´í„° ë¡œë“œ\n",
    "mart_info = load_processed_data_info()\n",
    "\n",
    "# ì–´ì‹œìŠ¤í„´íŠ¸ ì´ˆê¸°í™”\n",
    "assistant = DataAnayticsAssistant(openai_api_key)\n",
    "que= \"df_top_products ëŠ” ë¬´ì—‡ì¸ì§€ ë‹¤ì‹œ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "handle_chat_response(assistant, query = que, internal_id = \"temp_KSW_20250227_1403\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://swkwon:1q2w3e$r@cluster0.3rvbn.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.vector_handler import initialize_vector_store\n",
    "\n",
    "thread_id = 'new_chat'\n",
    "query = 'columns_with_20_percent_missing ê°€ ë­ë¼êµ¬ í–ˆì£ ?'\n",
    "vectorstore = initialize_vector_store(thread_id)  # ì„¸ì…˜ë³„ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ\n",
    "\n",
    "\n",
    "# ğŸ” ê²€ìƒ‰ ì‹¤í–‰\n",
    "search_results = vectorstore.similarity_search(query, k=2)\n",
    "retrieved_context = \"\\n\\n\".join([doc.page_content for doc in search_results])\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x24744a56fc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VECTOR_DB_SESSION_PATH = './vector_db_session' \n",
    "vector_db_path = os.path.join(VECTOR_DB_SESSION_PATH, f\"new_chat_vectorstore\")\n",
    "\n",
    "DDS = FAISS.load_local(vector_db_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)  # âœ… ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¡œì»¬ ë°ì´í„°ì´ë¯€ë¡œ í—ˆìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document ID: 94c4d233-b717-42f3-a7f4-a7b1e8916706\n",
      "Content: \n"
     ]
    }
   ],
   "source": [
    "all_docs = vectorstore.docstore._dict\n",
    "all_docs\n",
    "\n",
    "for doc_id, doc in all_docs.items():\n",
    "    print(f\"\\nDocument ID: {doc_id}\")\n",
    "    print(f\"Content: {doc.page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
