{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] ì‹¤í–‰í•  ì½”ë“œ:\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def summarize_data(df, df_name):\n",
      "    \"\"\"\n",
      "    ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„(df)ì— ëŒ€í•œ EDA(íƒìƒ‰ì  ë°ì´í„° ë¶„ì„) ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
      "    - \"ì»¬ëŸ¼ ê°œìš”\"ì— ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬ ì •ë³´ í¬í•¨\n",
      "    - ì—°ì†í˜• ë³€ìˆ˜ì˜ ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ) ì œì™¸ (í† í° ìˆ˜ ì ˆê° ëª©ì )\n",
      "    \"\"\"\n",
      "\n",
      "    # âœ… 1. ì´ìƒì¹˜ íƒì§€ (IQR ë°©ì‹)\n",
      "    outliers_info = {}\n",
      "    for col in df.select_dtypes(include=[np.number]).columns:\n",
      "        Q1 = df[col].quantile(0.25)\n",
      "        Q3 = df[col].quantile(0.75)\n",
      "        IQR = Q3 - Q1\n",
      "        lower_bound = Q1 - 1.5 * IQR\n",
      "        upper_bound = Q3 + 1.5 * IQR\n",
      "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
      "\n",
      "        if outlier_count > 0:\n",
      "            outliers_info[col] = int(outlier_count)\n",
      "\n",
      "    # âœ… 2. ì»¬ëŸ¼ ê°œìš” (ê¸°ë³¸ í†µê³„ ë° ê²°ì¸¡ ì •ë³´ + ì¸ìŠ¤í„´ìŠ¤ ì˜ˆì œ + ë²”ì£¼í˜• ë¶„í¬ ì¶”ê°€)\n",
      "    columns_info = []\n",
      "    for col in df.columns:\n",
      "        col_dtype = df[col].dtype\n",
      "\n",
      "        col_info = {\n",
      "            \"ë°ì´í„°í”„ë ˆì„ëª…\": df_name,\n",
      "            \"ì»¬ëŸ¼ëª…\": col,\n",
      "            \"ë°ì´í„° íƒ€ì…\": col_dtype,\n",
      "            \"count\": df[col].count(),\n",
      "            \"mean\": round(df[col].mean(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"std\": round(df[col].std(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"min\": round(df[col].min(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"25%\": round(df[col].quantile(0.25), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"75%\": round(df[col].quantile(0.75), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"max\": round(df[col].max(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"ê²°ì¸¡ ê°œìˆ˜\": df[col].isnull().sum(),\n",
      "            \"ê²°ì¸¡ì¹˜ ë¹„ìœ¨\": round(df[col].isnull().sum() / len(df) * 100, 0),\n",
      "            \"ê³ ìœ ê°’ ê°œìˆ˜\": df[col].nunique(),\n",
      "        }\n",
      "\n",
      "        # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ë§Œ ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ) í¬í•¨ (ì—°ì†í˜• ë³€ìˆ˜ ì œì™¸í•˜ì—¬ í† í° ìˆ˜ ì ˆê°)\n",
      "        if col_dtype in [\"object\", \"category\"]:\n",
      "            unique_vals = df[col].dropna().unique()\n",
      "            # ìœ ë‹ˆí¬ ê°’ ìƒ˜í”Œë§ (20ê°œ ì´ìƒì´ë©´ 10ê°œë§Œ ì¶œë ¥ + '...')\n",
      "            if len(unique_vals) > 20:\n",
      "                sample_display = list(unique_vals[:10]) + ['...']\n",
      "            else:\n",
      "                sample_display = unique_vals.tolist()\n",
      "            col_info[\"ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ)\"] = sample_display\n",
      "\n",
      "            # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ì¼ ê²½ìš°, ë¶„í¬ ì •ë³´ ì¶”ê°€ (ìµœëŒ€ 10ê°œë§Œ ì €ì¥í•˜ì—¬ í† í° ì ˆê°)\n",
      "            value_counts = df[col].value_counts(normalize=True) * 100\n",
      "            value_counts = value_counts[:10]  # ìµœëŒ€ 10ê°œë§Œ ìœ ì§€\n",
      "            category_distribution = {val: round(pct, 2) for val, pct in value_counts.items()}\n",
      "            col_info[\"ë²”ì£¼í˜• ë¶„í¬\"] = category_distribution\n",
      "\n",
      "        columns_info.append(col_info)\n",
      "\n",
      "    columns_info_df = pd.DataFrame(columns_info)\n",
      "\n",
      "    return columns_info_df\n",
      "\n",
      "# ë‹¤ì¤‘ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ ë° ê²°ê³¼ ì €ì¥\n",
      "def analyze_multiple_dataframes(dataframe_list):\n",
      "    result_tmp = {\"ë°ì´í„° ê°œìš”\": []}\n",
      "\n",
      "    for df_name in dataframe_list:\n",
      "        df = globals().get(df_name)\n",
      "\n",
      "        if df is not None:\n",
      "            rslt = summarize_data(df, df_name)\n",
      "            result_tmp[\"ë°ì´í„° ê°œìš”\"].append(rslt)\n",
      "\n",
      "    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ë³‘í•©\n",
      "    for key in result_tmp.keys():\n",
      "        result_tmp[key] = pd.concat(result_tmp[key], ignore_index=True)\n",
      "\n",
      "    # ê²°ê³¼ ì €ì¥ (ì—‘ì…€ í˜•ì‹)\n",
      "    output_path = \"../output/stage1/eda_summary.xlsx\"\n",
      "    with pd.ExcelWriter(output_path) as writer:\n",
      "        for sheet_name, df in result_tmp.items():\n",
      "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
      "\n",
      "    return result_tmp\n",
      "\n",
      "# ë°ì´í„°í”„ë ˆì„ ëª©ë¡\n",
      "dataframe_list = ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "\n",
      "# ë¶„ì„ ì‹¤í–‰\n",
      "analyze_multiple_dataframes(dataframe_list)\n",
      "\n",
      "[Stage 1. ë°ì´í„° êµ¬ì¡° íŒŒì•…] 1ì°¨ ì‹œë„ | âœ… ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "âœ… ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import traceback  # ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ì„ ìœ„í•´ ì¶”ê°€\n",
    "\n",
    "# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ì„¤ì •\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ê°ì²´ ì„ ì–¸\n",
    "results = {}\n",
    "list_df = {}\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë“œ: ../data ê²½ë¡œì˜ ëª¨ë“  pkl íŒŒì¼ ì½ê¸°\n",
    "data_path = os.path.join('..', 'data')\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        df_name = file.replace('.pkl', '')\n",
    "        list_df[df_name] = pd.read_pickle(file_path)\n",
    "\n",
    "# âœ… globals()ì— ë°ì´í„°í”„ë ˆì„ ë“±ë¡ (í•´ê²°ì±… 1)\n",
    "for name, df in list_df.items():\n",
    "    globals()[name] = df  # âœ… `analyze_multiple_dataframes`ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ë“±ë¡\n",
    "\n",
    "list_df_text = \", \".join(list_df.keys())\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "\n",
    "# âœ… LLMì— ì²« ë²ˆì§¸ ì½”ë“œ ìš”ì²­ (ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë‹¨ê³„)\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"### ì°¸ê³  ì½”ë“œ:\\n{func_code}\\n\\n\"),\n",
    "    (\"user\", \"### list_df:\\n{list_df_text}\\n\\n\")\n",
    "]) | llm\n",
    "\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df_text\": list_df_text}).content\n",
    "\n",
    "attempt_count = 0  # ì‹¤í–‰ ì‹œë„ íšŸìˆ˜\n",
    "success = False  # ì½”ë“œ ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€\n",
    "\n",
    "while attempt_count < 2:  # ìµœì´ˆ ì‹¤í–‰ + 1íšŒ ì¬ì‹œë„ ê°€ëŠ¥\n",
    "    try:\n",
    "        if \"```python\" in response:\n",
    "            modified_code = response.split(\"```python\")[-1].split(\"```\")[0]\n",
    "            print(f\"[LOG] ì‹¤í–‰í•  ì½”ë“œ:\\n{modified_code}\")\n",
    "            exec(modified_code, globals())  # âœ… LLMì´ ìƒì„±í•œ ì½”ë“œ ì‹¤í–‰\n",
    "            print(f\"[Stage 1. ë°ì´í„° êµ¬ì¡° íŒŒì•…] 1ì°¨ ì‹œë„ | âœ… ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            success = True\n",
    "            break  # ì‹¤í–‰ ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ\n",
    "    except Exception as e:\n",
    "        error_trace = traceback.format_exc()  # âœ… ì—ëŸ¬ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘\n",
    "        print(f\"âŒ {attempt_count+1}ì°¨ ì‹œë„ : LLM ìƒì„± ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ\\n{error_trace}\")\n",
    "\n",
    "        if attempt_count == 0:  # ìµœì´ˆ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ 1íšŒë§Œ ì¬ìƒì„±\n",
    "            print(\"ğŸ”„ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½”ë“œ ìˆ˜ì • ìš”ì²­ ì¤‘...\")\n",
    "\n",
    "            # âœ… LLMì— ë” ëª…í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì „ë‹¬ (í•´ê²°ì±… 2)\n",
    "            prompt_error_fix = f\"\"\"\n",
    "            ### ì½”ë“œ ìˆ˜ì • ìš”ì²­\n",
    "\n",
    "            ì´ì „ ì½”ë“œ ì‹¤í–‰ ì¤‘ ë‹¤ìŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n",
    "            ```\n",
    "            {error_trace}\n",
    "            ```\n",
    "\n",
    "            ìœ„ ì˜¤ë¥˜ë¥¼ í•´ê²°í•œ ìƒˆë¡œìš´ ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "            - ê¸°ì¡´ ì½”ë“œì—ì„œ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ ë²„ì „ìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "            - ì˜¤ë¥˜ ì›ì¸ì„ ë¶„ì„í•˜ì—¬ ë°˜ë“œì‹œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ë³´ì™„í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "            - í•„ìš”í•œ ê²½ìš°, ì¶”ê°€ì ì¸ ë°ì´í„° í•¸ë“¤ë§ ì½”ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "            ```python\n",
    "            # í•„ìš”í•œ ì½”ë“œ ì‚½ì…\n",
    "            ```\n",
    "            \"\"\"\n",
    "            chain_error_fix = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", prompt_error_fix),\n",
    "                (\"user\", \"### ê¸°ì¡´ ì½”ë“œ:\\n{modified_code}\\n\\n\")\n",
    "            ]) | llm\n",
    "\n",
    "            response = chain_error_fix.invoke({\"modified_code\": modified_code}).content\n",
    "        else:\n",
    "            print(\"âŒ ì½”ë“œ ì‹¤í–‰ ìµœì¢…ì ìœ¼ë¡œ ì‹¤íŒ¨. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        attempt_count += 1  # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€\n",
    "\n",
    "# âœ… Stage 1 ê²°ê³¼ íŒŒì¼ ë¡œë“œ (ì—‘ì…€)\n",
    "stage1_path = \"../output/stage1/eda_summary.xlsx\"\n",
    "if os.path.exists(stage1_path):\n",
    "    stage1_results = pd.read_excel(stage1_path, sheet_name=0)  # ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©\n",
    "    results[\"stage1\"] = stage1_results  # âœ… Stage 1 ê²°ê³¼ ì €ì¥\n",
    "else:\n",
    "    print(\"âŒ Stage 1 ê²°ê³¼ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    raise FileNotFoundError(\"Stage 1 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# âœ… RAG ê¸°ë°˜ ì»¬ëŸ¼ ì„¤ëª… ì¶”ê°€\n",
    "def load_vectorstore():\n",
    "    if os.path.exists(\"./vectordb\"):\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        try:\n",
    "            return FAISS.load_local(\"./vectordb\", embeddings, allow_dangerous_deserialization=True)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "vectorstore = load_vectorstore()\n",
    "\n",
    "def search_column_descriptions(col_desc_df, vectorstore):\n",
    "    \"\"\"RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¬ëŸ¼ ì„¤ëª…ì„ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    data = []\n",
    "    df_after_llm = col_desc_df[['ë°ì´í„°í”„ë ˆì„ëª…', 'ì»¬ëŸ¼ëª…']]\n",
    "    \n",
    "    for i, row in df_after_llm.iterrows():\n",
    "        table_name = row['ë°ì´í„°í”„ë ˆì„ëª…']\n",
    "        col = row['ì»¬ëŸ¼ëª…']\n",
    "        \n",
    "        search_query = f\"í…Œì´ë¸”ëª… : {table_name} | ì»¬ëŸ¼ëª… : {col}\"\n",
    "        docs = vectorstore.similarity_search(search_query, k=1)\n",
    "        \n",
    "        if docs:\n",
    "            best_match = docs[0].page_content\n",
    "            data.append({\n",
    "                'ë°ì´í„°í”„ë ˆì„ëª…': table_name,\n",
    "                'ì»¬ëŸ¼ëª…': col,\n",
    "                'ì»¬ëŸ¼ì„¤ëª…': best_match.split('\\n')[3].split('ì„¤ëª…')[1].strip()\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                'ë°ì´í„°í”„ë ˆì„ëª…': table_name,\n",
    "                'ì»¬ëŸ¼ëª…': col,\n",
    "                'ì»¬ëŸ¼ì„¤ëª…': \"ì„¤ëª… ì—†ìŒ\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# âœ… Stage 2: RAG ê¸°ë°˜ ì»¬ëŸ¼ ì„¤ëª… ì¶”ê°€\n",
    "rag_results = search_column_descriptions(stage1_results, vectorstore)\n",
    "\n",
    "# âœ… Stage 1 ê²°ê³¼ì™€ RAG ê²°ê³¼ë¥¼ í†µí•©\n",
    "final_df = pd.merge(\n",
    "    stage1_results,  # Stage 1 ê²°ê³¼ (ë°ì´í„° êµ¬ì¡° ì •ë³´)\n",
    "    rag_results,     # RAG ê²€ìƒ‰ ê²°ê³¼ (ì»¬ëŸ¼ ì„¤ëª…)\n",
    "    on=['ë°ì´í„°í”„ë ˆì„ëª…', 'ì»¬ëŸ¼ëª…'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# âœ… ìµœì¢… ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ ë‚´ ì €ì¥\n",
    "results[\"stage2\"] = final_df\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] ì‹¤í–‰í•  ì½”ë“œ:\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def summarize_data(df, df_name):\n",
      "    \"\"\"\n",
      "    ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„(df)ì— ëŒ€í•œ EDA(íƒìƒ‰ì  ë°ì´í„° ë¶„ì„) ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
      "    - \"ì»¬ëŸ¼ ê°œìš”\"ì— ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬ ì •ë³´ í¬í•¨\n",
      "    - ì—°ì†í˜• ë³€ìˆ˜ì˜ ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ) ì œì™¸ (í† í° ìˆ˜ ì ˆê° ëª©ì )\n",
      "    \"\"\"\n",
      "\n",
      "    # âœ… 1. ì´ìƒì¹˜ íƒì§€ (IQR ë°©ì‹)\n",
      "    outliers_info = {}\n",
      "    for col in df.select_dtypes(include=[np.number]).columns:\n",
      "        Q1 = df[col].quantile(0.25)\n",
      "        Q3 = df[col].quantile(0.75)\n",
      "        IQR = Q3 - Q1\n",
      "        lower_bound = Q1 - 1.5 * IQR\n",
      "        upper_bound = Q3 + 1.5 * IQR\n",
      "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
      "\n",
      "        if outlier_count > 0:\n",
      "            outliers_info[col] = int(outlier_count)\n",
      "\n",
      "    # âœ… 2. ì»¬ëŸ¼ ê°œìš” (ê¸°ë³¸ í†µê³„ ë° ê²°ì¸¡ ì •ë³´ + ì¸ìŠ¤í„´ìŠ¤ ì˜ˆì œ + ë²”ì£¼í˜• ë¶„í¬ ì¶”ê°€)\n",
      "    columns_info = []\n",
      "    for col in df.columns:\n",
      "        col_dtype = df[col].dtype\n",
      "\n",
      "        col_info = {\n",
      "            \"ë°ì´í„°í”„ë ˆì„ëª…\": df_name,\n",
      "            \"ì»¬ëŸ¼ëª…\": col,\n",
      "            \"ë°ì´í„° íƒ€ì…\": col_dtype,\n",
      "            \"count\": df[col].count(),\n",
      "            \"mean\": round(df[col].mean(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"std\": round(df[col].std(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"min\": round(df[col].min(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"25%\": round(df[col].quantile(0.25), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"75%\": round(df[col].quantile(0.75), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"max\": round(df[col].max(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"ê²°ì¸¡ ê°œìˆ˜\": df[col].isnull().sum(),\n",
      "            \"ê²°ì¸¡ì¹˜ ë¹„ìœ¨\": round(df[col].isnull().sum() / len(df) * 100, 0),\n",
      "            \"ê³ ìœ ê°’ ê°œìˆ˜\": df[col].nunique(),\n",
      "        }\n",
      "\n",
      "        # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ë§Œ ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ) í¬í•¨ (ì—°ì†í˜• ë³€ìˆ˜ ì œì™¸í•˜ì—¬ í† í° ìˆ˜ ì ˆê°)\n",
      "        if col_dtype in [\"object\", \"category\"]:\n",
      "            unique_vals = df[col].dropna().unique()\n",
      "            # ìœ ë‹ˆí¬ ê°’ ìƒ˜í”Œë§ (20ê°œ ì´ìƒì´ë©´ 10ê°œë§Œ ì¶œë ¥ + '...')\n",
      "            if len(unique_vals) > 20:\n",
      "                sample_display = list(unique_vals[:10]) + ['...']\n",
      "            else:\n",
      "                sample_display = unique_vals.tolist()\n",
      "            col_info[\"ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ)\"] = sample_display\n",
      "\n",
      "            # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ì¼ ê²½ìš°, ë¶„í¬ ì •ë³´ ì¶”ê°€ (ìµœëŒ€ 10ê°œë§Œ ì €ì¥í•˜ì—¬ í† í° ì ˆê°)\n",
      "            value_counts = df[col].value_counts(normalize=True) * 100\n",
      "            value_counts = value_counts[:10]  # ìµœëŒ€ 10ê°œë§Œ ìœ ì§€\n",
      "            category_distribution = {val: round(pct, 2) for val, pct in value_counts.items()}\n",
      "            col_info[\"ë²”ì£¼í˜• ë¶„í¬\"] = category_distribution\n",
      "\n",
      "        columns_info.append(col_info)\n",
      "\n",
      "    columns_info_df = pd.DataFrame(columns_info)\n",
      "\n",
      "    return columns_info_df\n",
      "\n",
      "# ë‹¤ì¤‘ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ ë° ê²°ê³¼ ì €ì¥\n",
      "def analyze_multiple_dataframes(dataframe_list):\n",
      "    result_tmp = {\"ë°ì´í„° ê°œìš”\": []}\n",
      "\n",
      "    for df_name in dataframe_list:\n",
      "        df = globals().get(df_name)\n",
      "\n",
      "        if df is not None:\n",
      "            rslt = summarize_data(df, df_name)\n",
      "            result_tmp[\"ë°ì´í„° ê°œìš”\"].append(rslt)\n",
      "\n",
      "    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ë³‘í•©\n",
      "    for key in result_tmp.keys():\n",
      "        result_tmp[key] = pd.concat(result_tmp[key], ignore_index=True)\n",
      "\n",
      "    # ê²°ê³¼ ì €ì¥ (ì—‘ì…€ í˜•ì‹)\n",
      "    output_path = \"../output/stage1/eda_summary.xlsx\"\n",
      "    with pd.ExcelWriter(output_path) as writer:\n",
      "        for sheet_name, df in result_tmp.items():\n",
      "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
      "\n",
      "    return result_tmp\n",
      "\n",
      "# ë°ì´í„°í”„ë ˆì„ ëª©ë¡\n",
      "dataframe_list = ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "\n",
      "# ë¶„ì„ ì‹¤í–‰\n",
      "analyze_multiple_dataframes(dataframe_list)\n",
      "\n",
      "âŒ 1ì°¨ ì‹œë„ : LLM ìƒì„± ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: No objects to concatenate\n",
      "ğŸ”„ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½”ë“œ ìˆ˜ì • ìš”ì²­ ì¤‘...\n",
      "[LOG] ì‹¤í–‰í•  ì½”ë“œ:\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def summarize_data(df, df_name):\n",
      "    \"\"\"\n",
      "    ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„(df)ì— ëŒ€í•œ EDA(íƒìƒ‰ì  ë°ì´í„° ë¶„ì„) ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
      "    - \"ì»¬ëŸ¼ ê°œìš”\"ì— ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬ ì •ë³´ í¬í•¨\n",
      "    - ì—°ì†í˜• ë³€ìˆ˜ì˜ ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ) ì œì™¸ (í† í° ìˆ˜ ì ˆê° ëª©ì )\n",
      "    \"\"\"\n",
      "\n",
      "    # âœ… 1. ì´ìƒì¹˜ íƒì§€ (IQR ë°©ì‹)\n",
      "    outliers_info = {}\n",
      "    for col in df.select_dtypes(include=[np.number]).columns:\n",
      "        Q1 = df[col].quantile(0.25)\n",
      "        Q3 = df[col].quantile(0.75)\n",
      "        IQR = Q3 - Q1\n",
      "        lower_bound = Q1 - 1.5 * IQR\n",
      "        upper_bound = Q3 + 1.5 * IQR\n",
      "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
      "\n",
      "        if outlier_count > 0:\n",
      "            outliers_info[col] = int(outlier_count)\n",
      "\n",
      "    # âœ… 2. ì»¬ëŸ¼ ê°œìš” (ê¸°ë³¸ í†µê³„ ë° ê²°ì¸¡ ì •ë³´ + ì¸ìŠ¤í„´ìŠ¤ ì˜ˆì œ + ë²”ì£¼í˜• ë¶„í¬ ì¶”ê°€)\n",
      "    columns_info = []\n",
      "    for col in df.columns:\n",
      "        col_dtype = df[col].dtype\n",
      "\n",
      "        col_info = {\n",
      "            \"ë°ì´í„°í”„ë ˆì„ëª…\": df_name,\n",
      "            \"ì»¬ëŸ¼ëª…\": col,\n",
      "            \"ë°ì´í„° íƒ€ì…\": col_dtype,\n",
      "            \"count\": df[col].count(),\n",
      "            \"mean\": round(df[col].mean(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"std\": round(df[col].std(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"min\": round(df[col].min(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"25%\": round(df[col].quantile(0.25), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"75%\": round(df[col].quantile(0.75), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"max\": round(df[col].max(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"ê²°ì¸¡ ê°œìˆ˜\": df[col].isnull().sum(),\n",
      "            \"ê²°ì¸¡ì¹˜ ë¹„ìœ¨\": round(df[col].isnull().sum() / len(df) * 100, 0),\n",
      "            \"ê³ ìœ ê°’ ê°œìˆ˜\": df[col].nunique(),\n",
      "        }\n",
      "\n",
      "        # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ë§Œ ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ) í¬í•¨ (ì—°ì†í˜• ë³€ìˆ˜ ì œì™¸í•˜ì—¬ í† í° ìˆ˜ ì ˆê°)\n",
      "        if col_dtype in [\"object\", \"category\"]:\n",
      "            unique_vals = df[col].dropna().unique()\n",
      "            # ìœ ë‹ˆí¬ ê°’ ìƒ˜í”Œë§ (20ê°œ ì´ìƒì´ë©´ 10ê°œë§Œ ì¶œë ¥ + '...')\n",
      "            if len(unique_vals) > 20:\n",
      "                sample_display = list(unique_vals[:10]) + ['...']\n",
      "            else:\n",
      "                sample_display = unique_vals.tolist()\n",
      "            col_info[\"ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ)\"] = sample_display\n",
      "\n",
      "            # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ì¼ ê²½ìš°, ë¶„í¬ ì •ë³´ ì¶”ê°€ (ìµœëŒ€ 10ê°œë§Œ ì €ì¥í•˜ì—¬ í† í° ì ˆê°)\n",
      "            value_counts = df[col].value_counts(normalize=True) * 100\n",
      "            value_counts = value_counts[:10]  # ìµœëŒ€ 10ê°œë§Œ ìœ ì§€\n",
      "            category_distribution = {val: round(pct, 2) for val, pct in value_counts.items()}\n",
      "            col_info[\"ë²”ì£¼í˜• ë¶„í¬\"] = category_distribution\n",
      "\n",
      "        columns_info.append(col_info)\n",
      "\n",
      "    columns_info_df = pd.DataFrame(columns_info)\n",
      "\n",
      "    return columns_info_df\n",
      "\n",
      "# ë‹¤ì¤‘ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ ë° ê²°ê³¼ ì €ì¥\n",
      "def analyze_multiple_dataframes(dataframe_list):\n",
      "    result_tmp = {\"ë°ì´í„° ê°œìš”\": []}\n",
      "\n",
      "    for df_name in dataframe_list:\n",
      "        df = globals().get(df_name)\n",
      "\n",
      "        if df is not None and not df.empty:\n",
      "            rslt = summarize_data(df, df_name)\n",
      "            result_tmp[\"ë°ì´í„° ê°œìš”\"].append(rslt)\n",
      "\n",
      "    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ë³‘í•©\n",
      "    for key in result_tmp.keys():\n",
      "        if result_tmp[key]:  # ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ë³‘í•©\n",
      "            result_tmp[key] = pd.concat(result_tmp[key], ignore_index=True)\n",
      "        else:\n",
      "            result_tmp[key] = pd.DataFrame()  # ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì´ˆê¸°í™”\n",
      "\n",
      "    # ê²°ê³¼ ì €ì¥ (ì—‘ì…€ í˜•ì‹)\n",
      "    output_path = \"../output/stage1/eda_summary.xlsx\"\n",
      "    with pd.ExcelWriter(output_path) as writer:\n",
      "        for sheet_name, df in result_tmp.items():\n",
      "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
      "\n",
      "    return result_tmp\n",
      "\n",
      "# ë°ì´í„°í”„ë ˆì„ ëª©ë¡\n",
      "dataframe_list = ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "\n",
      "# ë¶„ì„ ì‹¤í–‰\n",
      "analyze_multiple_dataframes(dataframe_list)\n",
      "\n",
      "[Stage 1. ë°ì´í„° êµ¬ì¡° íŒŒì•…] 1ì°¨ ì‹œë„ | âœ… ë°ì´í„°ë§ˆíŠ¸ì— ëŒ€í•œ êµ¬ì¡° íŒŒì•… ì½”ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "# âœ… LangGraph ë° LangChain ê´€ë ¨ ëª¨ë“ˆ\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# âœ… AI Assistant LangGraph Class Import\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "\n",
    "\n",
    "# âœ… OpenAI API Key í™•ì¸\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key, temperature=0,)\n",
    "\n",
    "# llm ê²°ê³¼ ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ê°€ ë‹´ê¸¸ ê°ì²´ dict ì„ ì–¸\n",
    "results = {}\n",
    "list_df = {}\n",
    "\n",
    "# ../data ê²½ë¡œì˜ ëª¨ë“  pkl íŒŒì¼ ì½ê¸°\n",
    "data_path = os.path.join('..', 'data')\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        df_name = file.replace('.pkl', '')\n",
    "        list_df[df_name] = pd.read_pickle(file_path)\n",
    "\n",
    "list_df_text = \", \".join(list_df)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "\n",
    "# LLMì— ì²« ë²ˆì§¸ ì½”ë“œ ìš”ì²­\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"### ì°¸ê³  ì½”ë“œ:\\n{func_code}\\n\\n\"),\n",
    "            (\"user\", \"### list_df:\\n{list_df}\\n\\n\")\n",
    "        ]) | llm\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df\": list_df_text}).content\n",
    "\n",
    "attempt_count = 0  # ì‹¤í–‰ ì‹œë„ íšŸìˆ˜\n",
    "success = False  # ì½”ë“œ ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€\n",
    "\n",
    "while attempt_count < 2:  # ìµœì´ˆ ì‹¤í–‰ + 1íšŒ ì¬ìƒì„± ê°€ëŠ¥\n",
    "    try:\n",
    "        if \"```python\" in response:\n",
    "            modified_code = response.split(\"```python\")[-1].split(\"```\")[0]\n",
    "            print(f\"[LOG] ì‹¤í–‰í•  ì½”ë“œ:\\n{modified_code}\")\n",
    "            exec(modified_code, globals())  # LLMì´ ìƒì„±í•œ ì½”ë“œ ì‹¤í–‰\n",
    "            print(f\"[Stage 1. ë°ì´í„° êµ¬ì¡° íŒŒì•…] 1ì°¨ ì‹œë„ | âœ… ë°ì´í„°ë§ˆíŠ¸ì— ëŒ€í•œ êµ¬ì¡° íŒŒì•… ì½”ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            success = True\n",
    "            break  # ì‹¤í–‰ ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ\n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        print(f\"âŒ {attempt_count+1}ì°¨ ì‹œë„ : LLM ìƒì„± ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_message}\")\n",
    "\n",
    "        if attempt_count == 0:  # ìµœì´ˆ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ 1íšŒë§Œ ì¬ìƒì„±\n",
    "            print(\"ğŸ”„ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½”ë“œ ìˆ˜ì • ìš”ì²­ ì¤‘...\")\n",
    "\n",
    "            # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì— ì½”ë“œ ìˆ˜ì • ìš”ì²­\n",
    "            prompt_error_fix = f\"\"\"\n",
    "            ### ì½”ë“œ ìˆ˜ì • ìš”ì²­\n",
    "\n",
    "            ì´ì „ ì½”ë“œ ì‹¤í–‰ ì¤‘ ë‹¤ìŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n",
    "            ```\n",
    "            {error_message}\n",
    "            ```\n",
    "\n",
    "            ìœ„ ì˜¤ë¥˜ë¥¼ í•´ê²°í•œ ìƒˆë¡œìš´ ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "            - ê¸°ì¡´ ì½”ë“œì—ì„œ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ ë²„ì „ìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "            - ì½”ë“œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ë³´ì™„í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "            ```python\n",
    "            # í•„ìš”í•œ ì½”ë“œ ì‚½ì…\n",
    "            ```\n",
    "            \"\"\"\n",
    "            chain_error_fix = ChatPromptTemplate.from_messages([\n",
    "                        (\"system\", prompt_error_fix),\n",
    "                        (\"user\", \"### ê¸°ì¡´ ì½”ë“œ:\\n{modified_code}\\n\\n\")\n",
    "                    ]) | llm\n",
    "\n",
    "            response = chain_error_fix.invoke({\"modified_code\": modified_code}).content\n",
    "            # print(f'[LOG] ìˆ˜ì •ëœ ì½”ë“œ:\\n{response}')\n",
    "        else:\n",
    "            print(\"âŒ ì½”ë“œ ì‹¤í–‰ ìµœì¢…ì ìœ¼ë¡œ ì‹¤íŒ¨. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        attempt_count += 1  # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€\n",
    "\n",
    "# âœ… FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ\n",
    "def load_vectorstore():\n",
    "    if os.path.exists(\"./vectordb\"):\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        try:\n",
    "            return FAISS.load_local(\"./vectordb\", embeddings, allow_dangerous_deserialization=True)\n",
    "        except Exception as e:\n",
    "            print(f\"ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "vectorstore = load_vectorstore()\n",
    "def load_column_descriptions(file_path):\n",
    "    \"\"\"ì»¬ëŸ¼ ì„¤ëª… ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        # Stage 1ì˜ ê²°ê³¼ì—ì„œ ì²« ë²ˆì§¸ ì‹œíŠ¸(ë°ì´í„° êµ¬ì¡° ìš”ì•½) ë¡œë“œ\n",
    "        return pd.read_excel(file_path, sheet_name=0)\n",
    "    print(\"âš ï¸ ì»¬ëŸ¼ ì„¤ëª… íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ëª… ì—†ì´ ì§„í–‰ë©ë‹ˆë‹¤.\")\n",
    "    return None\n",
    "\n",
    "def search_column_descriptions(col_desc_df, vectorstore):\n",
    "    \"\"\"RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¬ëŸ¼ ì„¤ëª…ì„ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    data = []\n",
    "    # Stage 1 ê²°ê³¼ì˜ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "    df_after_llm = col_desc_df[['ë°ì´í„°í”„ë ˆì„ëª…', 'ì»¬ëŸ¼ëª…']]\n",
    "    \n",
    "    for i, row in df_after_llm.iterrows():\n",
    "        table_name = row['ë°ì´í„°í”„ë ˆì„ëª…']\n",
    "        col = row['ì»¬ëŸ¼ëª…']\n",
    "        \n",
    "        # í˜„ì¬ í…Œì´ë¸”ëª…ì„ í¬í•¨í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±\n",
    "        search_query = f\"í…Œì´ë¸”ëª… : {table_name} | ì»¬ëŸ¼ëª… : {col}\"\n",
    "        docs = vectorstore.similarity_search(search_query, k=1)\n",
    "        \n",
    "        if docs:\n",
    "            best_match = docs[0].page_content\n",
    "            data.append({\n",
    "                'ë°ì´í„°í”„ë ˆì„ëª…': table_name,\n",
    "                'ì»¬ëŸ¼ëª…': col,\n",
    "                'ì»¬ëŸ¼ì„¤ëª…': best_match.split('\\n')[3].split('ì„¤ëª…')[1].strip()\n",
    "            })\n",
    "            print(f\"ğŸ” [{i+1}] {search_query} | {best_match.split('ì„¤ëª…')[1].strip()}\")\n",
    "        else:\n",
    "            data.append({\n",
    "                'ë°ì´í„°í”„ë ˆì„ëª…': table_name,\n",
    "                'ì»¬ëŸ¼ëª…': col,\n",
    "                'ì»¬ëŸ¼ì„¤ëª…': \"ì„¤ëª… ì—†ìŒ\"\n",
    "            })\n",
    "            print(f\"âš ï¸ ì»¬ëŸ¼ '{col}' ì„¤ëª… ì—†ìŒ\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„\n",
    "stage1_path = \"output/stage1/eda_summary.xlsx\"\n",
    "col_desc_df = load_column_descriptions(stage1_path)\n",
    "\n",
    "if col_desc_df is not None:\n",
    "    # RAG ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    rag_results = search_column_descriptions(col_desc_df, vectorstore)\n",
    "    \n",
    "    # Stage 1ì˜ ê²°ê³¼ì™€ RAG ê²°ê³¼ë¥¼ í†µí•©\n",
    "    final_df = pd.merge(\n",
    "        col_desc_df,     # Stage 1ì˜ ê²°ê³¼ (ì›ë³¸ ë°ì´í„° êµ¬ì¡° ì •ë³´)\n",
    "        rag_results,     # RAG ê²€ìƒ‰ ê²°ê³¼ (ì»¬ëŸ¼ ì„¤ëª…)\n",
    "        on=['ë°ì´í„°í”„ë ˆì„ëª…', 'ì»¬ëŸ¼ëª…'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    output_path = \"output/stage1/integrated_column_descriptions.xlsx\"\n",
    "    \n",
    "    # ì›ë³¸ Stage 1 ê²°ê³¼ì˜ ëª¨ë“  ì‹œíŠ¸ë¥¼ ë³µì‚¬í•˜ê³ , í†µí•© ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ ì‹œíŠ¸ë¡œ ì¶”ê°€\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        # ë¨¼ì € Stage 1ì˜ ëª¨ë“  ì‹œíŠ¸ë¥¼ ë³µì‚¬\n",
    "        original_sheets = pd.read_excel(stage1_path, sheet_name=None)\n",
    "        for sheet_name, df in original_sheets.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # í†µí•©ëœ ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ ì‹œíŠ¸ë¡œ ì¶”ê°€\n",
    "        final_df.to_excel(writer, sheet_name='í†µí•©_ê²°ê³¼', index=False)\n",
    "    \n",
    "    print(f\"âœ… í†µí•©ëœ ê²°ê³¼ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” [1] í…Œì´ë¸”ëª… : cust_enroll_history | ì»¬ëŸ¼ëª… : ê³ ê°ID | : ê°œë³„ ê³ ê°ì„ ì‹ë³„í•˜ê¸° ìœ„í•œ ê³ ìœ  ì‹ë³„ ë²ˆí˜¸\n",
      "ğŸ” [2] í…Œì´ë¸”ëª… : cust_enroll_history | ì»¬ëŸ¼ëª… : ê°€ì…ë…„ì›”ì¼ | : ê³ ê°ì´ ë³´í—˜ ìƒí’ˆì— ê°€ì…í•œ ë‚ ì§œ (ë…„, ì›”, ì¼ ë‹¨ìœ„).\n",
      "ğŸ” [3] í…Œì´ë¸”ëª… : cust_enroll_history | ì»¬ëŸ¼ëª… : ê°€ì…ë‹´ë³´ëª… | : ê³ ê°ì´ ê°€ì…í•œ ë‹´ë³´ì— ëŒ€í•´ ì„¤ì •ëœ ë³´ì¥ ê¸ˆì•¡.\n",
      "ğŸ” [4] í…Œì´ë¸”ëª… : cust_enroll_history | ì»¬ëŸ¼ëª… : ê°€ì…ë‹´ë³´ê¸ˆì•¡ | : ê³ ê°ì´ ê°€ì…í•œ ë‹´ë³´ì— ëŒ€í•´ ì„¤ì •ëœ ë³´ì¥ ê¸ˆì•¡.\n",
      "ğŸ” [5] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê³ ê°ID | : ê°œë³„ ê³ ê°ì„ ì‹ë³„í•˜ê¸° ìœ„í•œ ê³ ìœ  ì‹ë³„ ë²ˆí˜¸\n",
      "ğŸ” [6] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‚˜ì´ | : ê³ ê°ì˜ í˜„ì¬ ì—°ë ¹\n",
      "ğŸ” [7] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì„±ë³„ | : ê³ ê°ì˜ ì„±ë³„ (ë‚¨/ì—¬)\n",
      "ğŸ” [8] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìˆ˜ìµìì—¬ë¶€ | : ê³ ê°ì´ ë³´í—˜ ìˆ˜ìµìì¸ì§€ ì—¬ë¶€\n",
      "ğŸ” [9] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : CBì‹ ìš©í‰ì  | : CB(Credit Bureau) ê¸°ì¤€ ê³ ê°ì˜ ì‹ ìš©í‰ì \n",
      "ğŸ” [10] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : CBì‹ ìš©ë“±ê¸‰ | : CB(Credit Bureau) ê¸°ì¤€ ê³ ê°ì˜ ì‹ ìš©ë“±ê¸‰\n",
      "ğŸ” [11] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‘ë‚«ì½œì—¬ë¶€ | : ê³ ê°ì´ ë§ˆì¼€íŒ… ì „í™” ìˆ˜ì‹ ì„ ê±°ë¶€í–ˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [12] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìš´ì „ì½”ë“œëª… | : ê³ ê°ì˜ ìš´ì „ ê´€ë ¨ ì½”ë“œëª… (ìš´ì „ë©´í—ˆ ì—¬ë¶€ ë“±)\n",
      "ğŸ” [13] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì„±ë³„ì½”ë“œ | : ê³ ê° ì„±ë³„ì„ ë‚˜íƒ€ë‚´ëŠ” ì½”ë“œ ê°’\n",
      "ğŸ” [14] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : í”¼ë³´í—˜ìì—¬ë¶€ | : ê³ ê°ì´ í”¼ë³´í—˜ìì¸ì§€ ì—¬ë¶€\n",
      "ğŸ” [15] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³´í—˜ì—°ë ¹ | : ë³´í—˜ ê°€ì… ì‹œ ì‚°ì •ëœ ê³ ê°ì˜ ì—°ë ¹\n",
      "ğŸ” [16] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì§ì—…ë¶„ë¥˜ëª… | : ê³ ê°ì˜ ì§ì—… ë¶„ë¥˜ëª…\n",
      "ğŸ” [17] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì§ì—…ìœ„í—˜ë“±ê¸‰ì½”ë“œ | : ì§ì—…ì— ë”°ë¥¸ ìœ„í—˜ ë“±ê¸‰ì„ ë‚˜íƒ€ë‚´ëŠ” ì½”ë“œ\n",
      "ğŸ” [18] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì‹œë„ì½”ë“œ | : ê³ ê° ê±°ì£¼ì§€ì˜ ì‹œë„(ê´‘ì—­ìì¹˜ë‹¨ì²´)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì½”ë“œ\n",
      "ğŸ” [19] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë°©ì¹´ì±„ë„Affluentê³ ê°ì—¬ë¶€ | : ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì˜ ê³ ì•¡ ìì‚°(Affluent) ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [20] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë°©ì¹´ì±„ë„ìœ ì§€ê³„ì•½ê±´ìˆ˜ | : ë°©ì¹´ìŠˆë‘ìŠ¤ ì±„ë„ì„ í†µí•œ ìœ ì§€ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [21] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : CMIP | : ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [22] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : êµì°¨ì±„ë„í™œë™ê³ ê°ì—¬ë¶€ | : ê³ ê°ì´ êµì°¨ ì±„ë„ì—ì„œ í™œë™í–ˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [23] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : êµì°¨ì±„ë„CMIP | : êµì°¨ ì±„ë„ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [24] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : êµì°¨ì±„ë„ìœ ì§€ê³„ì•½ê±´ìˆ˜ | : êµì°¨ ì±„ë„ì„ í†µí•œ ìœ ì§€ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [25] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : DMì±„ë„í™œë™ê³ ê°ì—¬ë¶€ | : CM(Cyber Marketing) ì±„ë„ì—ì„œ ê³ ê°ì´ í™œë™í–ˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [26] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : DMì±„ë„ìœ ì§€ê³„ì•½ê±´ìˆ˜ | : ê¸°íƒ€ ì±„ë„ì„ í†µí•œ ìœ ì§€ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [27] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê¸°íƒ€ì±„ë„ëˆ„ì ì„±ë¦½ê±´ìˆ˜ | : ê¸°íƒ€ ì±„ë„ì—ì„œ ì„±ë¦½ëœ ëˆ„ì  ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [28] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê¸°íƒ€ì±„ë„CMIP | : ê¸°íƒ€ ì±„ë„ ê´€ë ¨ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [29] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê¸°íƒ€ì±„ë„ìœ ì§€ê³„ì•½ê±´ìˆ˜ | : ê¸°íƒ€ ì±„ë„ì„ í†µí•œ ìœ ì§€ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [30] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : GAì±„ë„í™œë™ê³ ê°ì—¬ë¶€ | : ê³ ê°ì´ GA(General Agency) ì±„ë„ì—ì„œ í™œë™í–ˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [31] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : GAì±„ë„Affluentê³ ê°ì—¬ë¶€ | : GA(General Agency)ì±„ë„ì˜ ê³ ì•¡ ìì‚°(Affluent) ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [32] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : GAì±„ë„CMIP | : GA(General Agency)ì±„ë„ ê´€ë ¨ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [33] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : GAì±„ë„ìœ ì§€ê³„ì•½ê±´ìˆ˜ | : GA(General Agency)ì±„ë„ì„ í†µí•œ ìœ ì§€ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [34] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : í•˜ì´ë¸Œë¦¬ë“œì±„ë„í™œë™ê³ ê°ì—¬ë¶€ | : í•˜ì´ë¸Œë¦¬ë“œ ì±„ë„ì—ì„œ ê³ ê°ì´ í™œë™í–ˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [35] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìì‚¬ì„¤ê³„ì‚¬ì±„ë„ëˆ„ì ì„±ë¦½ê±´ìˆ˜ | : ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì„ í†µí•œ ëˆ„ì  ì„±ë¦½ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [36] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìì‚¬ì„¤ê³„ì‚¬ì±„ë„í™œë™ê³ ê°ì—¬ë¶€ | : ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì—ì„œ ê³ ê°ì´ í™œë™í–ˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [37] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìì‚¬ì„¤ê³„ì‚¬ì±„ë„Affluentê³ ê°ì—¬ë¶€ | : ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì˜ ê³ ì•¡ ìì‚°(Affluent) ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [38] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìì‚¬ì„¤ê³„ì‚¬ì±„ë„CMIP | : ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ ê´€ë ¨ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [39] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìì‚¬ì„¤ê³„ì‚¬ì±„ë„ìœ ì§€ê³„ì•½ê±´ìˆ˜ | : ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì„ í†µí•œ ìœ ì§€ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [40] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : CMì±„ë„í™œë™ê³ ê°ì—¬ë¶€ | : CM(Cyber Marketing) ì±„ë„ì—ì„œ ê³ ê°ì´ í™œë™í–ˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [41] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : CMì±„ë„CMIP | : CM(Cyber Marketing) ì±„ë„ ê´€ë ¨ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [42] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì•„ì›ƒë°”ìš´ë“œì±„ë„ëˆ„ì ì„±ë¦½ê±´ìˆ˜ | : ì•„ì›ƒë°”ìš´ë“œ ì±„ë„ì„ í†µí•œ ëˆ„ì  ì„±ë¦½ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [43] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì•„ì›ƒë°”ìš´ë“œì±„ë„CMIP | : ì•„ì›ƒë°”ìš´ë“œ ì±„ë„ ê´€ë ¨ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [44] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì•„ì›ƒë°”ìš´ë“œì±„ë„ìœ ì§€ê³„ì•½ê±´ìˆ˜ | : ì•„ì›ƒë°”ìš´ë“œ ì±„ë„ì„ í†µí•œ ìœ ì§€ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [45] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ì´íƒˆê³ ê°ì—¬ë¶€ | : ë‹¹ì›”ì— ì´íƒˆí•œ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [46] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”êµì°¨ì±„ë„ìœ ì…ê³ ê°ì—¬ë¶€ | : ë‹¹ì›” êµì°¨ ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [47] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”DMì±„ë„ìœ ì…ê³ ê°ì—¬ë¶€ | : ë‹¹ì›” DM(Direct Marketing - ëŒ€ë©´ ë§ˆì¼€íŒ…)  ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [48] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”DMì±„ë„ìœ ì…ê³„ì•½ê±´ìˆ˜ | : ë‹¹ì›” DM(Direct Marketing - ëŒ€ë©´ ë§ˆì¼€íŒ…)  ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [49] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”DMì±„ë„ì„±ë¦½ê±´ìˆ˜ | : ë‹¹ì›” DM(Direct Marketing - ëŒ€ë©´ ë§ˆì¼€íŒ…)  ì±„ë„ì„ í†µí•œ ì„±ë¦½ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [50] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”DMì±„ë„ê³„ì•½ì´íƒˆê±´ìˆ˜ | : ë‹¹ì›” DM(Direct Marketing - ëŒ€ë©´ ë§ˆì¼€íŒ…)  ì±„ë„ì—ì„œ ê³„ì•½ ì´íƒˆ ê±´ìˆ˜\n",
      "ğŸ” [51] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”GAì±„ë„ìœ ì…ê³ ê°ì—¬ë¶€ | : ë‹¹ì›” GA(General Agency)ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [52] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”GAì±„ë„ìœ ì…ê³„ì•½ê±´ìˆ˜ | : ë‹¹ì›” GA(General Agency)ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [53] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”GAì±„ë„ì„±ë¦½ê±´ìˆ˜ | : ë‹¹ì›” GA(General Agency)ì±„ë„ì„ í†µí•œ ì„±ë¦½ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [54] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”GAì±„ë„ê³„ì•½ì´íƒˆê±´ìˆ˜ | : ë‹¹ì›” GA(General Agency)ì±„ë„ì—ì„œ ê³„ì•½ ì´íƒˆ ê±´ìˆ˜\n",
      "ğŸ” [55] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ìœ ì…ê³ ê°ì—¬ë¶€ | : ë‹¹ì›” ìœ ì…ëœ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [56] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ìœ ì…ê³„ì•½ê±´ìˆ˜ | : ë‹¹ì›” ìœ ì…ëœ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [57] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ìì‚¬ì„¤ê³„ì‚¬ì±„ë„ì´íƒˆê³ ê°ì—¬ë¶€ | : ë‹¹ì›” ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì—ì„œ ì´íƒˆí•œ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [58] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ìì‚¬ì„¤ê³„ì‚¬ì±„ë„ìœ ì…ê³ ê°ì—¬ë¶€ | : ë‹¹ì›” ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [59] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ìì‚¬ì„¤ê³„ì‚¬ì±„ë„ìœ ì…ê³„ì•½ê±´ìˆ˜ | : ë‹¹ì›” ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [60] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ìì‚¬ì„¤ê³„ì‚¬ì±„ë„ì„±ë¦½ê±´ìˆ˜ | : ë‹¹ì›” ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì„ í†µí•œ ì„±ë¦½ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [61] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ìì‚¬ì„¤ê³„ì‚¬ì±„ë„ê³„ì•½ì´íƒˆê±´ìˆ˜ | : ë‹¹ì›” ìì‚¬ ì„¤ê³„ì‚¬ ì±„ë„ì—ì„œ ê³„ì•½ ì´íƒˆ ê±´ìˆ˜\n",
      "ğŸ” [62] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ì‹ ê·œê³ ê°ì—¬ë¶€ | : ë‹¹ì›” ì‹ ê·œë¡œ ê°€ì…í•œ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [63] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ì•„ì›ƒë°”ìš´ë“œì±„ë„ìœ ì…ê³ ê°ì—¬ë¶€ | : ë‹¹ì›” ì•„ì›ƒë°”ìš´ë“œ ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [64] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ì•„ì›ƒë°”ìš´ë“œì±„ë„ìœ ì…ê³„ì•½ê±´ìˆ˜ | : ë‹¹ì›” ì•„ì›ƒë°”ìš´ë“œ ì±„ë„ì„ í†µí•´ ìœ ì…ëœ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [65] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ì•„ì›ƒë°”ìš´ë“œì±„ë„ì„±ë¦½ê±´ìˆ˜ | : ë‹¹ì›” ì•„ì›ƒë°”ìš´ë“œ ì±„ë„ì„ í†µí•œ ì„±ë¦½ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [66] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì ì½œì„¼í„°ìƒë‹´ê±´ìˆ˜ | : ì½œì„¼í„°ë¥¼ í†µí•œ ëˆ„ì  ìƒë‹´ ê±´ìˆ˜\n",
      "ğŸ” [67] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì ë¶€ì •ë°˜ì‘ê±´ìˆ˜ | : ê³ ê°ì˜ ë¶€ì •ì  ë°˜ì‘ ëˆ„ì  ê±´ìˆ˜\n",
      "ğŸ” [68] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì VOCì ‘ìˆ˜ê±´ìˆ˜ | : VOC(Voice of Customer) ì ‘ìˆ˜ ëˆ„ì  ê±´ìˆ˜\n",
      "ğŸ” [69] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìµœê·¼3ê°œì›”ì‚¬ì´ë²„í™˜ê¸‰ê¸ˆì¡°íšŒê±´ìˆ˜ | : ìµœê·¼ 3ê°œì›”ê°„ ì‚¬ì´ë²„ í™˜ê¸‰ê¸ˆ ì¡°íšŒ ê±´ìˆ˜\n",
      "ğŸ” [70] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì ì—°ê¸ˆì§€ê¸‰ê¸ˆì•¡ | : ëˆ„ì ëœ ì—°ê¸ˆ ì§€ê¸‰ ì´ ê¸ˆì•¡\n",
      "ğŸ” [71] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì ë³´í—˜ê¸ˆì§€ê¸‰ê±´ìˆ˜ | : ëˆ„ì ëœ ë³´í—˜ê¸ˆ ì§€ê¸‰ ê±´ìˆ˜\n",
      "ğŸ” [72] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì ì¤‘ë„ë³´í—˜ê¸ˆì§€ê¸‰ê¸ˆì•¡ | : ëˆ„ì ëœ ì¤‘ë„ ë³´í—˜ê¸ˆ ì§€ê¸‰ ì´ ê¸ˆì•¡\n",
      "ğŸ” [73] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì ì¤‘ë„ì¸ì¶œê±´ìˆ˜ | : ëˆ„ì ëœ ì¤‘ë„ ì¸ì¶œ ê±´ìˆ˜\n",
      "ğŸ” [74] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì í•´ì•½í™˜ê¸‰ê¸ˆì§€ê¸‰ê¸ˆì•¡ | : ëˆ„ì ëœ í•´ì•½ í™˜ê¸‰ê¸ˆ ì§€ê¸‰ ì´ ê¸ˆì•¡\n",
      "ğŸ” [75] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì „ì „ì›”ì œì§€ê¸‰ê¸ˆì´ë ¥ì—¬ë¶€ | : ì „ì „ì›”ì— ì§€ê¸‰ê¸ˆ ì´ë ¥ì´ ìˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [76] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì „ì›”ì œì§€ê¸‰ê¸ˆì´ë ¥ì—¬ë¶€ | : ë‹¹ì›” ì§€ê¸‰ê¸ˆ ì´ë ¥ì´ ìˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [77] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ë³´í—˜ë£Œìë™ëŒ€ì¶œì”ì•¡ | : ë‹¹ì›” ë³´í—˜ë£Œ ìë™ ëŒ€ì¶œ ì”ì•¡\n",
      "ğŸ” [78] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ë³´í—˜ê¸ˆì§€ê¸‰ê±´ìˆ˜ | : ë‹¹ì›” ë³´í—˜ê¸ˆ ì§€ê¸‰ ê±´ìˆ˜\n",
      "ğŸ” [79] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ë³´í—˜ê¸ˆì²­êµ¬ê±´ìˆ˜ | : ë‹¹ì›” ë³´í—˜ê¸ˆ ì²­êµ¬ ê±´ìˆ˜\n",
      "ğŸ” [80] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ì¤‘ë„ì¸ì¶œê±´ìˆ˜ | : ë‹¹ì›” ì¤‘ë„ ì¸ì¶œ ê±´ìˆ˜\n",
      "ğŸ” [81] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë‹¹ì›”ì œì§€ê¸‰ê¸ˆì´ë ¥ì—¬ë¶€ | : ë‹¹ì›” ì§€ê¸‰ê¸ˆ ì´ë ¥ì´ ìˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [82] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëˆ„ì ì„±ë¦½ê±´ìˆ˜ | : ëˆ„ì ëœ ê³„ì•½ ì„±ë¦½ ê±´ìˆ˜\n",
      "ğŸ” [83] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìˆ˜ê¸ˆì„¤ê³„ì‚¬ìˆ˜ | : ìˆ˜ê¸ˆì„ ë‹´ë‹¹í•˜ëŠ” ì„¤ê³„ì‚¬ ìˆ˜\n",
      "ğŸ” [84] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìˆ˜ê¸ˆë°©ë²•ë³€ê²½ê±´ìˆ˜ | : ìˆ˜ê¸ˆ ë°©ë²• ë³€ê²½ ê±´ìˆ˜\n",
      "ğŸ” [85] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëª¨ì§‘ì„¤ê³„ì‚¬ìˆ˜ | : ëª¨ì§‘ì„ ë‹´ë‹¹í•˜ëŠ” ì„¤ê³„ì‚¬ ìˆ˜\n",
      "ğŸ” [86] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³´ìœ ê³„ì•½í”¼ë³´í—˜ììˆ˜ | : ë³´ìœ  ê³„ì•½ì˜ í”¼ë³´í—˜ì ìˆ˜\n",
      "ğŸ” [87] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìœ ì§€ê³„ì•½ê±´ìˆ˜ | : ìœ ì§€ ì¤‘ì¸ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [88] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ìµœë¹ˆê°€ì…ì±„ë„ì½”ë“œ | : ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ì‚¬ìš©ëœ ê°€ì… ì±„ë„ ì½”ë“œ\n",
      "ğŸ” [89] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê³„ì•½ë³€ê²½ì‹ ì²­ê±´ìˆ˜ | : ê³ ê°ì˜ ê³„ì•½ ë³€ê²½ ì‹ ì²­ ê±´ìˆ˜\n",
      "ğŸ” [90] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë¶€í™œë³€ê²½ê±´ìˆ˜ | : ë³´í—˜ ê³„ì•½ì˜ ë¶€í™œ(íš¨ë ¥ íšŒë³µ) ê´€ë ¨ ë³€ê²½ ê±´ìˆ˜\n",
      "ğŸ” [91] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê°€ì…íŠ¹ì•½ìˆ˜í•©ê³„ | : ê³ ê°ì´ ê°€ì…í•œ íŠ¹ì•½(ì¶”ê°€ ë³´ì¥)ì˜ ì´ ê°œìˆ˜\n",
      "ğŸ” [92] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ëŒ€ì¶œê°€ëŠ¥ê¸ˆì•¡í•©ê³„ | : ê³ ê°ì´ ëŒ€ì¶œí•  ìˆ˜ ìˆëŠ” ì´ ê¸ˆì•¡\n",
      "ğŸ” [93] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³´í—˜ê³„ì•½ëŒ€ì¶œì”ì•¡í•©ê³„ | : ë³´í—˜ ê³„ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ëŒ€ì¶œì˜ ì”ì•¡ í•©ê³„\n",
      "ğŸ” [94] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê¸°ë‚©ì…ë³´í—˜ë£Œí•©ê³„ | : ê³ ê°ì´ ë‚©ì…í•œ ë³´í—˜ë£Œì˜ ì´ì•¡\n",
      "ğŸ” [95] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë¯¸ë‚©ë³´í—˜ë£Œí•©ê³„ | : ê³ ê°ì´ ë‚©ì…í•˜ì§€ ì•Šì€ ë¯¸ë‚© ë³´í—˜ë£Œì˜ ì´ì•¡\n",
      "ğŸ” [96] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì „ì‚¬ìµœì¢…ê³„ì•½ê²½ê³¼ì›”ìˆ˜ | : íšŒì‚¬ì˜ ë§ˆì§€ë§‰ ê³„ì•½ ì´í›„ ê²½ê³¼í•œ ê°œì›” ìˆ˜\n",
      "ğŸ” [97] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì „ì‚¬ìµœì´ˆê³„ì•½ê²½ê³¼ì›”ìˆ˜ | : íšŒì‚¬ì˜ ìµœì´ˆ ê³„ì•½ ì´í›„ ê²½ê³¼í•œ ê°œì›” ìˆ˜\n",
      "ğŸ” [98] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì—°ê¸ˆëˆ„ì ê°€ì…ê±´ìˆ˜ | : ì—°ê¸ˆ ìƒí’ˆ ëˆ„ì  ê°€ì… ê±´ìˆ˜\n",
      "ğŸ” [99] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì—°ê¸ˆë³´ìœ ì—¬ë¶€ | : ê³ ê°ì´ ì—°ê¸ˆ ìƒí’ˆì„ ë³´ìœ í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [100] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì—°ê¸ˆì‹¤íš¨ê³„ì•½ê±´ìˆ˜ | : íš¨ë ¥ì´ ìƒì‹¤ëœ ì—°ê¸ˆ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [101] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì—°ê¸ˆìµœëŒ€ë‚©ì…íšŒì°¨ | : ì—°ê¸ˆ ìƒí’ˆì˜ ìµœëŒ€ ë‚©ì… íšŒì°¨\n",
      "ğŸ” [102] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì—°ê¸ˆìœ ì§€ê³„ì•½ìˆ˜ | : ìœ ì§€ ì¤‘ì¸ ì—°ê¸ˆ ê³„ì•½ ìˆ˜\n",
      "ğŸ” [103] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì—°ê¸ˆê¸°ë‚©ì…ë³´í—˜ë£Œ | : ì—°ê¸ˆ ìƒí’ˆì— ë‚©ì…ëœ ë³´í—˜ë£Œ ì´ì•¡\n",
      "ğŸ” [104] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì—°ê¸ˆì¸ìˆ˜ê±°ì ˆì—¬ë¶€ | : ì—°ê¸ˆ ìƒí’ˆ ì¸ìˆ˜ê°€ ê±°ì ˆëœ ì—¬ë¶€\n",
      "ğŸ” [105] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê¸°íƒ€ë³´ì¥ëˆ„ì ê°€ì…ê±´ìˆ˜ | : ê¸°íƒ€ ë³´ì¥ ìƒí’ˆì˜ ëˆ„ì  ê°€ì… ê±´ìˆ˜\n",
      "ğŸ” [106] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê¸°íƒ€ë³´ì¥ìœ ì§€ê³„ì•½ìˆ˜ | : ìœ ì§€ ì¤‘ì¸ ê¸°íƒ€ ë³´ì¥ ê³„ì•½ ìˆ˜\n",
      "ğŸ” [107] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì¼ë°˜ì¢…ì‹ ëˆ„ì ê°€ì…ê±´ìˆ˜ | : ì¼ë°˜ ì¢…ì‹  ë³´í—˜ì˜ ëˆ„ì  ê°€ì… ê±´ìˆ˜\n",
      "ğŸ” [108] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì¼ë°˜ì¢…ì‹ ë³´ìœ ì—¬ë¶€ | : ì¼ë°˜ ì¢…ì‹  ë³´í—˜ì„ ë³´ìœ í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [109] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì¼ë°˜ì¢…ì‹ ì‹¤íš¨ê³„ì•½ê±´ìˆ˜ | : íš¨ë ¥ì´ ìƒì‹¤ëœ ì¼ë°˜ ì¢…ì‹  ë³´í—˜ ê³„ì•½ ê±´ìˆ˜\n",
      "ğŸ” [110] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì¼ë°˜ì¢…ì‹ ìµœëŒ€ë‚©ì…íšŒì°¨ | : ì¼ë°˜ ì¢…ì‹  ë³´í—˜ì˜ ìµœëŒ€ ë‚©ì… íšŒì°¨\n",
      "ğŸ” [111] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì¼ë°˜ì¢…ì‹ ìœ ì§€ê³„ì•½ìˆ˜ | : ìœ ì§€ ì¤‘ì¸ ì¼ë°˜ ì¢…ì‹  ë³´í—˜ ê³„ì•½ ìˆ˜\n",
      "ğŸ” [112] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì¼ë°˜ì¢…ì‹ ì¸ìˆ˜ê±°ì ˆì—¬ë¶€ | : ì¼ë°˜ ì¢…ì‹  ë³´í—˜ ì¸ìˆ˜ê°€ ê±°ì ˆëœ ì—¬ë¶€\n",
      "ğŸ” [113] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì €ì¶•CMIP | : ì €ì¶• ìƒí’ˆ ê´€ë ¨ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [114] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì €ì¶•ìµœëŒ€ë‚©ì…íšŒì°¨ | : ì €ì¶• ìƒí’ˆì˜ ìµœëŒ€ ë‚©ì… íšŒì°¨\n",
      "ğŸ” [115] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ì €ì¶•ê°€ì…ë‚©ì…ë³´í—˜ë£Œ | : ì €ì¶• ìƒí’ˆ ê°€ì… ì‹œ ë‚©ì…í•œ ë³´í—˜ë£Œ\n",
      "ğŸ” [116] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ëˆ„ì ê°€ì…ê±´ìˆ˜ | : ë³€ì•¡ ë³´í—˜ì˜ ëˆ„ì  ê°€ì… ê±´ìˆ˜\n",
      "ğŸ” [117] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡CMIP | : ë³€ì•¡ ë³´í—˜ ê´€ë ¨ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [118] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ë³´ìœ ì—¬ë¶€ | : ë³€ì•¡ ë³´í—˜ì„ ë³´ìœ í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [119] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ìµœëŒ€ë‚©ì…íšŒì°¨ | : ë³€ì•¡ ë³´í—˜ì˜ ìµœëŒ€ ë‚©ì… íšŒì°¨\n",
      "ğŸ” [120] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ìœ ì§€ê³„ì•½ìˆ˜ | : ìœ ì§€ ì¤‘ì¸ ë³€ì•¡ ë³´í—˜ ê³„ì•½ ìˆ˜\n",
      "ğŸ” [121] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ê¸°ë‚©ì…ë³´í—˜ë£Œ | : ë³€ì•¡ ë³´í—˜ì— ë‚©ì…ëœ ë³´í—˜ë£Œ ì´ì•¡\n",
      "ğŸ” [122] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ì¢…ì‹ CMIP | : ë³€ì•¡ ì¢…ì‹  ë³´í—˜ ê´€ë ¨ ì›”í™˜ì‚°ë³´í—˜ë£Œ\n",
      "ğŸ” [123] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ì¢…ì‹ ë³´ìœ ì—¬ë¶€ | : ë³€ì•¡ ì¢…ì‹  ë³´í—˜ì„ ë³´ìœ í•˜ê³  ìˆëŠ”ì§€ ì—¬ë¶€\n",
      "ğŸ” [124] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ì¢…ì‹ ìµœëŒ€ë‚©ì…íšŒì°¨ | : ë³€ì•¡ ì¢…ì‹  ë³´í—˜ì˜ ìµœëŒ€ ë‚©ì… íšŒì°¨\n",
      "ğŸ” [125] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ì¢…ì‹ ìœ ì§€ê³„ì•½ìˆ˜ | : ìœ ì§€ ì¤‘ì¸ ë³€ì•¡ ì¢…ì‹  ë³´í—˜ ê³„ì•½ ìˆ˜\n",
      "ğŸ” [126] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ë³€ì•¡ì¢…ì‹ ê¸°ë‚©ì…ë³´í—˜ë£Œ | : ë³€ì•¡ ì¢…ì‹  ë³´í—˜ì— ë‚©ì…ëœ ë³´í—˜ë£Œ ì´ì•¡\n",
      "ğŸ” [127] í…Œì´ë¸”ëª… : cust_intg | ì»¬ëŸ¼ëª… : ê¸°ì¤€ë…„ì›” | : ë‹¹ì›” ì‹ ê·œë¡œ ê°€ì…í•œ ê³ ê° ì—¬ë¶€\n",
      "ğŸ” [128] í…Œì´ë¸”ëª… : product_info | ì»¬ëŸ¼ëª… : íŠ¹ì•½ì½”ë“œ | : ìƒí’ˆì— ëŒ€í•œ íŠ¹ì•½(ì¶”ê°€ ë³´ì¥)ì˜ ê³ ìœ  ì½”ë“œ.\n",
      "ğŸ” [129] í…Œì´ë¸”ëª… : product_info | ì»¬ëŸ¼ëª… : ê°€ì…ì„±ë³„ | : ê°€ì… ê°€ëŠ¥í•œ ì„±ë³„ (ë‚¨/ì—¬/ê³µí†µ).\n",
      "ğŸ” [130] í…Œì´ë¸”ëª… : product_info | ì»¬ëŸ¼ëª… : ê°€ì…ìµœì†Œë‚˜ì´ | : ê°€ì… ê°€ëŠ¥í•œ ìµœì†Œ ë‚˜ì´.\n",
      "ğŸ” [131] í…Œì´ë¸”ëª… : product_info | ì»¬ëŸ¼ëª… : ê°€ì…ìµœëŒ€ë‚˜ì´ | : ê°€ì… ê°€ëŠ¥í•œ ìµœëŒ€ ë‚˜ì´.\n",
      "ğŸ” [132] í…Œì´ë¸”ëª… : product_info | ì»¬ëŸ¼ëª… : ë‹´ë³´ì½”ë“œ | : ìƒí’ˆì˜ ë‹´ë³´(ë³´ì¥ ë‚´ìš©)ë¥¼ êµ¬ë¶„í•˜ëŠ” ì½”ë“œ.\n",
      "ğŸ” [133] í…Œì´ë¸”ëª… : product_info | ì»¬ëŸ¼ëª… : ê°€ì…í•œë„ | : ê°€ì… ê°€ëŠ¥í•œ ìµœëŒ€ ê¸ˆì•¡ ë˜ëŠ” ë³´ì¥ í•œë„.\n",
      "âœ… í†µí•©ëœ ê²°ê³¼ê°€ output/stage1/integrated_column_descriptions.xlsxì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "# âœ… LangGraph ë° LangChain ê´€ë ¨ ëª¨ë“ˆ\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# âœ… AI Assistant LangGraph Class Import\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "\n",
    "\n",
    "# âœ… OpenAI API Key í™•ì¸\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key, temperature=0,)\n",
    "\n",
    "# llm ê²°ê³¼ ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ê°€ ë‹´ê¸¸ ê°ì²´ dict ì„ ì–¸\n",
    "results = {}\n",
    "list_df = {}\n",
    "\n",
    "# ../data ê²½ë¡œì˜ ëª¨ë“  pkl íŒŒì¼ ì½ê¸°\n",
    "data_path = os.path.join('..', 'data')\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        df_name = file.replace('.pkl', '')\n",
    "        list_df[df_name] = pd.read_pickle(file_path)\n",
    "\n",
    "list_df_text = \", \".join(list_df)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "\n",
    "# LLMì— ì²« ë²ˆì§¸ ì½”ë“œ ìš”ì²­\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"### ì°¸ê³  ì½”ë“œ:\\n{func_code}\\n\\n\"),\n",
    "            (\"user\", \"### list_df:\\n{list_df}\\n\\n\")\n",
    "        ]) | llm\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df\": list_df_text}).content\n",
    "\n",
    "attempt_count = 0  # ì‹¤í–‰ ì‹œë„ íšŸìˆ˜\n",
    "success = False  # ì½”ë“œ ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¡œë“œ ì™„ë£Œ\n",
      "\n",
      "ğŸ¤– LLMì— ì½”ë“œ ìƒì„± ìš”ì²­ ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "print(\"âœ… í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¡œë“œ ì™„ë£Œ\\n\")\n",
    "\n",
    "print(\"ğŸ¤– LLMì— ì½”ë“œ ìƒì„± ìš”ì²­ ì¤‘...\")\n",
    "\n",
    "# âœ… LLMì— ì²« ë²ˆì§¸ ì½”ë“œ ìš”ì²­\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"### ì°¸ê³  ì½”ë“œ:\\n{func_code}\\n\\n\"),\n",
    "    (\"user\", \"### list_df:\\n{list_df}\\n\\n\")\n",
    "]) | llm\n",
    "\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df\": list_df_text}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] ì‹¤í–‰í•  ì½”ë“œ:\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def summarize_data(df, df_name):\n",
      "    \"\"\"\n",
      "    ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„(df)ì— ëŒ€í•œ EDA(íƒìƒ‰ì  ë°ì´í„° ë¶„ì„) ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
      "    - \"ì»¬ëŸ¼ ê°œìš”\"ì— ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬ ì •ë³´ í¬í•¨\n",
      "    - ì—°ì†í˜• ë³€ìˆ˜ì˜ ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ) ì œì™¸ (í† í° ìˆ˜ ì ˆê° ëª©ì )\n",
      "    \"\"\"\n",
      "\n",
      "    # âœ… 1. ì´ìƒì¹˜ íƒì§€ (IQR ë°©ì‹)\n",
      "    outliers_info = {}\n",
      "    for col in df.select_dtypes(include=[np.number]).columns:\n",
      "        Q1 = df[col].quantile(0.25)\n",
      "        Q3 = df[col].quantile(0.75)\n",
      "        IQR = Q3 - Q1\n",
      "        lower_bound = Q1 - 1.5 * IQR\n",
      "        upper_bound = Q3 + 1.5 * IQR\n",
      "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
      "\n",
      "        if outlier_count > 0:\n",
      "            outliers_info[col] = int(outlier_count)\n",
      "\n",
      "    # âœ… 2. ì»¬ëŸ¼ ê°œìš” (ê¸°ë³¸ í†µê³„ ë° ê²°ì¸¡ ì •ë³´ + ì¸ìŠ¤í„´ìŠ¤ ì˜ˆì œ + ë²”ì£¼í˜• ë¶„í¬ ì¶”ê°€)\n",
      "    columns_info = []\n",
      "    for col in df.columns:\n",
      "        col_dtype = df[col].dtype\n",
      "\n",
      "        col_info = {\n",
      "            \"ë°ì´í„°í”„ë ˆì„ëª…\": df_name,\n",
      "            \"ì»¬ëŸ¼ëª…\": col,\n",
      "            \"ë°ì´í„° íƒ€ì…\": col_dtype,\n",
      "            \"count\": df[col].count(),\n",
      "            \"mean\": round(df[col].mean(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"std\": round(df[col].std(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"min\": round(df[col].min(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"25%\": round(df[col].quantile(0.25), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"75%\": round(df[col].quantile(0.75), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"max\": round(df[col].max(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"ê²°ì¸¡ ê°œìˆ˜\": df[col].isnull().sum(),\n",
      "            \"ê²°ì¸¡ì¹˜ ë¹„ìœ¨\": round(df[col].isnull().sum() / len(df) * 100, 0),\n",
      "            \"ê³ ìœ ê°’ ê°œìˆ˜\": df[col].nunique(),\n",
      "        }\n",
      "\n",
      "        # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ë§Œ ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ) í¬í•¨ (ì—°ì†í˜• ë³€ìˆ˜ ì œì™¸í•˜ì—¬ í† í° ìˆ˜ ì ˆê°)\n",
      "        if col_dtype in [\"object\", \"category\"]:\n",
      "            unique_vals = df[col].dropna().unique()\n",
      "            # ìœ ë‹ˆí¬ ê°’ ìƒ˜í”Œë§ (20ê°œ ì´ìƒì´ë©´ 10ê°œë§Œ ì¶œë ¥ + '...')\n",
      "            if len(unique_vals) > 20:\n",
      "                sample_display = list(unique_vals[:10]) + ['...']\n",
      "            else:\n",
      "                sample_display = unique_vals.tolist()\n",
      "            col_info[\"ì¸ìŠ¤í„´ìŠ¤(ì˜ˆì œ)\"] = sample_display\n",
      "\n",
      "            # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ì¼ ê²½ìš°, ë¶„í¬ ì •ë³´ ì¶”ê°€ (ìµœëŒ€ 10ê°œë§Œ ì €ì¥í•˜ì—¬ í† í° ì ˆê°)\n",
      "            value_counts = df[col].value_counts(normalize=True) * 100\n",
      "            value_counts = value_counts[:10]  # ìµœëŒ€ 10ê°œë§Œ ìœ ì§€\n",
      "            category_distribution = {val: round(pct, 2) for val, pct in value_counts.items()}\n",
      "            col_info[\"ë²”ì£¼í˜• ë¶„í¬\"] = category_distribution\n",
      "\n",
      "        columns_info.append(col_info)\n",
      "\n",
      "    columns_info_df = pd.DataFrame(columns_info)\n",
      "\n",
      "    return columns_info_df\n",
      "\n",
      "# ë‹¤ì¤‘ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ ë° ê²°ê³¼ ì €ì¥\n",
      "def analyze_multiple_dataframes(dataframe_list):\n",
      "    result_tmp = {\"ë°ì´í„° ê°œìš”\": []}\n",
      "\n",
      "    for df_name in dataframe_list:\n",
      "        df = globals().get(df_name)\n",
      "\n",
      "        if df is not None:\n",
      "            rslt1 = summarize_data(df, df_name)\n",
      "            rslt2 = summarize_data(df, df_name)  # ì˜ˆì‹œë¡œ ë™ì¼í•œ í•¨ìˆ˜ í˜¸ì¶œ, ì‹¤ì œë¡œëŠ” ë‹¤ë¥¸ ë¶„ì„ í•¨ìˆ˜ ì‚¬ìš©\n",
      "            rslt3 = summarize_data(df, df_name)  # ì˜ˆì‹œë¡œ ë™ì¼í•œ í•¨ìˆ˜ í˜¸ì¶œ, ì‹¤ì œë¡œëŠ” ë‹¤ë¥¸ ë¶„ì„ í•¨ìˆ˜ ì‚¬ìš©\n",
      "\n",
      "            result_tmp[f\"{df_name}_rslt1\"] = rslt1\n",
      "            result_tmp[f\"{df_name}_rslt2\"] = rslt2\n",
      "            result_tmp[f\"{df_name}_rslt3\"] = rslt3\n",
      "\n",
      "    # ê²°ê³¼ ì €ì¥ (ì—‘ì…€ í˜•ì‹)\n",
      "    output_path = \"../output/stage1/eda_summary.xlsx\"\n",
      "    with pd.ExcelWriter(output_path) as writer:\n",
      "        for sheet_name, df in result_tmp.items():\n",
      "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
      "\n",
      "    return result_tmp\n",
      "\n",
      "# ë°ì´í„°í”„ë ˆì„ ëª©ë¡\n",
      "dataframe_list = ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "analyze_multiple_dataframes(dataframe_list)\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "At least one sheet must be visible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<string>:88\u001b[0m, in \u001b[0;36manalyze_multiple_dataframes\u001b[1;34m(dataframe_list)\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_excel'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m modified_code \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```python\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LOG] ì‹¤í–‰í•  ì½”ë“œ:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodified_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m exec(modified_code, \u001b[38;5;28mglobals\u001b[39m())\n",
      "File \u001b[1;32m<string>:94\u001b[0m\n",
      "File \u001b[1;32m<string>:86\u001b[0m, in \u001b[0;36manalyze_multiple_dataframes\u001b[1;34m(dataframe_list)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1476\u001b[0m, in \u001b[0;36mExcelWriter.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1480\u001b[0m, in \u001b[0;36mExcelWriter.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"synonym for save, to make it more file-like\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n\u001b[0;32m   1481\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:109\u001b[0m, in \u001b[0;36mOpenpyxlWriter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    Save workbook to disk.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, mmap\u001b[38;5;241m.\u001b[39mmmap):\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;66;03m# truncate file to the written content\u001b[39;00m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mtruncate()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\workbook\\workbook.py:386\u001b[0m, in \u001b[0;36mWorkbook.save\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworksheets:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_sheet()\n\u001b[1;32m--> 386\u001b[0m save_workbook(\u001b[38;5;28mself\u001b[39m, filename)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\writer\\excel.py:294\u001b[0m, in \u001b[0;36msave_workbook\u001b[1;34m(workbook, filename)\u001b[0m\n\u001b[0;32m    292\u001b[0m workbook\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mmodified \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mutcnow()\n\u001b[0;32m    293\u001b[0m writer \u001b[38;5;241m=\u001b[39m ExcelWriter(workbook, archive)\n\u001b[1;32m--> 294\u001b[0m writer\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\writer\\excel.py:275\u001b[0m, in \u001b[0;36mExcelWriter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write data into the archive.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_data()\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_archive\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\writer\\excel.py:89\u001b[0m, in \u001b[0;36mExcelWriter.write_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m writer \u001b[38;5;241m=\u001b[39m WorkbookWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkbook)\n\u001b[0;32m     88\u001b[0m archive\u001b[38;5;241m.\u001b[39mwritestr(ARC_ROOT_RELS, writer\u001b[38;5;241m.\u001b[39mwrite_root_rels())\n\u001b[1;32m---> 89\u001b[0m archive\u001b[38;5;241m.\u001b[39mwritestr(ARC_WORKBOOK, writer\u001b[38;5;241m.\u001b[39mwrite())\n\u001b[0;32m     90\u001b[0m archive\u001b[38;5;241m.\u001b[39mwritestr(ARC_WORKBOOK_RELS, writer\u001b[38;5;241m.\u001b[39mwrite_rels())\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_vba()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\workbook\\_writer.py:150\u001b[0m, in \u001b[0;36mWorkbookWriter.write\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_names()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_pivots()\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_views()\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_refs()\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tostring(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpackage\u001b[38;5;241m.\u001b[39mto_tree())\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\workbook\\_writer.py:137\u001b[0m, in \u001b[0;36mWorkbookWriter.write_views\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_views\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 137\u001b[0m     active \u001b[38;5;241m=\u001b[39m get_active_sheet(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwb)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwb\u001b[38;5;241m.\u001b[39mviews:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwb\u001b[38;5;241m.\u001b[39mviews[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mactiveTab \u001b[38;5;241m=\u001b[39m active\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\workbook\\_writer.py:35\u001b[0m, in \u001b[0;36mget_active_sheet\u001b[1;34m(wb)\u001b[0m\n\u001b[0;32m     33\u001b[0m visible_sheets \u001b[38;5;241m=\u001b[39m [idx \u001b[38;5;28;01mfor\u001b[39;00m idx, sheet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(wb\u001b[38;5;241m.\u001b[39m_sheets) \u001b[38;5;28;01mif\u001b[39;00m sheet\u001b[38;5;241m.\u001b[39msheet_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisible\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m visible_sheets:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one sheet must be visible\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m idx \u001b[38;5;241m=\u001b[39m wb\u001b[38;5;241m.\u001b[39m_active_sheet_index\n\u001b[0;32m     38\u001b[0m sheet \u001b[38;5;241m=\u001b[39m wb\u001b[38;5;241m.\u001b[39mactive\n",
      "\u001b[1;31mIndexError\u001b[0m: At least one sheet must be visible"
     ]
    }
   ],
   "source": [
    "modified_code = response.split(\"```python\")[-1].split(\"```\")[0]\n",
    "print(f\"[LOG] ì‹¤í–‰í•  ì½”ë“œ:\\n{modified_code}\")\n",
    "exec(modified_code, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ë°ì´í„° ë¡œë“œ ì‹œì‘...\n",
      "âœ… 'cust_enroll_history' ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n",
      "âœ… 'cust_intg' ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n",
      "âœ… 'product_info' ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ“Š ì´ 3 ê°œì˜ ë°ì´í„°í”„ë ˆì„ ë¡œë“œ ì™„ë£Œ\n",
      "\n",
      "âœ… í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¡œë“œ ì™„ë£Œ\n",
      "\n",
      "ğŸ¤– LLMì— ì½”ë“œ ìƒì„± ìš”ì²­ ì¤‘...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'list_df_text'}.  Expected: ['func_code', 'list_df_text'] Received: ['func_code', 'list_df']\\nNote: if you intended {list_df_text} to be part of the string and not a variable, please escape it with double curly braces like: '{{list_df_text}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# âœ… LLMì— ì²« ë²ˆì§¸ ì½”ë“œ ìš”ì²­\u001b[39;00m\n\u001b[0;32m     64\u001b[0m chain \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m     65\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, prompt),\n\u001b[0;32m     66\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### ì°¸ê³  ì½”ë“œ:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{func_code}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     67\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### list_df:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{list_df_text}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m ]) \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m---> 70\u001b[0m response \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: func_code, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_df\u001b[39m\u001b[38;5;124m\"\u001b[39m: list_df_text})\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     72\u001b[0m attempt_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     73\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3014\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3012\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3014\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3016\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:210\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    209\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_prompt_with_error_handling,\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    213\u001b[0m     config,\n\u001b[0;32m    214\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m     serialized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m    216\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1914\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1910\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1911\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1912\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1913\u001b[0m         Output,\n\u001b[1;32m-> 1914\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1915\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1916\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1918\u001b[0m             config,\n\u001b[0;32m   1919\u001b[0m             run_manager,\n\u001b[0;32m   1920\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1921\u001b[0m         ),\n\u001b[0;32m   1922\u001b[0m     )\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1924\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:184\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 184\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:178\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    172\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    173\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m     )\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'list_df_text'}.  Expected: ['func_code', 'list_df_text'] Received: ['func_code', 'list_df']\\nNote: if you intended {list_df_text} to be part of the string and not a variable, please escape it with double curly braces like: '{{list_df_text}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import traceback\n",
    "import json\n",
    "\n",
    "# âœ… LangGraph ë° LangChain ê´€ë ¨ ëª¨ë“ˆ\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# âœ… í™˜ê²½ ì„¤ì •\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "# âœ… OpenAI API Key í™•ì¸\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_api_key, temperature=0)\n",
    "\n",
    "# âœ… ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ê°ì²´ ì„ ì–¸\n",
    "results = {}\n",
    "list_df = {}\n",
    "\n",
    "print(\"ğŸ”„ ë°ì´í„° ë¡œë“œ ì‹œì‘...\")\n",
    "# âœ… ë°ì´í„° ë¡œë“œ: ../data ê²½ë¡œì˜ ëª¨ë“  pkl íŒŒì¼ ì½ê¸°\n",
    "data_path = os.path.join('..', 'data')\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        df_name = file.replace('.pkl', '')\n",
    "        list_df[df_name] = pd.read_pickle(file_path)\n",
    "        print(f\"âœ… '{df_name}' ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "list_df_text = \", \".join(list_df.keys())\n",
    "print(f\"ğŸ“Š ì´ {len(list_df)} ê°œì˜ ë°ì´í„°í”„ë ˆì„ ë¡œë“œ ì™„ë£Œ\\n\")\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "print(\"âœ… í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¡œë“œ ì™„ë£Œ\\n\")\n",
    "\n",
    "def get_detailed_error_info(e):\n",
    "    \"\"\"ì—ëŸ¬ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    error_type = type(e).__name__\n",
    "    error_msg = str(e)\n",
    "    error_traceback = traceback.format_exc()\n",
    "    \n",
    "    return {\n",
    "        \"error_type\": error_type,\n",
    "        \"error_message\": error_msg,\n",
    "        \"traceback\": error_traceback,\n",
    "        \"context\": {\n",
    "            \"locals\": str(locals()),\n",
    "            \"globals\": str([k for k in globals().keys() if not k.startswith('_')])\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"ğŸ¤– LLMì— ì½”ë“œ ìƒì„± ìš”ì²­ ì¤‘...\")\n",
    "\n",
    "# âœ… LLMì— ì²« ë²ˆì§¸ ì½”ë“œ ìš”ì²­\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"### ì°¸ê³  ì½”ë“œ:\\n{func_code}\\n\\n\"),\n",
    "    (\"user\", \"### list_df:\\n{list_df_text}\\n\\n\")\n",
    "]) | llm\n",
    "\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df_text\": list_df_text}).content\n",
    "\n",
    "attempt_count = 0\n",
    "success = False\n",
    "\n",
    "while attempt_count < 2:\n",
    "    try:\n",
    "        if \"```python\" in response:\n",
    "            modified_code = response.split(\"```python\")[-1].split(\"```\")[0]\n",
    "            print(f\"[LOG] ì‹¤í–‰í•  ì½”ë“œ:\\n{modified_code}\")\n",
    "            exec(modified_code, globals())\n",
    "            print(f\"[Stage 1. ë°ì´í„° êµ¬ì¡° íŒŒì•…] {attempt_count+1}ì°¨ ì‹œë„ | âœ… ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            success = True\n",
    "            break\n",
    "    except Exception as e:\n",
    "        error_info = get_detailed_error_info(e)\n",
    "        print(f\"\\nâŒ {attempt_count+1}ì°¨ ì‹œë„ ì‹¤í–‰ ì‹¤íŒ¨\")\n",
    "        print(f\"ğŸ” ì—ëŸ¬ íƒ€ì…: {error_info['error_type']}\")\n",
    "        print(f\"ğŸ“ ì—ëŸ¬ ë©”ì‹œì§€: {error_info['error_message']}\")\n",
    "        print(\"\\nğŸ” ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\")\n",
    "        print(error_info['traceback'])\n",
    "\n",
    "        if attempt_count == 0:\n",
    "            print(\"\\nğŸ”„ ì—ëŸ¬ ë¶„ì„ ë° ì½”ë“œ ìˆ˜ì • ìš”ì²­ ì¤‘...\")\n",
    "            \n",
    "            # âœ… ì—ëŸ¬ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "            ERROR_ANALYSIS_PROMPT = open(f'prompt/99.prompt_error_python.txt', 'r', encoding='utf-8').read().format(\n",
    "                error_type= error_info['error_type'],\n",
    "                error_message = error_info['error_message'],\n",
    "                traceback = error_info['traceback'],\n",
    "                context = error_info['context']\n",
    "            )\n",
    "            \n",
    "            # ì—ëŸ¬ ë¶„ì„ ì „ë¬¸ í”„ë¡¬í”„íŠ¸ë¡œ ìš”ì²­\n",
    "            chain_error_analysis = ChatPromptTemplate.from_template(ERROR_ANALYSIS_PROMPT) | llm\n",
    "            \n",
    "            error_analysis_response = chain_error_analysis.invoke({\n",
    "                \n",
    "            })\n",
    "            \n",
    "            response = error_analysis_response.content\n",
    "            print(\"\\nâœï¸ LLMì˜ ì—ëŸ¬ ë¶„ì„ ë° ìˆ˜ì • ì œì•ˆ:\")\n",
    "            print(response)\n",
    "        else:\n",
    "            print(\"\\nâŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "        attempt_count += 1\n",
    "\n",
    "# âœ… Stage 1 ê²°ê³¼ íŒŒì¼ ë¡œë“œ (ì—‘ì…€)\n",
    "print(\"\\nğŸ”„ Stage 1 ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì¤‘...\")\n",
    "stage1_path = \"../output/stage1/eda_summary.xlsx\"\n",
    "if os.path.exists(stage1_path):\n",
    "    stage1_results = pd.read_excel(stage1_path, sheet_name=0)\n",
    "    results[\"stage1\"] = stage1_results\n",
    "    print(f\"âœ… Stage 1 ê²°ê³¼ ë¡œë“œ ì™„ë£Œ (ì´ {len(stage1_results)} ê°œ í–‰)\")\n",
    "else:\n",
    "    print(\"âŒ Stage 1 ê²°ê³¼ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    raise FileNotFoundError(\"Stage 1 ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# âœ… RAG ê¸°ë°˜ ì»¬ëŸ¼ ì„¤ëª… ì¶”ê°€\n",
    "def load_vectorstore():\n",
    "    if os.path.exists(\"./vectordb\"):\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        try:\n",
    "            return FAISS.load_local(\"./vectordb\", embeddings, allow_dangerous_deserialization=True)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "print(\"\\nğŸ”„ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...\")\n",
    "vectorstore = load_vectorstore()\n",
    "if vectorstore:\n",
    "    print(\"âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "\n",
    "def search_column_descriptions(col_desc_df, vectorstore):\n",
    "    \"\"\"RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¬ëŸ¼ ì„¤ëª…ì„ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    data = []\n",
    "    df_after_llm = col_desc_df[['ë°ì´í„°í”„ë ˆì„ëª…', 'ì»¬ëŸ¼ëª…']]\n",
    "    \n",
    "    for i, row in df_after_llm.iterrows():\n",
    "        table_name = row['ë°ì´í„°í”„ë ˆì„ëª…']\n",
    "        col = row['ì»¬ëŸ¼ëª…']\n",
    "        \n",
    "        search_query = f\"í…Œì´ë¸”ëª… : {table_name} | ì»¬ëŸ¼ëª… : {col}\"\n",
    "        docs = vectorstore.similarity_search(search_query, k=1)\n",
    "        \n",
    "        if docs:\n",
    "            best_match = docs[0].page_content\n",
    "            data.append({\n",
    "                'ë°ì´í„°í”„ë ˆì„ëª…': table_name,\n",
    "                'ì»¬ëŸ¼ëª…': col,\n",
    "                'ì»¬ëŸ¼ì„¤ëª…': best_match.split('\\n')[3].split('ì„¤ëª…')[1].strip()\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                'ë°ì´í„°í”„ë ˆì„ëª…': table_name,\n",
    "                'ì»¬ëŸ¼ëª…': col,\n",
    "                'ì»¬ëŸ¼ì„¤ëª…': \"ì„¤ëª… ì—†ìŒ\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "print(\"\\nğŸ”„ RAG ê¸°ë°˜ ì»¬ëŸ¼ ì„¤ëª… ê²€ìƒ‰ ì‹œì‘...\")\n",
    "# âœ… Stage 2: RAG ê¸°ë°˜ ì»¬ëŸ¼ ì„¤ëª… ì¶”ê°€\n",
    "rag_results = search_column_descriptions(stage1_results, vectorstore)\n",
    "print(f\"âœ… RAG ê²€ìƒ‰ ì™„ë£Œ (ì´ {len(rag_results)} ê°œ ì»¬ëŸ¼ì— ëŒ€í•œ ì„¤ëª… ì¶”ê°€)\")\n",
    "\n",
    "print(\"\\nğŸ”„ ìµœì¢… ê²°ê³¼ í†µí•© ì¤‘...\")\n",
    "# âœ… Stage 1 ê²°ê³¼ì™€ RAG ê²°ê³¼ë¥¼ í†µí•©\n",
    "final_df = pd.merge(\n",
    "    stage1_results,\n",
    "    rag_results,\n",
    "    on=['ë°ì´í„°í”„ë ˆì„ëª…', 'ì»¬ëŸ¼ëª…'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# âœ… ìµœì¢… ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ ë‚´ ì €ì¥\n",
    "results[\"stage2\"] = final_df\n",
    "print(f\"âœ… ìµœì¢… ê²°ê³¼ í†µí•© ì™„ë£Œ (ì´ {len(final_df)} ê°œ í–‰)\")\n",
    "\n",
    "print(\"\\nâœ¨ ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
