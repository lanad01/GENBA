{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 실행할 코드:\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def summarize_data(df, df_name):\n",
      "    \"\"\"\n",
      "    주어진 데이터프레임(df)에 대한 EDA(탐색적 데이터 분석) 결과를 정리하여 반환하는 함수.\n",
      "    - \"컬럼 개요\"에 범주형 변수 분포 정보 포함\n",
      "    - 연속형 변수의 인스턴스(예제) 제외 (토큰 수 절감 목적)\n",
      "    \"\"\"\n",
      "\n",
      "    # ✅ 1. 이상치 탐지 (IQR 방식)\n",
      "    outliers_info = {}\n",
      "    for col in df.select_dtypes(include=[np.number]).columns:\n",
      "        Q1 = df[col].quantile(0.25)\n",
      "        Q3 = df[col].quantile(0.75)\n",
      "        IQR = Q3 - Q1\n",
      "        lower_bound = Q1 - 1.5 * IQR\n",
      "        upper_bound = Q3 + 1.5 * IQR\n",
      "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
      "\n",
      "        if outlier_count > 0:\n",
      "            outliers_info[col] = int(outlier_count)\n",
      "\n",
      "    # ✅ 2. 컬럼 개요 (기본 통계 및 결측 정보 + 인스턴스 예제 + 범주형 분포 추가)\n",
      "    columns_info = []\n",
      "    for col in df.columns:\n",
      "        col_dtype = df[col].dtype\n",
      "\n",
      "        col_info = {\n",
      "            \"데이터프레임명\": df_name,\n",
      "            \"컬럼명\": col,\n",
      "            \"데이터 타입\": col_dtype,\n",
      "            \"count\": df[col].count(),\n",
      "            \"mean\": round(df[col].mean(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"std\": round(df[col].std(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"min\": round(df[col].min(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"25%\": round(df[col].quantile(0.25), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"75%\": round(df[col].quantile(0.75), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"max\": round(df[col].max(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"결측 개수\": df[col].isnull().sum(),\n",
      "            \"결측치 비율\": round(df[col].isnull().sum() / len(df) * 100, 0),\n",
      "            \"고유값 개수\": df[col].nunique(),\n",
      "        }\n",
      "\n",
      "        # ✅ 범주형 변수만 인스턴스(예제) 포함 (연속형 변수 제외하여 토큰 수 절감)\n",
      "        if col_dtype in [\"object\", \"category\"]:\n",
      "            unique_vals = df[col].dropna().unique()\n",
      "            # 유니크 값 샘플링 (20개 이상이면 10개만 출력 + '...')\n",
      "            if len(unique_vals) > 20:\n",
      "                sample_display = list(unique_vals[:10]) + ['...']\n",
      "            else:\n",
      "                sample_display = unique_vals.tolist()\n",
      "            col_info[\"인스턴스(예제)\"] = sample_display\n",
      "\n",
      "            # ✅ 범주형 변수일 경우, 분포 정보 추가 (최대 10개만 저장하여 토큰 절감)\n",
      "            value_counts = df[col].value_counts(normalize=True) * 100\n",
      "            value_counts = value_counts[:10]  # 최대 10개만 유지\n",
      "            category_distribution = {val: round(pct, 2) for val, pct in value_counts.items()}\n",
      "            col_info[\"범주형 분포\"] = category_distribution\n",
      "\n",
      "        columns_info.append(col_info)\n",
      "\n",
      "    columns_info_df = pd.DataFrame(columns_info)\n",
      "\n",
      "    return columns_info_df\n",
      "\n",
      "# 다중 데이터프레임 처리 및 결과 저장\n",
      "def analyze_multiple_dataframes(dataframe_list):\n",
      "    result_tmp = {\"데이터 개요\": []}\n",
      "\n",
      "    for df_name in dataframe_list:\n",
      "        df = globals().get(df_name)\n",
      "\n",
      "        if df is not None:\n",
      "            rslt = summarize_data(df, df_name)\n",
      "            result_tmp[\"데이터 개요\"].append(rslt)\n",
      "\n",
      "    # 결과 데이터프레임 병합\n",
      "    for key in result_tmp.keys():\n",
      "        result_tmp[key] = pd.concat(result_tmp[key], ignore_index=True)\n",
      "\n",
      "    # 결과 저장 (엑셀 형식)\n",
      "    output_path = \"../output/stage1/eda_summary.xlsx\"\n",
      "    with pd.ExcelWriter(output_path) as writer:\n",
      "        for sheet_name, df in result_tmp.items():\n",
      "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
      "\n",
      "    return result_tmp\n",
      "\n",
      "# 데이터프레임 목록\n",
      "dataframe_list = ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "\n",
      "# 분석 실행\n",
      "analyze_multiple_dataframes(dataframe_list)\n",
      "\n",
      "[Stage 1. 데이터 구조 파악] 1차 시도 | ✅ 성공적으로 실행되었습니다!\n",
      "✅ 모든 단계가 성공적으로 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import traceback  # 상세 에러 메시지 출력을 위해 추가\n",
    "\n",
    "# ✅ 환경 변수 로드 및 설정\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "# ✅ 결과 저장을 위한 객체 선언\n",
    "results = {}\n",
    "list_df = {}\n",
    "\n",
    "# ✅ 데이터 로드: ../data 경로의 모든 pkl 파일 읽기\n",
    "data_path = os.path.join('..', 'data')\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        df_name = file.replace('.pkl', '')\n",
    "        list_df[df_name] = pd.read_pickle(file_path)\n",
    "\n",
    "# ✅ globals()에 데이터프레임 등록 (해결책 1)\n",
    "for name, df in list_df.items():\n",
    "    globals()[name] = df  # ✅ `analyze_multiple_dataframes`에서 접근 가능하도록 등록\n",
    "\n",
    "list_df_text = \", \".join(list_df.keys())\n",
    "\n",
    "# ✅ 프롬프트 및 함수 코드 불러오기\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "\n",
    "# ✅ LLM에 첫 번째 코드 요청 (데이터 구조 분석 단계)\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"### 참고 코드:\\n{func_code}\\n\\n\"),\n",
    "    (\"user\", \"### list_df:\\n{list_df_text}\\n\\n\")\n",
    "]) | llm\n",
    "\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df_text\": list_df_text}).content\n",
    "\n",
    "attempt_count = 0  # 실행 시도 횟수\n",
    "success = False  # 코드 실행 성공 여부\n",
    "\n",
    "while attempt_count < 2:  # 최초 실행 + 1회 재시도 가능\n",
    "    try:\n",
    "        if \"```python\" in response:\n",
    "            modified_code = response.split(\"```python\")[-1].split(\"```\")[0]\n",
    "            print(f\"[LOG] 실행할 코드:\\n{modified_code}\")\n",
    "            exec(modified_code, globals())  # ✅ LLM이 생성한 코드 실행\n",
    "            print(f\"[Stage 1. 데이터 구조 파악] 1차 시도 | ✅ 성공적으로 실행되었습니다!\")\n",
    "            success = True\n",
    "            break  # 실행 성공 시 루프 종료\n",
    "    except Exception as e:\n",
    "        error_trace = traceback.format_exc()  # ✅ 에러 상세 정보 수집\n",
    "        print(f\"❌ {attempt_count+1}차 시도 : LLM 생성 코드 실행 중 오류 발생\\n{error_trace}\")\n",
    "\n",
    "        if attempt_count == 0:  # 최초 실행 실패 시 1회만 재생성\n",
    "            print(\"🔄 오류 메시지를 기반으로 코드 수정 요청 중...\")\n",
    "\n",
    "            # ✅ LLM에 더 명확한 오류 메시지 전달 (해결책 2)\n",
    "            prompt_error_fix = f\"\"\"\n",
    "            ### 코드 수정 요청\n",
    "\n",
    "            이전 코드 실행 중 다음 오류가 발생했습니다:\n",
    "            ```\n",
    "            {error_trace}\n",
    "            ```\n",
    "\n",
    "            위 오류를 해결한 새로운 코드를 생성하세요.\n",
    "            - 기존 코드에서 오류를 수정한 버전으로 제공해야 합니다.\n",
    "            - 오류 원인을 분석하여 반드시 실행 가능하도록 보완해야 합니다.\n",
    "            - 필요한 경우, 추가적인 데이터 핸들링 코드를 포함해야 합니다.\n",
    "\n",
    "            ```python\n",
    "            # 필요한 코드 삽입\n",
    "            ```\n",
    "            \"\"\"\n",
    "            chain_error_fix = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", prompt_error_fix),\n",
    "                (\"user\", \"### 기존 코드:\\n{modified_code}\\n\\n\")\n",
    "            ]) | llm\n",
    "\n",
    "            response = chain_error_fix.invoke({\"modified_code\": modified_code}).content\n",
    "        else:\n",
    "            print(\"❌ 코드 실행 최종적으로 실패. 프로세스를 중단합니다.\")\n",
    "\n",
    "        attempt_count += 1  # 재시도 횟수 증가\n",
    "\n",
    "# ✅ Stage 1 결과 파일 로드 (엑셀)\n",
    "stage1_path = \"../output/stage1/eda_summary.xlsx\"\n",
    "if os.path.exists(stage1_path):\n",
    "    stage1_results = pd.read_excel(stage1_path, sheet_name=0)  # 첫 번째 시트 사용\n",
    "    results[\"stage1\"] = stage1_results  # ✅ Stage 1 결과 저장\n",
    "else:\n",
    "    print(\"❌ Stage 1 결과 파일이 존재하지 않습니다.\")\n",
    "    raise FileNotFoundError(\"Stage 1 결과 파일을 찾을 수 없습니다.\")\n",
    "\n",
    "# ✅ RAG 기반 컬럼 설명 추가\n",
    "def load_vectorstore():\n",
    "    if os.path.exists(\"./vectordb\"):\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        try:\n",
    "            return FAISS.load_local(\"./vectordb\", embeddings, allow_dangerous_deserialization=True)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 벡터스토어 로드 중 오류 발생: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "vectorstore = load_vectorstore()\n",
    "\n",
    "def search_column_descriptions(col_desc_df, vectorstore):\n",
    "    \"\"\"RAG를 사용하여 컬럼 설명을 검색하는 함수\"\"\"\n",
    "    data = []\n",
    "    df_after_llm = col_desc_df[['데이터프레임명', '컬럼명']]\n",
    "    \n",
    "    for i, row in df_after_llm.iterrows():\n",
    "        table_name = row['데이터프레임명']\n",
    "        col = row['컬럼명']\n",
    "        \n",
    "        search_query = f\"테이블명 : {table_name} | 컬럼명 : {col}\"\n",
    "        docs = vectorstore.similarity_search(search_query, k=1)\n",
    "        \n",
    "        if docs:\n",
    "            best_match = docs[0].page_content\n",
    "            data.append({\n",
    "                '데이터프레임명': table_name,\n",
    "                '컬럼명': col,\n",
    "                '컬럼설명': best_match.split('\\n')[3].split('설명')[1].strip()\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                '데이터프레임명': table_name,\n",
    "                '컬럼명': col,\n",
    "                '컬럼설명': \"설명 없음\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# ✅ Stage 2: RAG 기반 컬럼 설명 추가\n",
    "rag_results = search_column_descriptions(stage1_results, vectorstore)\n",
    "\n",
    "# ✅ Stage 1 결과와 RAG 결과를 통합\n",
    "final_df = pd.merge(\n",
    "    stage1_results,  # Stage 1 결과 (데이터 구조 정보)\n",
    "    rag_results,     # RAG 검색 결과 (컬럼 설명)\n",
    "    on=['데이터프레임명', '컬럼명'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ✅ 최종 결과를 메모리 내 저장\n",
    "results[\"stage2\"] = final_df\n",
    "\n",
    "print(\"✅ 모든 단계가 성공적으로 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 실행할 코드:\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def summarize_data(df, df_name):\n",
      "    \"\"\"\n",
      "    주어진 데이터프레임(df)에 대한 EDA(탐색적 데이터 분석) 결과를 정리하여 반환하는 함수.\n",
      "    - \"컬럼 개요\"에 범주형 변수 분포 정보 포함\n",
      "    - 연속형 변수의 인스턴스(예제) 제외 (토큰 수 절감 목적)\n",
      "    \"\"\"\n",
      "\n",
      "    # ✅ 1. 이상치 탐지 (IQR 방식)\n",
      "    outliers_info = {}\n",
      "    for col in df.select_dtypes(include=[np.number]).columns:\n",
      "        Q1 = df[col].quantile(0.25)\n",
      "        Q3 = df[col].quantile(0.75)\n",
      "        IQR = Q3 - Q1\n",
      "        lower_bound = Q1 - 1.5 * IQR\n",
      "        upper_bound = Q3 + 1.5 * IQR\n",
      "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
      "\n",
      "        if outlier_count > 0:\n",
      "            outliers_info[col] = int(outlier_count)\n",
      "\n",
      "    # ✅ 2. 컬럼 개요 (기본 통계 및 결측 정보 + 인스턴스 예제 + 범주형 분포 추가)\n",
      "    columns_info = []\n",
      "    for col in df.columns:\n",
      "        col_dtype = df[col].dtype\n",
      "\n",
      "        col_info = {\n",
      "            \"데이터프레임명\": df_name,\n",
      "            \"컬럼명\": col,\n",
      "            \"데이터 타입\": col_dtype,\n",
      "            \"count\": df[col].count(),\n",
      "            \"mean\": round(df[col].mean(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"std\": round(df[col].std(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"min\": round(df[col].min(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"25%\": round(df[col].quantile(0.25), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"75%\": round(df[col].quantile(0.75), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"max\": round(df[col].max(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"결측 개수\": df[col].isnull().sum(),\n",
      "            \"결측치 비율\": round(df[col].isnull().sum() / len(df) * 100, 0),\n",
      "            \"고유값 개수\": df[col].nunique(),\n",
      "        }\n",
      "\n",
      "        # ✅ 범주형 변수만 인스턴스(예제) 포함 (연속형 변수 제외하여 토큰 수 절감)\n",
      "        if col_dtype in [\"object\", \"category\"]:\n",
      "            unique_vals = df[col].dropna().unique()\n",
      "            # 유니크 값 샘플링 (20개 이상이면 10개만 출력 + '...')\n",
      "            if len(unique_vals) > 20:\n",
      "                sample_display = list(unique_vals[:10]) + ['...']\n",
      "            else:\n",
      "                sample_display = unique_vals.tolist()\n",
      "            col_info[\"인스턴스(예제)\"] = sample_display\n",
      "\n",
      "            # ✅ 범주형 변수일 경우, 분포 정보 추가 (최대 10개만 저장하여 토큰 절감)\n",
      "            value_counts = df[col].value_counts(normalize=True) * 100\n",
      "            value_counts = value_counts[:10]  # 최대 10개만 유지\n",
      "            category_distribution = {val: round(pct, 2) for val, pct in value_counts.items()}\n",
      "            col_info[\"범주형 분포\"] = category_distribution\n",
      "\n",
      "        columns_info.append(col_info)\n",
      "\n",
      "    columns_info_df = pd.DataFrame(columns_info)\n",
      "\n",
      "    return columns_info_df\n",
      "\n",
      "# 다중 데이터프레임 처리 및 결과 저장\n",
      "def analyze_multiple_dataframes(dataframe_list):\n",
      "    result_tmp = {\"데이터 개요\": []}\n",
      "\n",
      "    for df_name in dataframe_list:\n",
      "        df = globals().get(df_name)\n",
      "\n",
      "        if df is not None:\n",
      "            rslt = summarize_data(df, df_name)\n",
      "            result_tmp[\"데이터 개요\"].append(rslt)\n",
      "\n",
      "    # 결과 데이터프레임 병합\n",
      "    for key in result_tmp.keys():\n",
      "        result_tmp[key] = pd.concat(result_tmp[key], ignore_index=True)\n",
      "\n",
      "    # 결과 저장 (엑셀 형식)\n",
      "    output_path = \"../output/stage1/eda_summary.xlsx\"\n",
      "    with pd.ExcelWriter(output_path) as writer:\n",
      "        for sheet_name, df in result_tmp.items():\n",
      "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
      "\n",
      "    return result_tmp\n",
      "\n",
      "# 데이터프레임 목록\n",
      "dataframe_list = ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "\n",
      "# 분석 실행\n",
      "analyze_multiple_dataframes(dataframe_list)\n",
      "\n",
      "❌ 1차 시도 : LLM 생성 코드 실행 중 오류 발생: No objects to concatenate\n",
      "🔄 오류 메시지를 기반으로 코드 수정 요청 중...\n",
      "[LOG] 실행할 코드:\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def summarize_data(df, df_name):\n",
      "    \"\"\"\n",
      "    주어진 데이터프레임(df)에 대한 EDA(탐색적 데이터 분석) 결과를 정리하여 반환하는 함수.\n",
      "    - \"컬럼 개요\"에 범주형 변수 분포 정보 포함\n",
      "    - 연속형 변수의 인스턴스(예제) 제외 (토큰 수 절감 목적)\n",
      "    \"\"\"\n",
      "\n",
      "    # ✅ 1. 이상치 탐지 (IQR 방식)\n",
      "    outliers_info = {}\n",
      "    for col in df.select_dtypes(include=[np.number]).columns:\n",
      "        Q1 = df[col].quantile(0.25)\n",
      "        Q3 = df[col].quantile(0.75)\n",
      "        IQR = Q3 - Q1\n",
      "        lower_bound = Q1 - 1.5 * IQR\n",
      "        upper_bound = Q3 + 1.5 * IQR\n",
      "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
      "\n",
      "        if outlier_count > 0:\n",
      "            outliers_info[col] = int(outlier_count)\n",
      "\n",
      "    # ✅ 2. 컬럼 개요 (기본 통계 및 결측 정보 + 인스턴스 예제 + 범주형 분포 추가)\n",
      "    columns_info = []\n",
      "    for col in df.columns:\n",
      "        col_dtype = df[col].dtype\n",
      "\n",
      "        col_info = {\n",
      "            \"데이터프레임명\": df_name,\n",
      "            \"컬럼명\": col,\n",
      "            \"데이터 타입\": col_dtype,\n",
      "            \"count\": df[col].count(),\n",
      "            \"mean\": round(df[col].mean(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"std\": round(df[col].std(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"min\": round(df[col].min(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"25%\": round(df[col].quantile(0.25), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"75%\": round(df[col].quantile(0.75), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"max\": round(df[col].max(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"결측 개수\": df[col].isnull().sum(),\n",
      "            \"결측치 비율\": round(df[col].isnull().sum() / len(df) * 100, 0),\n",
      "            \"고유값 개수\": df[col].nunique(),\n",
      "        }\n",
      "\n",
      "        # ✅ 범주형 변수만 인스턴스(예제) 포함 (연속형 변수 제외하여 토큰 수 절감)\n",
      "        if col_dtype in [\"object\", \"category\"]:\n",
      "            unique_vals = df[col].dropna().unique()\n",
      "            # 유니크 값 샘플링 (20개 이상이면 10개만 출력 + '...')\n",
      "            if len(unique_vals) > 20:\n",
      "                sample_display = list(unique_vals[:10]) + ['...']\n",
      "            else:\n",
      "                sample_display = unique_vals.tolist()\n",
      "            col_info[\"인스턴스(예제)\"] = sample_display\n",
      "\n",
      "            # ✅ 범주형 변수일 경우, 분포 정보 추가 (최대 10개만 저장하여 토큰 절감)\n",
      "            value_counts = df[col].value_counts(normalize=True) * 100\n",
      "            value_counts = value_counts[:10]  # 최대 10개만 유지\n",
      "            category_distribution = {val: round(pct, 2) for val, pct in value_counts.items()}\n",
      "            col_info[\"범주형 분포\"] = category_distribution\n",
      "\n",
      "        columns_info.append(col_info)\n",
      "\n",
      "    columns_info_df = pd.DataFrame(columns_info)\n",
      "\n",
      "    return columns_info_df\n",
      "\n",
      "# 다중 데이터프레임 처리 및 결과 저장\n",
      "def analyze_multiple_dataframes(dataframe_list):\n",
      "    result_tmp = {\"데이터 개요\": []}\n",
      "\n",
      "    for df_name in dataframe_list:\n",
      "        df = globals().get(df_name)\n",
      "\n",
      "        if df is not None and not df.empty:\n",
      "            rslt = summarize_data(df, df_name)\n",
      "            result_tmp[\"데이터 개요\"].append(rslt)\n",
      "\n",
      "    # 결과 데이터프레임 병합\n",
      "    for key in result_tmp.keys():\n",
      "        if result_tmp[key]:  # 리스트가 비어있지 않은 경우에만 병합\n",
      "            result_tmp[key] = pd.concat(result_tmp[key], ignore_index=True)\n",
      "        else:\n",
      "            result_tmp[key] = pd.DataFrame()  # 빈 데이터프레임으로 초기화\n",
      "\n",
      "    # 결과 저장 (엑셀 형식)\n",
      "    output_path = \"../output/stage1/eda_summary.xlsx\"\n",
      "    with pd.ExcelWriter(output_path) as writer:\n",
      "        for sheet_name, df in result_tmp.items():\n",
      "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
      "\n",
      "    return result_tmp\n",
      "\n",
      "# 데이터프레임 목록\n",
      "dataframe_list = ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "\n",
      "# 분석 실행\n",
      "analyze_multiple_dataframes(dataframe_list)\n",
      "\n",
      "[Stage 1. 데이터 구조 파악] 1차 시도 | ✅ 데이터마트에 대한 구조 파악 코드가 성공적으로 실행되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "# ✅ LangGraph 및 LangChain 관련 모듈\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# ✅ AI Assistant LangGraph Class Import\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()  # 환경 변수 로드\n",
    "\n",
    "\n",
    "# ✅ OpenAI API Key 확인\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key, temperature=0,)\n",
    "\n",
    "# llm 결과 코드 실행 결과가 담길 객체 dict 선언\n",
    "results = {}\n",
    "list_df = {}\n",
    "\n",
    "# ../data 경로의 모든 pkl 파일 읽기\n",
    "data_path = os.path.join('..', 'data')\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        df_name = file.replace('.pkl', '')\n",
    "        list_df[df_name] = pd.read_pickle(file_path)\n",
    "\n",
    "list_df_text = \", \".join(list_df)\n",
    "\n",
    "# 프롬프트 및 함수 코드 불러오기\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "\n",
    "# LLM에 첫 번째 코드 요청\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"### 참고 코드:\\n{func_code}\\n\\n\"),\n",
    "            (\"user\", \"### list_df:\\n{list_df}\\n\\n\")\n",
    "        ]) | llm\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df\": list_df_text}).content\n",
    "\n",
    "attempt_count = 0  # 실행 시도 횟수\n",
    "success = False  # 코드 실행 성공 여부\n",
    "\n",
    "while attempt_count < 2:  # 최초 실행 + 1회 재생성 가능\n",
    "    try:\n",
    "        if \"```python\" in response:\n",
    "            modified_code = response.split(\"```python\")[-1].split(\"```\")[0]\n",
    "            print(f\"[LOG] 실행할 코드:\\n{modified_code}\")\n",
    "            exec(modified_code, globals())  # LLM이 생성한 코드 실행\n",
    "            print(f\"[Stage 1. 데이터 구조 파악] 1차 시도 | ✅ 데이터마트에 대한 구조 파악 코드가 성공적으로 실행되었습니다!\")\n",
    "            success = True\n",
    "            break  # 실행 성공 시 루프 종료\n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        print(f\"❌ {attempt_count+1}차 시도 : LLM 생성 코드 실행 중 오류 발생: {error_message}\")\n",
    "\n",
    "        if attempt_count == 0:  # 최초 실행 실패 시 1회만 재생성\n",
    "            print(\"🔄 오류 메시지를 기반으로 코드 수정 요청 중...\")\n",
    "\n",
    "            # 오류 메시지를 기반으로 LLM에 코드 수정 요청\n",
    "            prompt_error_fix = f\"\"\"\n",
    "            ### 코드 수정 요청\n",
    "\n",
    "            이전 코드 실행 중 다음 오류가 발생했습니다:\n",
    "            ```\n",
    "            {error_message}\n",
    "            ```\n",
    "\n",
    "            위 오류를 해결한 새로운 코드를 생성하세요.\n",
    "            - 기존 코드에서 오류를 수정한 버전으로 제공해야 합니다.\n",
    "            - 코드 실행 가능하도록 보완해야 합니다.\n",
    "\n",
    "            ```python\n",
    "            # 필요한 코드 삽입\n",
    "            ```\n",
    "            \"\"\"\n",
    "            chain_error_fix = ChatPromptTemplate.from_messages([\n",
    "                        (\"system\", prompt_error_fix),\n",
    "                        (\"user\", \"### 기존 코드:\\n{modified_code}\\n\\n\")\n",
    "                    ]) | llm\n",
    "\n",
    "            response = chain_error_fix.invoke({\"modified_code\": modified_code}).content\n",
    "            # print(f'[LOG] 수정된 코드:\\n{response}')\n",
    "        else:\n",
    "            print(\"❌ 코드 실행 최종적으로 실패. 프로세스를 중단합니다.\")\n",
    "\n",
    "        attempt_count += 1  # 재시도 횟수 증가\n",
    "\n",
    "# ✅ FAISS 벡터스토어 로드\n",
    "def load_vectorstore():\n",
    "    if os.path.exists(\"./vectordb\"):\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        try:\n",
    "            return FAISS.load_local(\"./vectordb\", embeddings, allow_dangerous_deserialization=True)\n",
    "        except Exception as e:\n",
    "            print(f\"벡터스토어 로드 중 오류 발생: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "vectorstore = load_vectorstore()\n",
    "def load_column_descriptions(file_path):\n",
    "    \"\"\"컬럼 설명 데이터를 로드하는 함수\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        # Stage 1의 결과에서 첫 번째 시트(데이터 구조 요약) 로드\n",
    "        return pd.read_excel(file_path, sheet_name=0)\n",
    "    print(\"⚠️ 컬럼 설명 파일이 존재하지 않습니다. 설명 없이 진행됩니다.\")\n",
    "    return None\n",
    "\n",
    "def search_column_descriptions(col_desc_df, vectorstore):\n",
    "    \"\"\"RAG를 사용하여 컬럼 설명을 검색하는 함수\"\"\"\n",
    "    data = []\n",
    "    # Stage 1 결과의 필요한 컬럼만 선택\n",
    "    df_after_llm = col_desc_df[['데이터프레임명', '컬럼명']]\n",
    "    \n",
    "    for i, row in df_after_llm.iterrows():\n",
    "        table_name = row['데이터프레임명']\n",
    "        col = row['컬럼명']\n",
    "        \n",
    "        # 현재 테이블명을 포함한 검색 쿼리 생성\n",
    "        search_query = f\"테이블명 : {table_name} | 컬럼명 : {col}\"\n",
    "        docs = vectorstore.similarity_search(search_query, k=1)\n",
    "        \n",
    "        if docs:\n",
    "            best_match = docs[0].page_content\n",
    "            data.append({\n",
    "                '데이터프레임명': table_name,\n",
    "                '컬럼명': col,\n",
    "                '컬럼설명': best_match.split('\\n')[3].split('설명')[1].strip()\n",
    "            })\n",
    "            print(f\"🔍 [{i+1}] {search_query} | {best_match.split('설명')[1].strip()}\")\n",
    "        else:\n",
    "            data.append({\n",
    "                '데이터프레임명': table_name,\n",
    "                '컬럼명': col,\n",
    "                '컬럼설명': \"설명 없음\"\n",
    "            })\n",
    "            print(f\"⚠️ 컬럼 '{col}' 설명 없음\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# 메인 실행 부분\n",
    "stage1_path = \"output/stage1/eda_summary.xlsx\"\n",
    "col_desc_df = load_column_descriptions(stage1_path)\n",
    "\n",
    "if col_desc_df is not None:\n",
    "    # RAG 검색 수행\n",
    "    rag_results = search_column_descriptions(col_desc_df, vectorstore)\n",
    "    \n",
    "    # Stage 1의 결과와 RAG 결과를 통합\n",
    "    final_df = pd.merge(\n",
    "        col_desc_df,     # Stage 1의 결과 (원본 데이터 구조 정보)\n",
    "        rag_results,     # RAG 검색 결과 (컬럼 설명)\n",
    "        on=['데이터프레임명', '컬럼명'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 결과 저장\n",
    "    output_path = \"output/stage1/integrated_column_descriptions.xlsx\"\n",
    "    \n",
    "    # 원본 Stage 1 결과의 모든 시트를 복사하고, 통합 결과를 새로운 시트로 추가\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        # 먼저 Stage 1의 모든 시트를 복사\n",
    "        original_sheets = pd.read_excel(stage1_path, sheet_name=None)\n",
    "        for sheet_name, df in original_sheets.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # 통합된 결과를 새로운 시트로 추가\n",
    "        final_df.to_excel(writer, sheet_name='통합_결과', index=False)\n",
    "    \n",
    "    print(f\"✅ 통합된 결과가 {output_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 [1] 테이블명 : cust_enroll_history | 컬럼명 : 고객ID | : 개별 고객을 식별하기 위한 고유 식별 번호\n",
      "🔍 [2] 테이블명 : cust_enroll_history | 컬럼명 : 가입년월일 | : 고객이 보험 상품에 가입한 날짜 (년, 월, 일 단위).\n",
      "🔍 [3] 테이블명 : cust_enroll_history | 컬럼명 : 가입담보명 | : 고객이 가입한 담보에 대해 설정된 보장 금액.\n",
      "🔍 [4] 테이블명 : cust_enroll_history | 컬럼명 : 가입담보금액 | : 고객이 가입한 담보에 대해 설정된 보장 금액.\n",
      "🔍 [5] 테이블명 : cust_intg | 컬럼명 : 고객ID | : 개별 고객을 식별하기 위한 고유 식별 번호\n",
      "🔍 [6] 테이블명 : cust_intg | 컬럼명 : 나이 | : 고객의 현재 연령\n",
      "🔍 [7] 테이블명 : cust_intg | 컬럼명 : 성별 | : 고객의 성별 (남/여)\n",
      "🔍 [8] 테이블명 : cust_intg | 컬럼명 : 수익자여부 | : 고객이 보험 수익자인지 여부\n",
      "🔍 [9] 테이블명 : cust_intg | 컬럼명 : CB신용평점 | : CB(Credit Bureau) 기준 고객의 신용평점\n",
      "🔍 [10] 테이블명 : cust_intg | 컬럼명 : CB신용등급 | : CB(Credit Bureau) 기준 고객의 신용등급\n",
      "🔍 [11] 테이블명 : cust_intg | 컬럼명 : 두낫콜여부 | : 고객이 마케팅 전화 수신을 거부했는지 여부\n",
      "🔍 [12] 테이블명 : cust_intg | 컬럼명 : 운전코드명 | : 고객의 운전 관련 코드명 (운전면허 여부 등)\n",
      "🔍 [13] 테이블명 : cust_intg | 컬럼명 : 성별코드 | : 고객 성별을 나타내는 코드 값\n",
      "🔍 [14] 테이블명 : cust_intg | 컬럼명 : 피보험자여부 | : 고객이 피보험자인지 여부\n",
      "🔍 [15] 테이블명 : cust_intg | 컬럼명 : 보험연령 | : 보험 가입 시 산정된 고객의 연령\n",
      "🔍 [16] 테이블명 : cust_intg | 컬럼명 : 직업분류명 | : 고객의 직업 분류명\n",
      "🔍 [17] 테이블명 : cust_intg | 컬럼명 : 직업위험등급코드 | : 직업에 따른 위험 등급을 나타내는 코드\n",
      "🔍 [18] 테이블명 : cust_intg | 컬럼명 : 시도코드 | : 고객 거주지의 시도(광역자치단체)를 나타내는 코드\n",
      "🔍 [19] 테이블명 : cust_intg | 컬럼명 : 방카채널Affluent고객여부 | : 자사 설계사 채널의 고액 자산(Affluent) 고객 여부\n",
      "🔍 [20] 테이블명 : cust_intg | 컬럼명 : 방카채널유지계약건수 | : 방카슈랑스 채널을 통한 유지 계약 건수\n",
      "🔍 [21] 테이블명 : cust_intg | 컬럼명 : CMIP | : 월환산보험료\n",
      "🔍 [22] 테이블명 : cust_intg | 컬럼명 : 교차채널활동고객여부 | : 고객이 교차 채널에서 활동했는지 여부\n",
      "🔍 [23] 테이블명 : cust_intg | 컬럼명 : 교차채널CMIP | : 교차 채널 월환산보험료\n",
      "🔍 [24] 테이블명 : cust_intg | 컬럼명 : 교차채널유지계약건수 | : 교차 채널을 통한 유지 계약 건수\n",
      "🔍 [25] 테이블명 : cust_intg | 컬럼명 : DM채널활동고객여부 | : CM(Cyber Marketing) 채널에서 고객이 활동했는지 여부\n",
      "🔍 [26] 테이블명 : cust_intg | 컬럼명 : DM채널유지계약건수 | : 기타 채널을 통한 유지 계약 건수\n",
      "🔍 [27] 테이블명 : cust_intg | 컬럼명 : 기타채널누적성립건수 | : 기타 채널에서 성립된 누적 계약 건수\n",
      "🔍 [28] 테이블명 : cust_intg | 컬럼명 : 기타채널CMIP | : 기타 채널 관련 월환산보험료\n",
      "🔍 [29] 테이블명 : cust_intg | 컬럼명 : 기타채널유지계약건수 | : 기타 채널을 통한 유지 계약 건수\n",
      "🔍 [30] 테이블명 : cust_intg | 컬럼명 : GA채널활동고객여부 | : 고객이 GA(General Agency) 채널에서 활동했는지 여부\n",
      "🔍 [31] 테이블명 : cust_intg | 컬럼명 : GA채널Affluent고객여부 | : GA(General Agency)채널의 고액 자산(Affluent) 고객 여부\n",
      "🔍 [32] 테이블명 : cust_intg | 컬럼명 : GA채널CMIP | : GA(General Agency)채널 관련 월환산보험료\n",
      "🔍 [33] 테이블명 : cust_intg | 컬럼명 : GA채널유지계약건수 | : GA(General Agency)채널을 통한 유지 계약 건수\n",
      "🔍 [34] 테이블명 : cust_intg | 컬럼명 : 하이브리드채널활동고객여부 | : 하이브리드 채널에서 고객이 활동했는지 여부\n",
      "🔍 [35] 테이블명 : cust_intg | 컬럼명 : 자사설계사채널누적성립건수 | : 자사 설계사 채널을 통한 누적 성립 계약 건수\n",
      "🔍 [36] 테이블명 : cust_intg | 컬럼명 : 자사설계사채널활동고객여부 | : 자사 설계사 채널에서 고객이 활동했는지 여부\n",
      "🔍 [37] 테이블명 : cust_intg | 컬럼명 : 자사설계사채널Affluent고객여부 | : 자사 설계사 채널의 고액 자산(Affluent) 고객 여부\n",
      "🔍 [38] 테이블명 : cust_intg | 컬럼명 : 자사설계사채널CMIP | : 자사 설계사 채널 관련 월환산보험료\n",
      "🔍 [39] 테이블명 : cust_intg | 컬럼명 : 자사설계사채널유지계약건수 | : 자사 설계사 채널을 통한 유지 계약 건수\n",
      "🔍 [40] 테이블명 : cust_intg | 컬럼명 : CM채널활동고객여부 | : CM(Cyber Marketing) 채널에서 고객이 활동했는지 여부\n",
      "🔍 [41] 테이블명 : cust_intg | 컬럼명 : CM채널CMIP | : CM(Cyber Marketing) 채널 관련 월환산보험료\n",
      "🔍 [42] 테이블명 : cust_intg | 컬럼명 : 아웃바운드채널누적성립건수 | : 아웃바운드 채널을 통한 누적 성립 계약 건수\n",
      "🔍 [43] 테이블명 : cust_intg | 컬럼명 : 아웃바운드채널CMIP | : 아웃바운드 채널 관련 월환산보험료\n",
      "🔍 [44] 테이블명 : cust_intg | 컬럼명 : 아웃바운드채널유지계약건수 | : 아웃바운드 채널을 통한 유지 계약 건수\n",
      "🔍 [45] 테이블명 : cust_intg | 컬럼명 : 당월이탈고객여부 | : 당월에 이탈한 고객 여부\n",
      "🔍 [46] 테이블명 : cust_intg | 컬럼명 : 당월교차채널유입고객여부 | : 당월 교차 채널을 통해 유입된 고객 여부\n",
      "🔍 [47] 테이블명 : cust_intg | 컬럼명 : 당월DM채널유입고객여부 | : 당월 DM(Direct Marketing - 대면 마케팅)  채널을 통해 유입된 고객 여부\n",
      "🔍 [48] 테이블명 : cust_intg | 컬럼명 : 당월DM채널유입계약건수 | : 당월 DM(Direct Marketing - 대면 마케팅)  채널을 통해 유입된 계약 건수\n",
      "🔍 [49] 테이블명 : cust_intg | 컬럼명 : 당월DM채널성립건수 | : 당월 DM(Direct Marketing - 대면 마케팅)  채널을 통한 성립 계약 건수\n",
      "🔍 [50] 테이블명 : cust_intg | 컬럼명 : 당월DM채널계약이탈건수 | : 당월 DM(Direct Marketing - 대면 마케팅)  채널에서 계약 이탈 건수\n",
      "🔍 [51] 테이블명 : cust_intg | 컬럼명 : 당월GA채널유입고객여부 | : 당월 GA(General Agency)채널을 통해 유입된 고객 여부\n",
      "🔍 [52] 테이블명 : cust_intg | 컬럼명 : 당월GA채널유입계약건수 | : 당월 GA(General Agency)채널을 통해 유입된 계약 건수\n",
      "🔍 [53] 테이블명 : cust_intg | 컬럼명 : 당월GA채널성립건수 | : 당월 GA(General Agency)채널을 통한 성립 계약 건수\n",
      "🔍 [54] 테이블명 : cust_intg | 컬럼명 : 당월GA채널계약이탈건수 | : 당월 GA(General Agency)채널에서 계약 이탈 건수\n",
      "🔍 [55] 테이블명 : cust_intg | 컬럼명 : 당월유입고객여부 | : 당월 유입된 고객 여부\n",
      "🔍 [56] 테이블명 : cust_intg | 컬럼명 : 당월유입계약건수 | : 당월 유입된 계약 건수\n",
      "🔍 [57] 테이블명 : cust_intg | 컬럼명 : 당월자사설계사채널이탈고객여부 | : 당월 자사 설계사 채널에서 이탈한 고객 여부\n",
      "🔍 [58] 테이블명 : cust_intg | 컬럼명 : 당월자사설계사채널유입고객여부 | : 당월 자사 설계사 채널을 통해 유입된 고객 여부\n",
      "🔍 [59] 테이블명 : cust_intg | 컬럼명 : 당월자사설계사채널유입계약건수 | : 당월 자사 설계사 채널을 통해 유입된 계약 건수\n",
      "🔍 [60] 테이블명 : cust_intg | 컬럼명 : 당월자사설계사채널성립건수 | : 당월 자사 설계사 채널을 통한 성립 계약 건수\n",
      "🔍 [61] 테이블명 : cust_intg | 컬럼명 : 당월자사설계사채널계약이탈건수 | : 당월 자사 설계사 채널에서 계약 이탈 건수\n",
      "🔍 [62] 테이블명 : cust_intg | 컬럼명 : 당월신규고객여부 | : 당월 신규로 가입한 고객 여부\n",
      "🔍 [63] 테이블명 : cust_intg | 컬럼명 : 당월아웃바운드채널유입고객여부 | : 당월 아웃바운드 채널을 통해 유입된 고객 여부\n",
      "🔍 [64] 테이블명 : cust_intg | 컬럼명 : 당월아웃바운드채널유입계약건수 | : 당월 아웃바운드 채널을 통해 유입된 계약 건수\n",
      "🔍 [65] 테이블명 : cust_intg | 컬럼명 : 당월아웃바운드채널성립건수 | : 당월 아웃바운드 채널을 통한 성립 계약 건수\n",
      "🔍 [66] 테이블명 : cust_intg | 컬럼명 : 누적콜센터상담건수 | : 콜센터를 통한 누적 상담 건수\n",
      "🔍 [67] 테이블명 : cust_intg | 컬럼명 : 누적부정반응건수 | : 고객의 부정적 반응 누적 건수\n",
      "🔍 [68] 테이블명 : cust_intg | 컬럼명 : 누적VOC접수건수 | : VOC(Voice of Customer) 접수 누적 건수\n",
      "🔍 [69] 테이블명 : cust_intg | 컬럼명 : 최근3개월사이버환급금조회건수 | : 최근 3개월간 사이버 환급금 조회 건수\n",
      "🔍 [70] 테이블명 : cust_intg | 컬럼명 : 누적연금지급금액 | : 누적된 연금 지급 총 금액\n",
      "🔍 [71] 테이블명 : cust_intg | 컬럼명 : 누적보험금지급건수 | : 누적된 보험금 지급 건수\n",
      "🔍 [72] 테이블명 : cust_intg | 컬럼명 : 누적중도보험금지급금액 | : 누적된 중도 보험금 지급 총 금액\n",
      "🔍 [73] 테이블명 : cust_intg | 컬럼명 : 누적중도인출건수 | : 누적된 중도 인출 건수\n",
      "🔍 [74] 테이블명 : cust_intg | 컬럼명 : 누적해약환급금지급금액 | : 누적된 해약 환급금 지급 총 금액\n",
      "🔍 [75] 테이블명 : cust_intg | 컬럼명 : 전전월제지급금이력여부 | : 전전월에 지급금 이력이 있는지 여부\n",
      "🔍 [76] 테이블명 : cust_intg | 컬럼명 : 전월제지급금이력여부 | : 당월 지급금 이력이 있는지 여부\n",
      "🔍 [77] 테이블명 : cust_intg | 컬럼명 : 당월보험료자동대출잔액 | : 당월 보험료 자동 대출 잔액\n",
      "🔍 [78] 테이블명 : cust_intg | 컬럼명 : 당월보험금지급건수 | : 당월 보험금 지급 건수\n",
      "🔍 [79] 테이블명 : cust_intg | 컬럼명 : 당월보험금청구건수 | : 당월 보험금 청구 건수\n",
      "🔍 [80] 테이블명 : cust_intg | 컬럼명 : 당월중도인출건수 | : 당월 중도 인출 건수\n",
      "🔍 [81] 테이블명 : cust_intg | 컬럼명 : 당월제지급금이력여부 | : 당월 지급금 이력이 있는지 여부\n",
      "🔍 [82] 테이블명 : cust_intg | 컬럼명 : 누적성립건수 | : 누적된 계약 성립 건수\n",
      "🔍 [83] 테이블명 : cust_intg | 컬럼명 : 수금설계사수 | : 수금을 담당하는 설계사 수\n",
      "🔍 [84] 테이블명 : cust_intg | 컬럼명 : 수금방법변경건수 | : 수금 방법 변경 건수\n",
      "🔍 [85] 테이블명 : cust_intg | 컬럼명 : 모집설계사수 | : 모집을 담당하는 설계사 수\n",
      "🔍 [86] 테이블명 : cust_intg | 컬럼명 : 보유계약피보험자수 | : 보유 계약의 피보험자 수\n",
      "🔍 [87] 테이블명 : cust_intg | 컬럼명 : 유지계약건수 | : 유지 중인 계약 건수\n",
      "🔍 [88] 테이블명 : cust_intg | 컬럼명 : 최빈가입채널코드 | : 가장 빈번하게 사용된 가입 채널 코드\n",
      "🔍 [89] 테이블명 : cust_intg | 컬럼명 : 계약변경신청건수 | : 고객의 계약 변경 신청 건수\n",
      "🔍 [90] 테이블명 : cust_intg | 컬럼명 : 부활변경건수 | : 보험 계약의 부활(효력 회복) 관련 변경 건수\n",
      "🔍 [91] 테이블명 : cust_intg | 컬럼명 : 가입특약수합계 | : 고객이 가입한 특약(추가 보장)의 총 개수\n",
      "🔍 [92] 테이블명 : cust_intg | 컬럼명 : 대출가능금액합계 | : 고객이 대출할 수 있는 총 금액\n",
      "🔍 [93] 테이블명 : cust_intg | 컬럼명 : 보험계약대출잔액합계 | : 보험 계약을 기반으로 한 대출의 잔액 합계\n",
      "🔍 [94] 테이블명 : cust_intg | 컬럼명 : 기납입보험료합계 | : 고객이 납입한 보험료의 총액\n",
      "🔍 [95] 테이블명 : cust_intg | 컬럼명 : 미납보험료합계 | : 고객이 납입하지 않은 미납 보험료의 총액\n",
      "🔍 [96] 테이블명 : cust_intg | 컬럼명 : 전사최종계약경과월수 | : 회사의 마지막 계약 이후 경과한 개월 수\n",
      "🔍 [97] 테이블명 : cust_intg | 컬럼명 : 전사최초계약경과월수 | : 회사의 최초 계약 이후 경과한 개월 수\n",
      "🔍 [98] 테이블명 : cust_intg | 컬럼명 : 연금누적가입건수 | : 연금 상품 누적 가입 건수\n",
      "🔍 [99] 테이블명 : cust_intg | 컬럼명 : 연금보유여부 | : 고객이 연금 상품을 보유하고 있는지 여부\n",
      "🔍 [100] 테이블명 : cust_intg | 컬럼명 : 연금실효계약건수 | : 효력이 상실된 연금 계약 건수\n",
      "🔍 [101] 테이블명 : cust_intg | 컬럼명 : 연금최대납입회차 | : 연금 상품의 최대 납입 회차\n",
      "🔍 [102] 테이블명 : cust_intg | 컬럼명 : 연금유지계약수 | : 유지 중인 연금 계약 수\n",
      "🔍 [103] 테이블명 : cust_intg | 컬럼명 : 연금기납입보험료 | : 연금 상품에 납입된 보험료 총액\n",
      "🔍 [104] 테이블명 : cust_intg | 컬럼명 : 연금인수거절여부 | : 연금 상품 인수가 거절된 여부\n",
      "🔍 [105] 테이블명 : cust_intg | 컬럼명 : 기타보장누적가입건수 | : 기타 보장 상품의 누적 가입 건수\n",
      "🔍 [106] 테이블명 : cust_intg | 컬럼명 : 기타보장유지계약수 | : 유지 중인 기타 보장 계약 수\n",
      "🔍 [107] 테이블명 : cust_intg | 컬럼명 : 일반종신누적가입건수 | : 일반 종신 보험의 누적 가입 건수\n",
      "🔍 [108] 테이블명 : cust_intg | 컬럼명 : 일반종신보유여부 | : 일반 종신 보험을 보유하고 있는지 여부\n",
      "🔍 [109] 테이블명 : cust_intg | 컬럼명 : 일반종신실효계약건수 | : 효력이 상실된 일반 종신 보험 계약 건수\n",
      "🔍 [110] 테이블명 : cust_intg | 컬럼명 : 일반종신최대납입회차 | : 일반 종신 보험의 최대 납입 회차\n",
      "🔍 [111] 테이블명 : cust_intg | 컬럼명 : 일반종신유지계약수 | : 유지 중인 일반 종신 보험 계약 수\n",
      "🔍 [112] 테이블명 : cust_intg | 컬럼명 : 일반종신인수거절여부 | : 일반 종신 보험 인수가 거절된 여부\n",
      "🔍 [113] 테이블명 : cust_intg | 컬럼명 : 저축CMIP | : 저축 상품 관련 월환산보험료\n",
      "🔍 [114] 테이블명 : cust_intg | 컬럼명 : 저축최대납입회차 | : 저축 상품의 최대 납입 회차\n",
      "🔍 [115] 테이블명 : cust_intg | 컬럼명 : 저축가입납입보험료 | : 저축 상품 가입 시 납입한 보험료\n",
      "🔍 [116] 테이블명 : cust_intg | 컬럼명 : 변액누적가입건수 | : 변액 보험의 누적 가입 건수\n",
      "🔍 [117] 테이블명 : cust_intg | 컬럼명 : 변액CMIP | : 변액 보험 관련 월환산보험료\n",
      "🔍 [118] 테이블명 : cust_intg | 컬럼명 : 변액보유여부 | : 변액 보험을 보유하고 있는지 여부\n",
      "🔍 [119] 테이블명 : cust_intg | 컬럼명 : 변액최대납입회차 | : 변액 보험의 최대 납입 회차\n",
      "🔍 [120] 테이블명 : cust_intg | 컬럼명 : 변액유지계약수 | : 유지 중인 변액 보험 계약 수\n",
      "🔍 [121] 테이블명 : cust_intg | 컬럼명 : 변액기납입보험료 | : 변액 보험에 납입된 보험료 총액\n",
      "🔍 [122] 테이블명 : cust_intg | 컬럼명 : 변액종신CMIP | : 변액 종신 보험 관련 월환산보험료\n",
      "🔍 [123] 테이블명 : cust_intg | 컬럼명 : 변액종신보유여부 | : 변액 종신 보험을 보유하고 있는지 여부\n",
      "🔍 [124] 테이블명 : cust_intg | 컬럼명 : 변액종신최대납입회차 | : 변액 종신 보험의 최대 납입 회차\n",
      "🔍 [125] 테이블명 : cust_intg | 컬럼명 : 변액종신유지계약수 | : 유지 중인 변액 종신 보험 계약 수\n",
      "🔍 [126] 테이블명 : cust_intg | 컬럼명 : 변액종신기납입보험료 | : 변액 종신 보험에 납입된 보험료 총액\n",
      "🔍 [127] 테이블명 : cust_intg | 컬럼명 : 기준년월 | : 당월 신규로 가입한 고객 여부\n",
      "🔍 [128] 테이블명 : product_info | 컬럼명 : 특약코드 | : 상품에 대한 특약(추가 보장)의 고유 코드.\n",
      "🔍 [129] 테이블명 : product_info | 컬럼명 : 가입성별 | : 가입 가능한 성별 (남/여/공통).\n",
      "🔍 [130] 테이블명 : product_info | 컬럼명 : 가입최소나이 | : 가입 가능한 최소 나이.\n",
      "🔍 [131] 테이블명 : product_info | 컬럼명 : 가입최대나이 | : 가입 가능한 최대 나이.\n",
      "🔍 [132] 테이블명 : product_info | 컬럼명 : 담보코드 | : 상품의 담보(보장 내용)를 구분하는 코드.\n",
      "🔍 [133] 테이블명 : product_info | 컬럼명 : 가입한도 | : 가입 가능한 최대 금액 또는 보장 한도.\n",
      "✅ 통합된 결과가 output/stage1/integrated_column_descriptions.xlsx에 저장되었습니다.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "# ✅ LangGraph 및 LangChain 관련 모듈\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# ✅ AI Assistant LangGraph Class Import\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()  # 환경 변수 로드\n",
    "\n",
    "\n",
    "# ✅ OpenAI API Key 확인\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key, temperature=0,)\n",
    "\n",
    "# llm 결과 코드 실행 결과가 담길 객체 dict 선언\n",
    "results = {}\n",
    "list_df = {}\n",
    "\n",
    "# ../data 경로의 모든 pkl 파일 읽기\n",
    "data_path = os.path.join('..', 'data')\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        df_name = file.replace('.pkl', '')\n",
    "        list_df[df_name] = pd.read_pickle(file_path)\n",
    "\n",
    "list_df_text = \", \".join(list_df)\n",
    "\n",
    "# 프롬프트 및 함수 코드 불러오기\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "\n",
    "# LLM에 첫 번째 코드 요청\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"### 참고 코드:\\n{func_code}\\n\\n\"),\n",
    "            (\"user\", \"### list_df:\\n{list_df}\\n\\n\")\n",
    "        ]) | llm\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df\": list_df_text}).content\n",
    "\n",
    "attempt_count = 0  # 실행 시도 횟수\n",
    "success = False  # 코드 실행 성공 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 프롬프트 및 함수 코드 로드 완료\n",
      "\n",
      "🤖 LLM에 코드 생성 요청 중...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ 프롬프트 및 함수 코드 불러오기\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "print(\"✅ 프롬프트 및 함수 코드 로드 완료\\n\")\n",
    "\n",
    "print(\"🤖 LLM에 코드 생성 요청 중...\")\n",
    "\n",
    "# ✅ LLM에 첫 번째 코드 요청\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"### 참고 코드:\\n{func_code}\\n\\n\"),\n",
    "    (\"user\", \"### list_df:\\n{list_df}\\n\\n\")\n",
    "]) | llm\n",
    "\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df\": list_df_text}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 실행할 코드:\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def summarize_data(df, df_name):\n",
      "    \"\"\"\n",
      "    주어진 데이터프레임(df)에 대한 EDA(탐색적 데이터 분석) 결과를 정리하여 반환하는 함수.\n",
      "    - \"컬럼 개요\"에 범주형 변수 분포 정보 포함\n",
      "    - 연속형 변수의 인스턴스(예제) 제외 (토큰 수 절감 목적)\n",
      "    \"\"\"\n",
      "\n",
      "    # ✅ 1. 이상치 탐지 (IQR 방식)\n",
      "    outliers_info = {}\n",
      "    for col in df.select_dtypes(include=[np.number]).columns:\n",
      "        Q1 = df[col].quantile(0.25)\n",
      "        Q3 = df[col].quantile(0.75)\n",
      "        IQR = Q3 - Q1\n",
      "        lower_bound = Q1 - 1.5 * IQR\n",
      "        upper_bound = Q3 + 1.5 * IQR\n",
      "        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
      "\n",
      "        if outlier_count > 0:\n",
      "            outliers_info[col] = int(outlier_count)\n",
      "\n",
      "    # ✅ 2. 컬럼 개요 (기본 통계 및 결측 정보 + 인스턴스 예제 + 범주형 분포 추가)\n",
      "    columns_info = []\n",
      "    for col in df.columns:\n",
      "        col_dtype = df[col].dtype\n",
      "\n",
      "        col_info = {\n",
      "            \"데이터프레임명\": df_name,\n",
      "            \"컬럼명\": col,\n",
      "            \"데이터 타입\": col_dtype,\n",
      "            \"count\": df[col].count(),\n",
      "            \"mean\": round(df[col].mean(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"std\": round(df[col].std(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"min\": round(df[col].min(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"25%\": round(df[col].quantile(0.25), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"75%\": round(df[col].quantile(0.75), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"max\": round(df[col].max(), 2) if col_dtype in [\"int64\", \"float64\"] else None,\n",
      "            \"결측 개수\": df[col].isnull().sum(),\n",
      "            \"결측치 비율\": round(df[col].isnull().sum() / len(df) * 100, 0),\n",
      "            \"고유값 개수\": df[col].nunique(),\n",
      "        }\n",
      "\n",
      "        # ✅ 범주형 변수만 인스턴스(예제) 포함 (연속형 변수 제외하여 토큰 수 절감)\n",
      "        if col_dtype in [\"object\", \"category\"]:\n",
      "            unique_vals = df[col].dropna().unique()\n",
      "            # 유니크 값 샘플링 (20개 이상이면 10개만 출력 + '...')\n",
      "            if len(unique_vals) > 20:\n",
      "                sample_display = list(unique_vals[:10]) + ['...']\n",
      "            else:\n",
      "                sample_display = unique_vals.tolist()\n",
      "            col_info[\"인스턴스(예제)\"] = sample_display\n",
      "\n",
      "            # ✅ 범주형 변수일 경우, 분포 정보 추가 (최대 10개만 저장하여 토큰 절감)\n",
      "            value_counts = df[col].value_counts(normalize=True) * 100\n",
      "            value_counts = value_counts[:10]  # 최대 10개만 유지\n",
      "            category_distribution = {val: round(pct, 2) for val, pct in value_counts.items()}\n",
      "            col_info[\"범주형 분포\"] = category_distribution\n",
      "\n",
      "        columns_info.append(col_info)\n",
      "\n",
      "    columns_info_df = pd.DataFrame(columns_info)\n",
      "\n",
      "    return columns_info_df\n",
      "\n",
      "# 다중 데이터프레임 처리 및 결과 저장\n",
      "def analyze_multiple_dataframes(dataframe_list):\n",
      "    result_tmp = {\"데이터 개요\": []}\n",
      "\n",
      "    for df_name in dataframe_list:\n",
      "        df = globals().get(df_name)\n",
      "\n",
      "        if df is not None:\n",
      "            rslt1 = summarize_data(df, df_name)\n",
      "            rslt2 = summarize_data(df, df_name)  # 예시로 동일한 함수 호출, 실제로는 다른 분석 함수 사용\n",
      "            rslt3 = summarize_data(df, df_name)  # 예시로 동일한 함수 호출, 실제로는 다른 분석 함수 사용\n",
      "\n",
      "            result_tmp[f\"{df_name}_rslt1\"] = rslt1\n",
      "            result_tmp[f\"{df_name}_rslt2\"] = rslt2\n",
      "            result_tmp[f\"{df_name}_rslt3\"] = rslt3\n",
      "\n",
      "    # 결과 저장 (엑셀 형식)\n",
      "    output_path = \"../output/stage1/eda_summary.xlsx\"\n",
      "    with pd.ExcelWriter(output_path) as writer:\n",
      "        for sheet_name, df in result_tmp.items():\n",
      "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
      "\n",
      "    return result_tmp\n",
      "\n",
      "# 데이터프레임 목록\n",
      "dataframe_list = ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "analyze_multiple_dataframes(dataframe_list)\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "At least one sheet must be visible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<string>:88\u001b[0m, in \u001b[0;36manalyze_multiple_dataframes\u001b[1;34m(dataframe_list)\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_excel'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m modified_code \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```python\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LOG] 실행할 코드:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodified_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m exec(modified_code, \u001b[38;5;28mglobals\u001b[39m())\n",
      "File \u001b[1;32m<string>:94\u001b[0m\n",
      "File \u001b[1;32m<string>:86\u001b[0m, in \u001b[0;36manalyze_multiple_dataframes\u001b[1;34m(dataframe_list)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1476\u001b[0m, in \u001b[0;36mExcelWriter.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1480\u001b[0m, in \u001b[0;36mExcelWriter.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"synonym for save, to make it more file-like\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n\u001b[0;32m   1481\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:109\u001b[0m, in \u001b[0;36mOpenpyxlWriter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    Save workbook to disk.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, mmap\u001b[38;5;241m.\u001b[39mmmap):\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;66;03m# truncate file to the written content\u001b[39;00m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mtruncate()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\workbook\\workbook.py:386\u001b[0m, in \u001b[0;36mWorkbook.save\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworksheets:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_sheet()\n\u001b[1;32m--> 386\u001b[0m save_workbook(\u001b[38;5;28mself\u001b[39m, filename)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\writer\\excel.py:294\u001b[0m, in \u001b[0;36msave_workbook\u001b[1;34m(workbook, filename)\u001b[0m\n\u001b[0;32m    292\u001b[0m workbook\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mmodified \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mutcnow()\n\u001b[0;32m    293\u001b[0m writer \u001b[38;5;241m=\u001b[39m ExcelWriter(workbook, archive)\n\u001b[1;32m--> 294\u001b[0m writer\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\writer\\excel.py:275\u001b[0m, in \u001b[0;36mExcelWriter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write data into the archive.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_data()\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_archive\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\writer\\excel.py:89\u001b[0m, in \u001b[0;36mExcelWriter.write_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m writer \u001b[38;5;241m=\u001b[39m WorkbookWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkbook)\n\u001b[0;32m     88\u001b[0m archive\u001b[38;5;241m.\u001b[39mwritestr(ARC_ROOT_RELS, writer\u001b[38;5;241m.\u001b[39mwrite_root_rels())\n\u001b[1;32m---> 89\u001b[0m archive\u001b[38;5;241m.\u001b[39mwritestr(ARC_WORKBOOK, writer\u001b[38;5;241m.\u001b[39mwrite())\n\u001b[0;32m     90\u001b[0m archive\u001b[38;5;241m.\u001b[39mwritestr(ARC_WORKBOOK_RELS, writer\u001b[38;5;241m.\u001b[39mwrite_rels())\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_vba()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\workbook\\_writer.py:150\u001b[0m, in \u001b[0;36mWorkbookWriter.write\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_names()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_pivots()\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_views()\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_refs()\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tostring(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpackage\u001b[38;5;241m.\u001b[39mto_tree())\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\workbook\\_writer.py:137\u001b[0m, in \u001b[0;36mWorkbookWriter.write_views\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_views\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 137\u001b[0m     active \u001b[38;5;241m=\u001b[39m get_active_sheet(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwb)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwb\u001b[38;5;241m.\u001b[39mviews:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwb\u001b[38;5;241m.\u001b[39mviews[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mactiveTab \u001b[38;5;241m=\u001b[39m active\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\openpyxl\\workbook\\_writer.py:35\u001b[0m, in \u001b[0;36mget_active_sheet\u001b[1;34m(wb)\u001b[0m\n\u001b[0;32m     33\u001b[0m visible_sheets \u001b[38;5;241m=\u001b[39m [idx \u001b[38;5;28;01mfor\u001b[39;00m idx, sheet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(wb\u001b[38;5;241m.\u001b[39m_sheets) \u001b[38;5;28;01mif\u001b[39;00m sheet\u001b[38;5;241m.\u001b[39msheet_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisible\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m visible_sheets:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one sheet must be visible\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m idx \u001b[38;5;241m=\u001b[39m wb\u001b[38;5;241m.\u001b[39m_active_sheet_index\n\u001b[0;32m     38\u001b[0m sheet \u001b[38;5;241m=\u001b[39m wb\u001b[38;5;241m.\u001b[39mactive\n",
      "\u001b[1;31mIndexError\u001b[0m: At least one sheet must be visible"
     ]
    }
   ],
   "source": [
    "modified_code = response.split(\"```python\")[-1].split(\"```\")[0]\n",
    "print(f\"[LOG] 실행할 코드:\\n{modified_code}\")\n",
    "exec(modified_code, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 데이터 로드 시작...\n",
      "✅ 'cust_enroll_history' 데이터 로드 완료\n",
      "✅ 'cust_intg' 데이터 로드 완료\n",
      "✅ 'product_info' 데이터 로드 완료\n",
      "📊 총 3 개의 데이터프레임 로드 완료\n",
      "\n",
      "✅ 프롬프트 및 함수 코드 로드 완료\n",
      "\n",
      "🤖 LLM에 코드 생성 요청 중...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'list_df_text'}.  Expected: ['func_code', 'list_df_text'] Received: ['func_code', 'list_df']\\nNote: if you intended {list_df_text} to be part of the string and not a variable, please escape it with double curly braces like: '{{list_df_text}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# ✅ LLM에 첫 번째 코드 요청\u001b[39;00m\n\u001b[0;32m     64\u001b[0m chain \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m     65\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, prompt),\n\u001b[0;32m     66\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### 참고 코드:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{func_code}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     67\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### list_df:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{list_df_text}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m ]) \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m---> 70\u001b[0m response \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: func_code, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_df\u001b[39m\u001b[38;5;124m\"\u001b[39m: list_df_text})\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     72\u001b[0m attempt_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     73\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3014\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3012\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3014\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3016\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:210\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    209\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_prompt_with_error_handling,\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    213\u001b[0m     config,\n\u001b[0;32m    214\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m     serialized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m    216\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1914\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1910\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1911\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1912\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1913\u001b[0m         Output,\n\u001b[1;32m-> 1914\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1915\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1916\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1918\u001b[0m             config,\n\u001b[0;32m   1919\u001b[0m             run_manager,\n\u001b[0;32m   1920\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1921\u001b[0m         ),\n\u001b[0;32m   1922\u001b[0m     )\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1924\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:184\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 184\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:178\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    172\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    173\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m     )\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'list_df_text'}.  Expected: ['func_code', 'list_df_text'] Received: ['func_code', 'list_df']\\nNote: if you intended {list_df_text} to be part of the string and not a variable, please escape it with double curly braces like: '{{list_df_text}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import traceback\n",
    "import json\n",
    "\n",
    "# ✅ LangGraph 및 LangChain 관련 모듈\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# ✅ 환경 설정\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "# ✅ OpenAI API Key 확인\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_api_key, temperature=0)\n",
    "\n",
    "# ✅ 결과 저장을 위한 객체 선언\n",
    "results = {}\n",
    "list_df = {}\n",
    "\n",
    "print(\"🔄 데이터 로드 시작...\")\n",
    "# ✅ 데이터 로드: ../data 경로의 모든 pkl 파일 읽기\n",
    "data_path = os.path.join('..', 'data')\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.pkl'):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        df_name = file.replace('.pkl', '')\n",
    "        list_df[df_name] = pd.read_pickle(file_path)\n",
    "        print(f\"✅ '{df_name}' 데이터 로드 완료\")\n",
    "\n",
    "list_df_text = \", \".join(list_df.keys())\n",
    "print(f\"📊 총 {len(list_df)} 개의 데이터프레임 로드 완료\\n\")\n",
    "\n",
    "# ✅ 프롬프트 및 함수 코드 불러오기\n",
    "prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)\n",
    "func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()\n",
    "print(\"✅ 프롬프트 및 함수 코드 로드 완료\\n\")\n",
    "\n",
    "def get_detailed_error_info(e):\n",
    "    \"\"\"에러에 대한 상세 정보를 반환하는 함수\"\"\"\n",
    "    error_type = type(e).__name__\n",
    "    error_msg = str(e)\n",
    "    error_traceback = traceback.format_exc()\n",
    "    \n",
    "    return {\n",
    "        \"error_type\": error_type,\n",
    "        \"error_message\": error_msg,\n",
    "        \"traceback\": error_traceback,\n",
    "        \"context\": {\n",
    "            \"locals\": str(locals()),\n",
    "            \"globals\": str([k for k in globals().keys() if not k.startswith('_')])\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"🤖 LLM에 코드 생성 요청 중...\")\n",
    "\n",
    "# ✅ LLM에 첫 번째 코드 요청\n",
    "chain = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"### 참고 코드:\\n{func_code}\\n\\n\"),\n",
    "    (\"user\", \"### list_df:\\n{list_df_text}\\n\\n\")\n",
    "]) | llm\n",
    "\n",
    "response = chain.invoke({\"func_code\": func_code, \"list_df_text\": list_df_text}).content\n",
    "\n",
    "attempt_count = 0\n",
    "success = False\n",
    "\n",
    "while attempt_count < 2:\n",
    "    try:\n",
    "        if \"```python\" in response:\n",
    "            modified_code = response.split(\"```python\")[-1].split(\"```\")[0]\n",
    "            print(f\"[LOG] 실행할 코드:\\n{modified_code}\")\n",
    "            exec(modified_code, globals())\n",
    "            print(f\"[Stage 1. 데이터 구조 파악] {attempt_count+1}차 시도 | ✅ 성공적으로 실행되었습니다!\")\n",
    "            success = True\n",
    "            break\n",
    "    except Exception as e:\n",
    "        error_info = get_detailed_error_info(e)\n",
    "        print(f\"\\n❌ {attempt_count+1}차 시도 실행 실패\")\n",
    "        print(f\"🔍 에러 타입: {error_info['error_type']}\")\n",
    "        print(f\"📝 에러 메시지: {error_info['error_message']}\")\n",
    "        print(\"\\n🔍 스택 트레이스:\")\n",
    "        print(error_info['traceback'])\n",
    "\n",
    "        if attempt_count == 0:\n",
    "            print(\"\\n🔄 에러 분석 및 코드 수정 요청 중...\")\n",
    "            \n",
    "            # ✅ 에러 분석을 위한 프롬프트 템플릿\n",
    "            ERROR_ANALYSIS_PROMPT = open(f'prompt/99.prompt_error_python.txt', 'r', encoding='utf-8').read().format(\n",
    "                error_type= error_info['error_type'],\n",
    "                error_message = error_info['error_message'],\n",
    "                traceback = error_info['traceback'],\n",
    "                context = error_info['context']\n",
    "            )\n",
    "            \n",
    "            # 에러 분석 전문 프롬프트로 요청\n",
    "            chain_error_analysis = ChatPromptTemplate.from_template(ERROR_ANALYSIS_PROMPT) | llm\n",
    "            \n",
    "            error_analysis_response = chain_error_analysis.invoke({\n",
    "                \n",
    "            })\n",
    "            \n",
    "            response = error_analysis_response.content\n",
    "            print(\"\\n✏️ LLM의 에러 분석 및 수정 제안:\")\n",
    "            print(response)\n",
    "        else:\n",
    "            print(\"\\n❌ 최대 재시도 횟수 초과. 프로세스를 중단합니다.\")\n",
    "            \n",
    "        attempt_count += 1\n",
    "\n",
    "# ✅ Stage 1 결과 파일 로드 (엑셀)\n",
    "print(\"\\n🔄 Stage 1 결과 파일 로드 중...\")\n",
    "stage1_path = \"../output/stage1/eda_summary.xlsx\"\n",
    "if os.path.exists(stage1_path):\n",
    "    stage1_results = pd.read_excel(stage1_path, sheet_name=0)\n",
    "    results[\"stage1\"] = stage1_results\n",
    "    print(f\"✅ Stage 1 결과 로드 완료 (총 {len(stage1_results)} 개 행)\")\n",
    "else:\n",
    "    print(\"❌ Stage 1 결과 파일이 존재하지 않습니다.\")\n",
    "    raise FileNotFoundError(\"Stage 1 결과 파일을 찾을 수 없습니다.\")\n",
    "\n",
    "# ✅ RAG 기반 컬럼 설명 추가\n",
    "def load_vectorstore():\n",
    "    if os.path.exists(\"./vectordb\"):\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        try:\n",
    "            return FAISS.load_local(\"./vectordb\", embeddings, allow_dangerous_deserialization=True)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 벡터스토어 로드 중 오류 발생: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "print(\"\\n🔄 벡터스토어 로드 중...\")\n",
    "vectorstore = load_vectorstore()\n",
    "if vectorstore:\n",
    "    print(\"✅ 벡터스토어 로드 완료\")\n",
    "else:\n",
    "    print(\"⚠️ 벡터스토어 로드 실패\")\n",
    "\n",
    "def search_column_descriptions(col_desc_df, vectorstore):\n",
    "    \"\"\"RAG를 사용하여 컬럼 설명을 검색하는 함수\"\"\"\n",
    "    data = []\n",
    "    df_after_llm = col_desc_df[['데이터프레임명', '컬럼명']]\n",
    "    \n",
    "    for i, row in df_after_llm.iterrows():\n",
    "        table_name = row['데이터프레임명']\n",
    "        col = row['컬럼명']\n",
    "        \n",
    "        search_query = f\"테이블명 : {table_name} | 컬럼명 : {col}\"\n",
    "        docs = vectorstore.similarity_search(search_query, k=1)\n",
    "        \n",
    "        if docs:\n",
    "            best_match = docs[0].page_content\n",
    "            data.append({\n",
    "                '데이터프레임명': table_name,\n",
    "                '컬럼명': col,\n",
    "                '컬럼설명': best_match.split('\\n')[3].split('설명')[1].strip()\n",
    "            })\n",
    "        else:\n",
    "            data.append({\n",
    "                '데이터프레임명': table_name,\n",
    "                '컬럼명': col,\n",
    "                '컬럼설명': \"설명 없음\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "print(\"\\n🔄 RAG 기반 컬럼 설명 검색 시작...\")\n",
    "# ✅ Stage 2: RAG 기반 컬럼 설명 추가\n",
    "rag_results = search_column_descriptions(stage1_results, vectorstore)\n",
    "print(f\"✅ RAG 검색 완료 (총 {len(rag_results)} 개 컬럼에 대한 설명 추가)\")\n",
    "\n",
    "print(\"\\n🔄 최종 결과 통합 중...\")\n",
    "# ✅ Stage 1 결과와 RAG 결과를 통합\n",
    "final_df = pd.merge(\n",
    "    stage1_results,\n",
    "    rag_results,\n",
    "    on=['데이터프레임명', '컬럼명'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ✅ 최종 결과를 메모리 내 저장\n",
    "results[\"stage2\"] = final_df\n",
    "print(f\"✅ 최종 결과 통합 완료 (총 {len(final_df)} 개 행)\")\n",
    "\n",
    "print(\"\\n✨ 모든 단계가 성공적으로 완료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
