{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_data_info        데이터프레임명         컬럼명   데이터 타입   count        mean         std  \\\n",
      "0    cust_intg        고객ID    int64  120000    43126.17    33176.95   \n",
      "1    cust_intg          나이   object  120000         NaN         NaN   \n",
      "2    cust_intg          성별   object  120000         NaN         NaN   \n",
      "3    cust_intg       수익자여부    int64  120000        0.89        0.31   \n",
      "4    cust_intg      CB신용평점  float64   14118      316.21      280.35   \n",
      "..         ...         ...      ...     ...         ...         ...   \n",
      "118  cust_intg    변액종신보유여부    int64  120000        0.06        0.24   \n",
      "119  cust_intg  변액종신최대납입회차  float64  120000       12.36       12.87   \n",
      "120  cust_intg   변액종신유지계약수  float64  120000        0.08        0.29   \n",
      "121  cust_intg  변액종신기납입보험료  float64  120000  3124802.54  3134004.52   \n",
      "122  cust_intg        기준년월    int64  120000   202407.50        1.71   \n",
      "\n",
      "           min        25%         75%          max   결측 개수  결측치 비율  고유값 개수  \\\n",
      "0         1.00   14297.25    69490.25    100000.00       0       0   15474   \n",
      "1          NaN        NaN         NaN          NaN       0       0       9   \n",
      "2          NaN        NaN         NaN          NaN       0       0       2   \n",
      "3         0.00       1.00        1.00         1.00       0       0       2   \n",
      "4         0.00      95.16      457.66      1049.57  105882      88   12570   \n",
      "..         ...        ...         ...          ...     ...     ...     ...   \n",
      "118       0.00       0.00        0.00         1.00       0       0       2   \n",
      "119       0.00       3.05       17.39       128.89       0       0    6011   \n",
      "120       0.00       0.00        0.00         4.19       0       0      69   \n",
      "121     236.16  907729.04  4313038.50  43303564.47       0       0  119992   \n",
      "122  202405.00  202406.00   202409.00    202410.00       0       0       6   \n",
      "\n",
      "                                              인스턴스(예제)  \\\n",
      "0                                                  NaN   \n",
      "1    ['60대', '40대', '50대', '30대', '20대', '10세미만', '...   \n",
      "2                                         ['여성', '남성']   \n",
      "3                                                  NaN   \n",
      "4                                                  NaN   \n",
      "..                                                 ...   \n",
      "118                                                NaN   \n",
      "119                                                NaN   \n",
      "120                                                NaN   \n",
      "121                                                NaN   \n",
      "122                                                NaN   \n",
      "\n",
      "                                                범주형 분포  \\\n",
      "0                                                  NaN   \n",
      "1    {'50대': 31.2, '40대': 30.53, '30대': 16.98, '20대...   \n",
      "2                           {'여성': 52.44, '남성': 47.56}   \n",
      "3                                                  NaN   \n",
      "4                                                  NaN   \n",
      "..                                                 ...   \n",
      "118                                                NaN   \n",
      "119                                                NaN   \n",
      "120                                                NaN   \n",
      "121                                                NaN   \n",
      "122                                                NaN   \n",
      "\n",
      "                                컬럼설명  \n",
      "0          : 개별 고객을 식별하기 위한 고유 식별 번호  \n",
      "1                        : 고객의 현재 연령  \n",
      "2                     : 고객의 성별 (남/여)  \n",
      "3                  : 고객이 보험 수익자인지 여부  \n",
      "4    : CB(Credit Bureau) 기준 고객의 신용평점  \n",
      "..                               ...  \n",
      "118          : 변액 종신 보험을 보유하고 있는지 여부  \n",
      "119             : 변액 종신 보험의 최대 납입 회차  \n",
      "120            : 유지 중인 변액 종신 보험 계약 수  \n",
      "121           : 변액 종신 보험에 납입된 보험료 총액  \n",
      "122               : 당월 신규로 가입한 고객 여부  \n",
      "\n",
      "[123 rows x 16 columns]\n",
      "✅ 그래프 컴파일 완료\n",
      "\n",
      "✅ 1개의 데이터프레임이 성공적으로 설정되었습니다.\n",
      "📊 데이터마트 이름: cust_intg\n",
      "🔹 데이터 크기: 120000행 x 123열\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from ai_agent_v2 import DataAnayticsAssistant\n",
    "\n",
    "# OpenAI API 키 로드\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "PROCESSED_DATA_PATH = \"../output/stage1/processed_data_info.xlsx\"\n",
    "mart_name = \"cust_intg\"\n",
    "def load_processed_data_info():\n",
    "    \"\"\"사전에 분석된 데이터 정보 로드\"\"\"\n",
    "    if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "        return None\n",
    "    else:\n",
    "        # 모든 시트 로드\n",
    "        return pd.read_excel(PROCESSED_DATA_PATH, sheet_name=mart_name)\n",
    "\n",
    "\n",
    "# ✅ Streamlit 실행 시 데이터 로드\n",
    "processed_data_info = load_processed_data_info()\n",
    "\n",
    "# 어시스턴트 초기화\n",
    "assistant = DataAnayticsAssistant(openai_api_key, processed_data_info )\n",
    "\n",
    "df = pd.read_pickle(f'../data/{mart_name}.pkl')\n",
    "\n",
    "# 데이터프레임 설정\n",
    "assistant.set_active_mart(df, mart_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 새로운 요청 처리 시작: '주요 변수를 선택하여 랜덤포레스트 기반 특징 중요도를 계산해 주세요.'\n",
      "\n",
      "====================================================================================================\n",
      "👨‍💼 Supervisor 단계:\n",
      "🏃🏿‍➡️ 다음 단계: Analytics\n",
      "\n",
      "📊 [handle_analytics] 분석 요청 처리 시작\n",
      "현재 데이터 정보:\n",
      " <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "====================================================================================================\n",
      "🤖 코드 생성 단계:\n",
      "✨ 생성된 코드:\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# 데이터 전처리\n",
      "df = df.dropna(subset=['수익자여부'])  # 타겟 변수가 NaN인 경우 제거\n",
      "y = df['수익자여부']\n",
      "X = df.drop(columns=['고객ID', '수익자여부', '기준년월'])\n",
      "\n",
      "# 범주형 변수 인코딩\n",
      "for column in X.select_dtypes(include=['object']).columns:\n",
      "    le = LabelEncoder()\n",
      "    X[column] = le.fit_transform(X[column].astype(str))\n",
      "\n",
      "# 결측값 처리\n",
      "X = X.fillna(X.mean())\n",
      "\n",
      "# 랜덤 포레스트 모델 초기화\n",
      "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "\n",
      "# 모델 학습\n",
      "model.fit(X, y)\n",
      "\n",
      "# 특징 중요도 추출\n",
      "importances = model.feature_importances_\n",
      "\n",
      "# 중요도 데이터프레임 생성\n",
      "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
      "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
      "\n",
      "# 결과 저장\n",
      "result_df = feature_importances.reset_index(drop=True)\n",
      "```\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "📊 cust_intg: 50개 샘플 추출\n",
      "✅ 샘플 코드 실행 성공\n",
      "✅ 코드 검증 완료, 전체 데이터 실행으로 진행합니다\n",
      "\n",
      "====================================================================================================\n",
      "📊 전체 데이터 실행 단계:\n",
      "🔹 전체 데이터 실행 환경에 추가된 데이터프레임 목록: ['df', 'cust_intg']\n",
      "🔄 전체 데이터 실행 결과\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미납보험료합계</td>\n",
       "      <td>0.027759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>변액종신기납입보험료</td>\n",
       "      <td>0.027639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>보험계약대출잔액합계</td>\n",
       "      <td>0.026451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>변액종신CMIP</td>\n",
       "      <td>0.026389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>변액기납입보험료</td>\n",
       "      <td>0.025921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "0     미납보험료합계    0.027759\n",
       "1  변액종신기납입보험료    0.027639\n",
       "2  보험계약대출잔액합계    0.026451\n",
       "3    변액종신CMIP    0.026389\n",
       "4    변액기납입보험료    0.025921"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "📂 처리 데이터 저장 단계\n",
      "\n",
      "====================================================================================================\n",
      "🔄 인사이트 도출 단계:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미납보험료합계</td>\n",
       "      <td>0.027759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>변액종신기납입보험료</td>\n",
       "      <td>0.027639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>보험계약대출잔액합계</td>\n",
       "      <td>0.026451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>변액종신CMIP</td>\n",
       "      <td>0.026389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>변액기납입보험료</td>\n",
       "      <td>0.025921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "0     미납보험료합계    0.027759\n",
       "1  변액종신기납입보험료    0.027639\n",
       "2  보험계약대출잔액합계    0.026451\n",
       "3    변액종신CMIP    0.026389\n",
       "4    변액기납입보험료    0.025921"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌀 생성된 인사이트:\n",
      "1. 주요 발견사항:\n",
      "   - 이번 분석에서 가장 중요한 변수로 꼽힌 것은 '미납보험료합계'로, 중요도 점수가 0.027759입니다. 이는 보험계약자의 미납 보험료 상태가 보험 관련 의사결정이나 위험 평가에 큰 영향을 미칠 수 있음을 시사합니다.\n",
      "   - '변액종신기납입보험료'와 '보험계약대출잔액합계' 역시 높은 중요도를 가진 변수들로, 각각 0.027639와 0.026451의 점수를 기록했습니다. 이는 변수들이 보험 계약자의 경제적 상태나 보험 상품의 지속성에 크게 기여할 수 있다는 것을 암시합니다.\n",
      "   - '변액종신CMIP' 및 '변액기납입보험료'도 상대적으로 중요한 변수로 나타났으며, 이는 변액 보험료와 관련된 변수들이 계약자의 보험 계약 및 유지에 영향을 미칠 수 있음을 보여줍니다.\n",
      "\n",
      "2. 특이점:\n",
      "   - 각 변수의 중요도 차이가 크지 않으며, 모두 비슷한 범위 내에서 나타났습니다. 이는 분석 전반에 걸쳐 여러 변수가 대부분의 모델 성능에 기여하고 있다는 것을 의미할 수 있습니다.\n",
      "   - 특히 변액보험 관련 변수들이 중요도 순위 상위에 집중되어 있어, 변액보험 상품의 특성이나 계약자 행동이 매우 중요한 역할을 하고 있을 가능성이 있습니다.\n",
      "\n",
      "3. 추천 사항:\n",
      "   - 미납보험료와 관련된 리스크를 더욱 세밀하게 관리하기 위한 추가 분석이 필요할 수 있습니다. 이를 통해 해당 변수가 보험 손익에 미치는 영향을 더욱 명확히 이해할 수 있습니다.\n",
      "   - 변액보험 관련 변수들이 중요하게 나타난 만큼, 변액보험 상품의 설계 및 관리에 대한 전략을 재검토할 필요가 있습니다. 특히 변액종신보험과 관련된 요인을 심층 분석하여 고객 맞춤형 상품 제공 및 유지 전략을 마련해야 합니다.\n",
      "   - '보험계약대출잔액합계'의 중요성을 고려할 때, 계약자 대출과 관련된 리스크 평가 및 관리 방안을 강화하는 것도 추천합니다. 대출 상환 능력에 대한 정교한 평가 기준을 마련하면, 장기적인 손실을 줄일 수 있을 것입니다.\n",
      "🌀 차트 필요 여부: 'yes'\n",
      "\n",
      "====================================================================================================\n",
      "🔄 인사이트 라우팅 단계\n",
      "📝 보고서 생성 단계로 진행합니다\n",
      "\n",
      "====================================================================================================\n",
      "📑 보고서 생성 단계:\n",
      "✅ 보고서 생성 완료\n",
      "[HumanMessage(content='주요 변수를 선택하여 랜덤포레스트 기반 특징 중요도를 계산해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# 데이터 전처리\n",
      "df = df.dropna(subset=['수익자여부'])  # 타겟 변수가 NaN인 경우 제거\n",
      "y = df['수익자여부']\n",
      "X = df.drop(columns=['고객ID', '수익자여부', '기준년월'])\n",
      "\n",
      "# 범주형 변수 인코딩\n",
      "for column in X.select_dtypes(include=['object']).columns:\n",
      "    le = LabelEncoder()\n",
      "    X[column] = le.fit_transform(X[column].astype(str))\n",
      "\n",
      "# 결측값 처리\n",
      "X = X.fillna(X.mean())\n",
      "\n",
      "# 랜덤 포레스트 모델 초기화\n",
      "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "\n",
      "# 모델 학습\n",
      "model.fit(X, y)\n",
      "\n",
      "# 특징 중요도 추출\n",
      "importances = model.feature_importances_\n",
      "\n",
      "# 중요도 데이터프레임 생성\n",
      "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
      "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
      "\n",
      "# 결과 저장\n",
      "result_df = feature_importances.reset_index(drop=True)\n",
      "```\n",
      "1. 주요 발견사항:\n",
      "   - 이번 분석에서 가장 중요한 변수로 꼽힌 것은 '미납보험료합계'로, 중요도 점수가 0.027759입니다. 이는 보험계약자의 미납 보험료 상태가 보험 관련 의사결정이나 위험 평가에 큰 영향을 미칠 수 있음을 시사합니다.\n",
      "   - '변액종신기납입보험료'와 '보험계약대출잔액합계' 역시 높은 중요도를 가진 변수들로, 각각 0.027639와 0.026451의 점수를 기록했습니다. 이는 변수들이 보험 계약자의 경제적 상태나 보험 상품의 지속성에 크게 기여할 수 있다는 것을 암시합니다.\n",
      "   - '변액종신CMIP' 및 '변액기납입보험료'도 상대적으로 중요한 변수로 나타났으며, 이는 변액 보험료와 관련된 변수들이 계약자의 보험 계약 및 유지에 영향을 미칠 수 있음을 보여줍니다.\n",
      "\n",
      "2. 특이점:\n",
      "   - 각 변수의 중요도 차이가 크지 않으며, 모두 비슷한 범위 내에서 나타났습니다. 이는 분석 전반에 걸쳐 여러 변수가 대부분의 모델 성능에 기여하고 있다는 것을 의미할 수 있습니다.\n",
      "   - 특히 변액보험 관련 변수들이 중요도 순위 상위에 집중되어 있어, 변액보험 상품의 특성이나 계약자 행동이 매우 중요한 역할을 하고 있을 가능성이 있습니다.\n",
      "\n",
      "3. 추천 사항:\n",
      "   - 미납보험료와 관련된 리스크를 더욱 세밀하게 관리하기 위한 추가 분석이 필요할 수 있습니다. 이를 통해 해당 변수가 보험 손익에 미치는 영향을 더욱 명확히 이해할 수 있습니다.\n",
      "   - 변액보험 관련 변수들이 중요하게 나타난 만큼, 변액보험 상품의 설계 및 관리에 대한 전략을 재검토할 필요가 있습니다. 특히 변액종신보험과 관련된 요인을 심층 분석하여 고객 맞춤형 상품 제공 및 유지 전략을 마련해야 합니다.\n",
      "   - '보험계약대출잔액합계'의 중요성을 고려할 때, 계약자 대출과 관련된 리스크 평가 및 관리 방안을 강화하는 것도 추천합니다. 대출 상환 능력에 대한 정교한 평가 기준을 마련하면, 장기적인 손실을 줄일 수 있을 것입니다.\n",
      "# 분석 보고서\n",
      "\n",
      "## 1. 요약\n",
      "\n",
      "이번 보고서는 랜덤포레스트 알고리즘을 사용하여 보험 데이터의 특징 중요도를 분석한 결과를 종합한 것입니다. 분석 결과, '미납보험료합계'가 가장 중요한 변수로 나타났으며, 다른 변수들도 보험 계약자의 경제적 상태 및 보험 상품의 지속성에 중요한 영향을 미칠 수 있음을 보여줍니다.\n",
      "\n",
      "## 2. 분석 방법\n",
      "\n",
      "- **데이터 수집**: 분석에 사용된 원본 데이터는 미납보험료, 변액종신기납입보험료, 보험계약대출잔액 등을 포함한 여러 특징들을 담고 있습니다.\n",
      "- **특징 중요도 평가**: 랜덤포레스트 모델을 통해 각 변수의 중요도를 계산하였습니다. 랜덤포레스트는 다수의 의사결정트리를 사용하여 변수의 중요도를 평가하는 데 용이한 방법입니다.\n",
      "\n",
      "## 3. 주요 발견사항\n",
      "\n",
      "1. **중요한 변수 식별**:\n",
      "   - '미납보험료합계'는 가장 중요한 변수로, 그 중요도 점수는 0.027759로 나타났습니다. 이는 보험 계약자의 미납 보험료 상태가 전체 보험 의사결정 프로세스에 중요한 영향을 미친다는 것을 의미합니다.\n",
      "   - '변액종신기납입보험료'와 '보험계약대출잔액합계'도 각각 중요도 0.027639 및 0.026451로 높은 중요도를 가지며, 보험 상품의 지속성에 관련이 깊음을 시사합니다.\n",
      "   - 변액보험과 관련된 변수가 중요도에서 상위권을 차지하여, 이들이 계약자의 행동이나 보험 상품 관리에서 중요한 역할을 할 수 있음을 보여줍니다.\n",
      "\n",
      "2. **특이점**:\n",
      "   - 변수의 중요도 차이가 크지 않아 여러 변수가 모델 성능에 균일하게 기여하고 있음을 알 수 있습니다.\n",
      "   - 변액보험 관련 변수들이 중요 변수로 집중된 것은 이는 상품의 특성상 복잡한 고객 행동 분석이 필요함을 암시합니다.\n",
      "\n",
      "## 4. 결론 및 제언\n",
      "\n",
      "- **미납보험료 관리**: 미납보험료가 중요한 리스크 요인으로 나타났으므로, 해당 변수를 보다 철저히 분석하여 보험 손익에 미치는 영향을 이해할 필요가 있습니다.\n",
      "- **변액보험 전략 재검토**: 변액보험 관련 변수가 중요하게 나타난 만큼 상품 설계 및 관리 전략을 검토하고, 고객 친화적인 맞춤형 상품 및 전략을 수립해야 합니다.\n",
      "- **대출 리스크 관리**: '보험계약대출잔액합계'의 중요성을 고려하여, 대출에 대한 리스크 평가 및 관리 방안을 강화하는 것이 추천됩니다. 이를 통해 대출에 따른 장기적인 손실을 최소화할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "result = assistant.ask(f\"\"\"주요 변수를 선택하여 랜덤포레스트 기반 특징 중요도를 계산해 주세요.\"\"\")\n",
    "print(result['messages'])\n",
    "print(result['validated_code'])\n",
    "print(result['insights'])\n",
    "print(result['report_filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####messages:\n",
      "  주요 변수를 선택하여 랜덤포레스트 기반 특징 중요도를 계산해 주세요.\n",
      "#####validated_code:\n",
      "  ```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# 데이터 전처리\n",
      "df = df.dropna(subset=['수익자여부'])  # 타겟 변수가 NaN인 경우 제거\n",
      "y = df['수익자여부']\n",
      "X = df.drop(columns=['고객ID', '수익자여부', '기준년월'])\n",
      "\n",
      "# 범주형 변수 인코딩\n",
      "for column in X.select_dtypes(include=['object']).columns:\n",
      "    le = LabelEncoder()\n",
      "    X[column] = le.fit_transform(X[column].astype(str))\n",
      "\n",
      "# 결측값 처리\n",
      "X = X.fillna(X.mean())\n",
      "\n",
      "# 랜덤 포레스트 모델 초기화\n",
      "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "\n",
      "# 모델 학습\n",
      "model.fit(X, y)\n",
      "\n",
      "# 특징 중요도 추출\n",
      "importances = model.feature_importances_\n",
      "\n",
      "# 중요도 데이터프레임 생성\n",
      "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
      "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
      "\n",
      "# 결과 저장\n",
      "result_df = feature_importances.reset_index(drop=True)\n",
      "```\n",
      "#####insights:\n",
      "  1. 주요 발견사항:\n",
      "   - 이번 분석에서 가장 중요한 변수로 꼽힌 것은 '미납보험료합계'로, 중요도 점수가 0.027759입니다. 이는 보험계약자의 미납 보험료 상태가 보험 관련 의사결정이나 위험 평가에 큰 영향을 미칠 수 있음을 시사합니다.\n",
      "   - '변액종신기납입보험료'와 '보험계약대출잔액합계' 역시 높은 중요도를 가진 변수들로, 각각 0.027639와 0.026451의 점수를 기록했습니다. 이는 변수들이 보험 계약자의 경제적 상태나 보험 상품의 지속성에 크게 기여할 수 있다는 것을 암시합니다.\n",
      "   - '변액종신CMIP' 및 '변액기납입보험료'도 상대적으로 중요한 변수로 나타났으며, 이는 변액 보험료와 관련된 변수들이 계약자의 보험 계약 및 유지에 영향을 미칠 수 있음을 보여줍니다.\n",
      "\n",
      "2. 특이점:\n",
      "   - 각 변수의 중요도 차이가 크지 않으며, 모두 비슷한 범위 내에서 나타났습니다. 이는 분석 전반에 걸쳐 여러 변수가 대부분의 모델 성능에 기여하고 있다는 것을 의미할 수 있습니다.\n",
      "   - 특히 변액보험 관련 변수들이 중요도 순위 상위에 집중되어 있어, 변액보험 상품의 특성이나 계약자 행동이 매우 중요한 역할을 하고 있을 가능성이 있습니다.\n",
      "\n",
      "3. 추천 사항:\n",
      "   - 미납보험료와 관련된 리스크를 더욱 세밀하게 관리하기 위한 추가 분석이 필요할 수 있습니다. 이를 통해 해당 변수가 보험 손익에 미치는 영향을 더욱 명확히 이해할 수 있습니다.\n",
      "   - 변액보험 관련 변수들이 중요하게 나타난 만큼, 변액보험 상품의 설계 및 관리에 대한 전략을 재검토할 필요가 있습니다. 특히 변액종신보험과 관련된 요인을 심층 분석하여 고객 맞춤형 상품 제공 및 유지 전략을 마련해야 합니다.\n",
      "   - '보험계약대출잔액합계'의 중요성을 고려할 때, 계약자 대출과 관련된 리스크 평가 및 관리 방안을 강화하는 것도 추천합니다. 대출 상환 능력에 대한 정교한 평가 기준을 마련하면, 장기적인 손실을 줄일 수 있을 것입니다.\n",
      "#####report_filename:\n",
      "  # 분석 보고서\n",
      "\n",
      "## 1. 요약\n",
      "\n",
      "이번 보고서는 랜덤포레스트 알고리즘을 사용하여 보험 데이터의 특징 중요도를 분석한 결과를 종합한 것입니다. 분석 결과, '미납보험료합계'가 가장 중요한 변수로 나타났으며, 다른 변수들도 보험 계약자의 경제적 상태 및 보험 상품의 지속성에 중요한 영향을 미칠 수 있음을 보여줍니다.\n",
      "\n",
      "## 2. 분석 방법\n",
      "\n",
      "- **데이터 수집**: 분석에 사용된 원본 데이터는 미납보험료, 변액종신기납입보험료, 보험계약대출잔액 등을 포함한 여러 특징들을 담고 있습니다.\n",
      "- **특징 중요도 평가**: 랜덤포레스트 모델을 통해 각 변수의 중요도를 계산하였습니다. 랜덤포레스트는 다수의 의사결정트리를 사용하여 변수의 중요도를 평가하는 데 용이한 방법입니다.\n",
      "\n",
      "## 3. 주요 발견사항\n",
      "\n",
      "1. **중요한 변수 식별**:\n",
      "   - '미납보험료합계'는 가장 중요한 변수로, 그 중요도 점수는 0.027759로 나타났습니다. 이는 보험 계약자의 미납 보험료 상태가 전체 보험 의사결정 프로세스에 중요한 영향을 미친다는 것을 의미합니다.\n",
      "   - '변액종신기납입보험료'와 '보험계약대출잔액합계'도 각각 중요도 0.027639 및 0.026451로 높은 중요도를 가지며, 보험 상품의 지속성에 관련이 깊음을 시사합니다.\n",
      "   - 변액보험과 관련된 변수가 중요도에서 상위권을 차지하여, 이들이 계약자의 행동이나 보험 상품 관리에서 중요한 역할을 할 수 있음을 보여줍니다.\n",
      "\n",
      "2. **특이점**:\n",
      "   - 변수의 중요도 차이가 크지 않아 여러 변수가 모델 성능에 균일하게 기여하고 있음을 알 수 있습니다.\n",
      "   - 변액보험 관련 변수들이 중요 변수로 집중된 것은 이는 상품의 특성상 복잡한 고객 행동 분석이 필요함을 암시합니다.\n",
      "\n",
      "## 4. 결론 및 제언\n",
      "\n",
      "- **미납보험료 관리**: 미납보험료가 중요한 리스크 요인으로 나타났으므로, 해당 변수를 보다 철저히 분석하여 보험 손익에 미치는 영향을 이해할 필요가 있습니다.\n",
      "- **변액보험 전략 재검토**: 변액보험 관련 변수가 중요하게 나타난 만큼 상품 설계 및 관리 전략을 검토하고, 고객 친화적인 맞춤형 상품 및 전략을 수립해야 합니다.\n",
      "- **대출 리스크 관리**: '보험계약대출잔액합계'의 중요성을 고려하여, 대출에 대한 리스크 평가 및 관리 방안을 강화하는 것이 추천됩니다. 이를 통해 대출에 따른 장기적인 손실을 최소화할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(f\"#####   messages:\\n  {result['messages'][0].content}\")\n",
    "print(f\"#####   validated_code:\\n  {result['validated_code']}\")\n",
    "print(f\"#####   insights:\\n  {result['insights']}\")\n",
    "print(f\"#####   report_filename:\\n  {result['report_filename']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 보고서\n",
      "\n",
      "## 1. 요약\n",
      "\n",
      "이 보고서는 다양한 고객 데이터 정보를 가지고, 해당 데이터를 심층 분석하기 위한 기초 인사이트를 제공합니다. 데이터를 검토한 결과, 고객의 보험 계약 유지 패턴, 상품 선호도, 채널 선호도 분석이 가능하며, 이러한 정보를 통해 효율적인 마케팅 전략과 고객 유지 활동을 지원할 수 있습니다. 다만, 데이터의 특성상 결측치가 많은 일부 컬럼에 대한 추가적인 검토가 필요하며, 데이터의 일관성 및 최신성을 보장하기 위한 조치가 필요합니다.\n",
      "\n",
      "## 2. 분석 방법\n",
      "\n",
      "데이터프레임에서 불필요한 컬럼을 제거하여 데이터의 핵심 요소를 검토했습니다. 주요 분석 포인트는 고객의 인구통계학적 정보와 보험 상품 관련 정보, 그리고 다양한 채널별 활동 및 계약 정보입니다. 결측치가 많은 컬럼의 경우, 대체할 수 있는 전략과 결측치의 원인을 파악하는 데 주안점을 두었습니다. 전체 데이터를 기반으로 고객의 행동 패턴과 선호도를 분석하여 향후 마케팅 전략과 데이터 활용 방법을 제시하였습니다.\n",
      "\n",
      "## 3. 주요 발견사항\n",
      "\n",
      "- **다양한 정보 포함:** 고객 데이터는 다양한 채널 활동과 계약 정보, 지급 이력 및 보험 상품 관련 정보를 포함해, 고객 행동 분석에 적합한 기반을 제공합니다.\n",
      "- **결측치 존재:** CB신용평점, 직업분류명 등의 컬럼에 결측치가 많아 이를 보완하기 위한 추가 분석 또는 데이터 처리가 필요합니다.\n",
      "- **데이터 특성:** 특정 데이터가 [OLD] 표시로 확인되어, 데이터의 최신 여부와 향후 업데이트 필요성을 검토해야 합니다.\n",
      "- **분석 잠재력:** 채널별 활동 여부 및 계약 정보를 통해 고객의 선호도를 분석하여, 차별화된 마케팅 전략을 수립할 수 있는 가능성을 제공합니다.\n",
      "\n",
      "## 4. 결론 및 제언\n",
      "\n",
      "- **결측치 처리:** CB신용평점과 같은 주요 컬럼의 결측치를 대체하거나 그 원인을 분석하여 추가적인 가치를 도출할 필요가 있습니다.\n",
      "- **데이터 업데이트:** [OLD]로 표시된 데이터가 포함된 부분의 갱신을 통해 데이터의 일관성과 최신성을 확보해야 합니다.\n",
      "- **인구통계학적 데이터 활용:** 외부 데이터 소스를 결합하여 고객 세그멘테이션을 강화하여 보다 정교한 마케팅 전략을 수립하십시오.\n",
      "- **채널 선호도 분석:** 고객의 채널 선호도 및 유지율을 분석하여 맞춤형 마케팅 전략 또는 서비스 개선 방안을 마련하세요. 방카채널 사용이 적은 고객군을 대상으로 한 마케팅 캠페인이 그 일환이 될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result['report_filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assistant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 분석 요청 실행\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43massistant\u001b[49m\u001b[38;5;241m.\u001b[39mask(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m제공한 데이터프레임을 이용하여 아래 각 단계별 항목에 대해 차례대로 적용 및 그 결과를 정리하고, \u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m각 단계는 데이터 분석가가 EDA(Exploratory Data Analysis)를 수행할 때 더욱 체계적이고 심층적으로 접근할 수 있도록 해달라.\u001b[39m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m                       \u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m1. Remove Unnecessary Columns and List Up\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m데이터셋에서 모든 행에 대해 동일한 값을 가지는 열(예: 모든 행이 1인 열)을 식별하고 제거하세요. \u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m추가적으로, 분석 목적과 무관하거나 중복된 정보를 제공하는 열도 제거 대상으로 고려하세요.\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m제거된 열 목록을 정리하고, 제거 이유를 간단히 설명하세요.\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m추가 고려사항:\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m열의 고유값(unique values)을 확인하여 모든 행이 동일한 값을 가지는지 검토하세요.\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m열의 의미와 분석 목적을 고려하여, 불필요한 열인지 판단하세요.\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m제거 전, 해당 열이 향후 모델링이나 분석에 사용될 가능성이 없는지 다시 한번 확인하세요.\u001b[39m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m2. Check for Missing Values\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m데이터셋의 각 열에 대해 결측값(missing values)이 있는지 확인하세요.\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m결측값이 발견된 경우, 해당 열의 데이터 분포와 결측값의 비율을 고려하여 적절한 처리 전략을 제안하세요.\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124m단순히 0이나 평균값, 중앙값으로 대체하는 것은 지양하세요.\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m결측값 처리 방법: 삭제, 다중 대체법(Multiple Imputation), 예측 모델을 활용한 대체 등 상황에 맞는 방법을 선택하세요.\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m결측값 처리 후, 데이터의 무결성과 분석 결과에 미치는 영향을 검토하세요.\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m추가 고려사항:\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m결측값이 발생한 이유(MCAR, MAR, MNAR)를 고려하여 처리 방법을 결정하세요.\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124m범주형 변수의 경우, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 또는 \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m과 같은 새로운 카테고리를 추가하는 방법도 고려하세요.\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m결측값이 많은 열은 전체 데이터 품질에 영향을 미칠 수 있으므로, 열 자체를 제거하는 것도 고려하세요.\u001b[39m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m3. Data Type Consistency\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m데이터셋의 각 열이 올바른 데이터 타입을 가지고 있는지 확인하세요.\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124m범주형 변수(categorical variables)는 object 또는 category 타입으로 변환하세요.\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m수치형 변수(numerical variables)는 int 또는 float 타입으로 변환하세요.\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m날짜/시간 데이터는 datetime 타입으로 변환하세요.\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m잘못된 데이터 타입으로 인해 발생할 수 있는 문제(예: 수치형 데이터가 문자열로 저장된 경우)를 해결하세요.\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m데이터 타입 변환 시, 데이터 손실이나 오류가 발생하지 않도록 주의하세요.\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m범주형 변수의 경우, 고유값의 수를 확인하여 적절한 인코딩 방법(예: One-Hot Encoding, Label Encoding)을 선택하세요.\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m데이터 타입 변환 후, 데이터의 무결성을 다시 한번 검토하세요.\u001b[39m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;124m4. Duplicate Rows\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124m데이터셋에서 중복된 행(duplicate rows)이 있는지 확인하세요.\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124m중복된 행이 발견된 경우, 해당 행을 제거하세요.\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124m중복 행 제거 후, 데이터셋의 크기와 무결성을 검토하세요.\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124m추가 고려사항:\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124m중복 행을 제거하기 전, 중복이 발생한 이유를 분석하세요(예: 데이터 수집 오류, 병합 과정에서의 중복 등).\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124m특정 열을 기준으로 중복을 판단할 경우, 해당 열의 중요성을 고려하세요.\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124m중복 행 제거 후, 데이터셋의 균형(예: 클래스 불균형)이 깨지지 않았는지 확인하세요.\u001b[39m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124m5. Outlier Detection\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124m수치형 열에서 이상치(outliers)를 식별하세요.\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124m이상치를 처리하기 전, 해당 열의 도메인 지식과 데이터 분포를 고려하여 이상치가 실제로 유효한 값인지 판단하세요(예: 특정 직군의 높은 연봉).\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m이상치 처리 방법: 제거, 변환(예: 로그 변환), 또는 별도의 범주로 처리하는 방법을 고려하세요.\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124m이상치 처리 후, 데이터의 분포와 분석 결과에 미치는 영향을 검토하세요.\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124m추가 고려사항:\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124m이상치를 식별하기 위해 IQR(Interquartile Range), Z-score, 또는 시각화(예: 박스플롯)를 활용하세요.\u001b[39m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;124m이상치가 특정 패턴이나 의미를 가질 경우, 이를 별도로 분석하거나 모델링에 반영하세요.\u001b[39m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124m이상치 처리 방법을 선택할 때, 데이터의 특성과 분석 목적을 고려하세요.\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# 결과 확인\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'assistant' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 분석 요청 실행\n",
    "result = assistant.ask(f\"\"\"\n",
    "제공한 데이터프레임을 이용하여 아래 각 단계별 항목에 대해 차례대로 적용 및 그 결과를 정리하고, \n",
    "각 단계는 데이터 분석가가 EDA(Exploratory Data Analysis)를 수행할 때 더욱 체계적이고 심층적으로 접근할 수 있도록 해달라.\n",
    "\n",
    "                       \n",
    "1. Remove Unnecessary Columns and List Up\n",
    "데이터셋에서 모든 행에 대해 동일한 값을 가지는 열(예: 모든 행이 1인 열)을 식별하고 제거하세요. \n",
    "추가적으로, 분석 목적과 무관하거나 중복된 정보를 제공하는 열도 제거 대상으로 고려하세요.\n",
    "제거된 열 목록을 정리하고, 제거 이유를 간단히 설명하세요.\n",
    "추가 고려사항:\n",
    "열의 고유값(unique values)을 확인하여 모든 행이 동일한 값을 가지는지 검토하세요.\n",
    "열의 의미와 분석 목적을 고려하여, 불필요한 열인지 판단하세요.\n",
    "제거 전, 해당 열이 향후 모델링이나 분석에 사용될 가능성이 없는지 다시 한번 확인하세요.\n",
    "\n",
    "2. Check for Missing Values\n",
    "데이터셋의 각 열에 대해 결측값(missing values)이 있는지 확인하세요.\n",
    "결측값이 발견된 경우, 해당 열의 데이터 분포와 결측값의 비율을 고려하여 적절한 처리 전략을 제안하세요.\n",
    "단순히 0이나 평균값, 중앙값으로 대체하는 것은 지양하세요.\n",
    "결측값 처리 방법: 삭제, 다중 대체법(Multiple Imputation), 예측 모델을 활용한 대체 등 상황에 맞는 방법을 선택하세요.\n",
    "결측값 처리 후, 데이터의 무결성과 분석 결과에 미치는 영향을 검토하세요.\n",
    "추가 고려사항:\n",
    "결측값이 발생한 이유(MCAR, MAR, MNAR)를 고려하여 처리 방법을 결정하세요.\n",
    "범주형 변수의 경우, \"Unknown\" 또는 \"Missing\"과 같은 새로운 카테고리를 추가하는 방법도 고려하세요.\n",
    "결측값이 많은 열은 전체 데이터 품질에 영향을 미칠 수 있으므로, 열 자체를 제거하는 것도 고려하세요.\n",
    "\n",
    "3. Data Type Consistency\n",
    "데이터셋의 각 열이 올바른 데이터 타입을 가지고 있는지 확인하세요.\n",
    "범주형 변수(categorical variables)는 object 또는 category 타입으로 변환하세요.\n",
    "수치형 변수(numerical variables)는 int 또는 float 타입으로 변환하세요.\n",
    "날짜/시간 데이터는 datetime 타입으로 변환하세요.\n",
    "잘못된 데이터 타입으로 인해 발생할 수 있는 문제(예: 수치형 데이터가 문자열로 저장된 경우)를 해결하세요.\n",
    "데이터 타입 변환 시, 데이터 손실이나 오류가 발생하지 않도록 주의하세요.\n",
    "범주형 변수의 경우, 고유값의 수를 확인하여 적절한 인코딩 방법(예: One-Hot Encoding, Label Encoding)을 선택하세요.\n",
    "데이터 타입 변환 후, 데이터의 무결성을 다시 한번 검토하세요.\n",
    "\n",
    "4. Duplicate Rows\n",
    "데이터셋에서 중복된 행(duplicate rows)이 있는지 확인하세요.\n",
    "중복된 행이 발견된 경우, 해당 행을 제거하세요.\n",
    "중복 행 제거 후, 데이터셋의 크기와 무결성을 검토하세요.\n",
    "추가 고려사항:\n",
    "중복 행을 제거하기 전, 중복이 발생한 이유를 분석하세요(예: 데이터 수집 오류, 병합 과정에서의 중복 등).\n",
    "특정 열을 기준으로 중복을 판단할 경우, 해당 열의 중요성을 고려하세요.\n",
    "중복 행 제거 후, 데이터셋의 균형(예: 클래스 불균형)이 깨지지 않았는지 확인하세요.\n",
    "\n",
    "5. Outlier Detection\n",
    "수치형 열에서 이상치(outliers)를 식별하세요.\n",
    "이상치를 처리하기 전, 해당 열의 도메인 지식과 데이터 분포를 고려하여 이상치가 실제로 유효한 값인지 판단하세요(예: 특정 직군의 높은 연봉).\n",
    "이상치 처리 방법: 제거, 변환(예: 로그 변환), 또는 별도의 범주로 처리하는 방법을 고려하세요.\n",
    "이상치 처리 후, 데이터의 분포와 분석 결과에 미치는 영향을 검토하세요.\n",
    "추가 고려사항:\n",
    "이상치를 식별하기 위해 IQR(Interquartile Range), Z-score, 또는 시각화(예: 박스플롯)를 활용하세요.\n",
    "\n",
    "이상치가 특정 패턴이나 의미를 가질 경우, 이를 별도로 분석하거나 모델링에 반영하세요.\n",
    "이상치 처리 방법을 선택할 때, 데이터의 특성과 분석 목적을 고려하세요.\n",
    "\"\"\"\n",
    ")\n",
    "# 결과 확인\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔨 그래프 구성 시작\n",
      "✅ 노드 추가 완료\n",
      "✅ 엣지 설정 완료\n",
      "✅ 그래프 컴파일 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# OpenAI API 키 로드\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 어시스턴트 초기화\n",
    "assistant = AIDataFrameAssistant(openai_api_key)\n",
    "\n",
    "df = pd.read_pickle(f'../data/cust_intg.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 시작...\n",
      "\n",
      "1. 불필요한 컬럼 제거 시작...\n",
      "제거된 컬럼: ['GA채널Affluent고객여부', '자사설계사채널Affluent고객여부', '기준년월']\n",
      "소요 시간: 0.25초\n",
      "\n",
      "2. 결측치 처리 시작...\n",
      "결측치 현황:\n",
      "고객ID               0\n",
      "나이                 0\n",
      "성별                 0\n",
      "수익자여부              0\n",
      "CB신용평점        105882\n",
      "               ...  \n",
      "변액종신CMIP           0\n",
      "변액종신보유여부           0\n",
      "변액종신최대납입회차         0\n",
      "변액종신유지계약수          0\n",
      "변액종신기납입보험료         0\n",
      "Length: 120, dtype: int64\n",
      "수치형 변수 결측치 처리 중...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m수치형 변수 결측치 처리 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m imp \u001b[38;5;241m=\u001b[39m IterativeImputer(estimator\u001b[38;5;241m=\u001b[39mRandomForestRegressor(), random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m df[numerical_cols] \u001b[38;5;241m=\u001b[39m \u001b[43mimp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m범주형 변수 결측치 처리 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cat_cols:\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:859\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat_idx \u001b[38;5;129;01min\u001b[39;00m ordered_idx:\n\u001b[0;32m    856\u001b[0m     neighbor_feat_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[0;32m    857\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[0;32m    858\u001b[0m     )\n\u001b[1;32m--> 859\u001b[0m     Xt, estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impute_one_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_missing_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneighbor_feat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m     estimator_triplet \u001b[38;5;241m=\u001b[39m _ImputerTriplet(\n\u001b[0;32m    869\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_\u001b[38;5;241m.\u001b[39mappend(estimator_triplet)\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:427\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[1;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode, params)\u001b[0m\n\u001b[0;32m    417\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[0;32m    418\u001b[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[0;32m    420\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    422\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[0;32m    423\u001b[0m         _safe_indexing(X_filled, feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[0;32m    425\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    426\u001b[0m     )\n\u001b[1;32m--> 427\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;66;03m# if no missing values, don't predict\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(missing_row_mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\권상우\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "print(\"데이터 전처리 시작...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# 1. Remove Unnecessary Columns and List Up\n",
    "print(\"\\n1. 불필요한 컬럼 제거 시작...\")\n",
    "step_start = time.time()\n",
    "\n",
    "cols_to_remove = []\n",
    "unique_value_cols = df.columns[df.nunique() <= 1]\n",
    "cols_to_remove.extend(unique_value_cols)\n",
    "unnecessary_cols = ['기준년월']\n",
    "cols_to_remove.extend(unnecessary_cols)\n",
    "df = df.drop(columns=cols_to_remove)\n",
    "\n",
    "print(f\"제거된 컬럼: {cols_to_remove}\")\n",
    "print(f\"소요 시간: {time.time() - step_start:.2f}초\")\n",
    "\n",
    "# 2. Check for Missing Values\n",
    "print(\"\\n2. 결측치 처리 시작...\")\n",
    "step_start = time.time()\n",
    "\n",
    "missing_values_count = df.isnull().sum()\n",
    "print(f\"결측치 현황:\\n{missing_values_count}\")\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"수치형 변수 결측치 처리 중...\")\n",
    "imp = IterativeImputer(estimator=RandomForestRegressor(), random_state=0, max_iter=10, tol=1e-3)\n",
    "df[numerical_cols] = imp.fit_transform(df[numerical_cols])\n",
    "\n",
    "# 큐가 오래걸릴법한 애는 튜닝해서 줘.\n",
    "\n",
    "print(\"범주형 변수 결측치 처리 중...\")\n",
    "for col in cat_cols:\n",
    "    df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(f\"소요 시간: {time.time() - step_start:.2f}초\")\n",
    "\n",
    "# 3. Data Type Consistency\n",
    "print(\"\\n3. 데이터 타입 변환 시작...\")\n",
    "step_start = time.time()\n",
    "\n",
    "df[cat_cols] = df[cat_cols].astype('category')\n",
    "for col in numerical_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(f\"소요 시간: {time.time() - step_start:.2f}초\")\n",
    "\n",
    "# 4. Duplicate Rows\n",
    "print(\"\\n4. 중복 행 제거 시작...\")\n",
    "step_start = time.time()\n",
    "\n",
    "initial_rows = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "removed_rows = initial_rows - len(df)\n",
    "\n",
    "print(f\"제거된 중복 행 수: {removed_rows}\")\n",
    "print(f\"소요 시간: {time.time() - step_start:.2f}초\")\n",
    "\n",
    "# 5. Outlier Detection\n",
    "print(\"\\n5. 이상치 처리 시작...\")\n",
    "step_start = time.time()\n",
    "\n",
    "initial_rows = len(df)\n",
    "for col in numerical_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "removed_outliers = initial_rows - len(df)\n",
    "print(f\"제거된 이상치 행 수: {removed_outliers}\")\n",
    "print(f\"소요 시간: {time.time() - step_start:.2f}초\")\n",
    "\n",
    "result_df = df.copy()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n전체 데이터 전처리 완료. 총 소요 시간: {total_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
