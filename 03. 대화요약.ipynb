{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key, temperature=0.0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 {ability} 에 능숙한 어시스턴트입니다. 20자 이내로 응답하세요\",\n",
    "        ),\n",
    "        # 대화 기록을 변수로 사용, history 가 MessageHistory 의 key 가 됨\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # 사용자 입력을 변수로 사용\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model  # 프롬프트와 모델을 연결하여 runnable 객체 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_retrieved_documents(filtered_results, query):\n",
    "    \"\"\"검색된 문서를 LLM을 활용하여 요약\"\"\"\n",
    "    if not filtered_results:\n",
    "        return \"\"\n",
    "\n",
    "    document_texts = \"\\n\\n\".join([\n",
    "        f\"[유사도: {score:.2f}]\\n{doc.page_content}\" \n",
    "        for doc, score in filtered_results\n",
    "    ])\n",
    "\n",
    "    print(f'#################################################\\ndocument_texts: \\n{document_texts}')\n",
    "\n",
    "    # LLM을 사용하여 문서 요약\n",
    "    prompt = f\"\"\"\n",
    "    다음은 이전 대화 내역에서 현재 질문 \"{query}\"와 관련성이 높은 부분들입니다. 이를 참고하여 다음 지침에 따라 요약해주세요:\n",
    "\n",
    "    1. 현재 질문에 직접적으로 관련된 정보를 우선적으로 추출하세요.\n",
    "    2. 코드 블록과 그 설명은 온전히 보존하세요.\n",
    "    3. 유사도 점수가 높은 내용에 더 큰 가중치를 두세요.\n",
    "    4. 정보를 다음 형식으로 구조화하세요:\n",
    "    - 핵심 개념/용어 설명\n",
    "    - 관련 코드 예시\n",
    "    - 주요 인사이트/팁\n",
    "    5. 기술적 정확성을 유지하면서 중복 정보는 제거하세요.\n",
    "    6. 최신 대화 내용을 더 관련성 높게 처리하세요.\n",
    "\n",
    "    {document_texts}\n",
    "    \"\"\"\n",
    "    summarized_result = model.invoke(prompt)\n",
    "    return summarized_result.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vector_handler import initialize_vector_store\n",
    "\n",
    "def search_similar_questions(internal_id, query, top_k=5, similarity_threshold=0.7):\n",
    "    \"\"\"벡터DB에서 사용자의 질문과 유사한 질문 검색\"\"\"\n",
    "    vectorstore = initialize_vector_store(internal_id)  # 세션별 벡터스토어 로드\n",
    "    \n",
    "    # 🔎 유사도 점수와 함께 검색 실행\n",
    "    search_results = vectorstore.similarity_search_with_score(query, k=top_k*2)  # 더 많은 결과를 가져와서 필터링\n",
    "    \n",
    "    # 유사도 점수가 threshold를 넘는 결과만 필터링\n",
    "    filtered_results = []\n",
    "    seen_content = set()  # 중복 콘텐츠 확인용 집합\n",
    "    \n",
    "    for doc, score in search_results:\n",
    "        # FAISS의 score는 L2 거리이므로 코사인 유사도로 변환 (1 - score/2가 코사인 유사도의 근사값)\n",
    "        cosine_sim = 1 - (score / 2)\n",
    "        \n",
    "        if cosine_sim >= similarity_threshold:\n",
    "            # 콘텐츠 핵심 부분 추출 (사용자 질문 부분만)\n",
    "            content_key = \"\"\n",
    "            for line in doc.page_content.split('\\n'):\n",
    "                if \"사용자 질문:\" in line:\n",
    "                    content_key = line.strip()\n",
    "                    break\n",
    "            \n",
    "            # 중복 콘텐츠 건너뛰기\n",
    "            if content_key and content_key in seen_content:\n",
    "                continue\n",
    "            \n",
    "            # 가중치 계산 (콘텐츠 품질 기반)\n",
    "            weight = 1.0\n",
    "            if \"validated_code: None\" in doc.page_content or \"코드 없음\" in doc.page_content:\n",
    "                weight *= 0.8  # 코드가 없는 경우 가중치 감소\n",
    "            \n",
    "            if \"인사이트: None\" in doc.page_content or \"인사이트 없음\" in doc.page_content:\n",
    "                weight *= 0.9  # 인사이트가 없는 경우 가중치 감소\n",
    "                \n",
    "            if \"실행된 코드:\" in doc.page_content and \"코드 없음\" not in doc.page_content:\n",
    "                weight *= 1.3  # 실행된 코드가 있는 경우 가중치 증가\n",
    "                \n",
    "            if \"생성된 인사이트:\" in doc.page_content and \"인사이트 없음\" not in doc.page_content:\n",
    "                weight *= 1.2  # 인사이트가 있는 경우 가중치 증가\n",
    "            \n",
    "            # 최종 스코어 조정\n",
    "            adjusted_score = cosine_sim * weight\n",
    "            \n",
    "            if content_key:\n",
    "                seen_content.add(content_key)\n",
    "            \n",
    "            filtered_results.append((doc, adjusted_score))\n",
    "    \n",
    "    # 조정된 점수로 상위 결과 선택\n",
    "    filtered_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    filtered_results = filtered_results[:3]  # 상위 top_k개만 유지\n",
    "    \n",
    "    # 결과가 있는 경우에만 컨텍스트 생성\n",
    "    if filtered_results:\n",
    "        retrieved_context = \"\\n\\n\".join([\n",
    "            f\"[유사도: {score:.2f}]\\n{doc.page_content}\" \n",
    "            for doc, score in filtered_results\n",
    "        ])\n",
    "    else:\n",
    "        retrieved_context = \"\"\n",
    "    retrieved_context = summarize_retrieved_documents(filtered_results, query)\n",
    "    \n",
    "    return retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 [initialize_vector_store] 벡터DB 로드 시작 (세션: temp_KSW_20250225_1118)\n",
      "#################################################\n",
      "document_texts: \n",
      "[유사도: 1.19]\n",
      "\n",
      "            사용자 질문: 기준년월에 따른  CMIP의 추세를 알고 싶습니다.\n",
      "            AI 응답: 분석이 완료되었습니다! 아래 결과를 확인해주세요.\n",
      "            실행된 코드: ```python\n",
      "import pandas as pd\n",
      "\n",
      "# 기준년월별 변액종신CMIP의 평균 추세 계산\n",
      "cmip_trend = df.groupby('기준년월')['변액종신CMIP'].mean().round(2)\n",
      "\n",
      "# 결과 저장\n",
      "analytic_results = {\n",
      "    'CMIP_Trend': cmip_trend\n",
      "}\n",
      "\n",
      "# 집계성 데이터 출력\n",
      "print(cmip_trend)\n",
      "```\n",
      "            분석 결과: {'CMIP_Trend': 기준년월\n",
      "202405    17327.30\n",
      "202406    17320.91\n",
      "202407    17322.96\n",
      "202408    17323.08\n",
      "202409    17327.54\n",
      "202410    17315.90\n",
      "Name: 변액종신CMIP, dtype: float64}\n",
      "            생성된 인사이트: 1. 주요 발견사항\n",
      "   - CMIP(변액종신CMIP)의 추세를 분석한 결과, 2024년 5월부터 2024년 10월까지의 데이터에서 큰 변동 없이 비교적 안정적인 추세를 보이고 있습니다. CMIP 값은 17315.90에서 17327.54 사이에서 움직이고 있으며, 월별로 큰 변화는 관찰되지 않았습니다.\n",
      "\n",
      "2. 특이점\n",
      "   - 2024년 10월에 CMIP 값이 약간 감소한 17315.90을 기록하였으나, 이는 전체적인 추세에 큰 영향을 미치지 않는 수준입니다. 전반적으로 CMIP 값은 안정적인 수준을 유지하고 있습니다.\n",
      "\n",
      "3. 추천 사항\n",
      "   - CMIP의 안정적인 추세를 유지하기 위해 현재의 보험 상품 및 투자 전략을 지속적으로 모니터링하고, 외부 경제 환경 변화에 대한 민감도를 분석하여 필요 시 조정할 수 있는 준비가 필요합니다.\n",
      "   - 추가적으로, CMIP의 장기적인 추세를 파악하기 위해 더 긴 기간의 데이터를 분석하고, 계절적 요인이나 외부 경제 지표와의 상관관계를 검토하는 것도 유용할 것입니다.\n",
      "   - 만약 CMIP의 변동성이 증가할 경우, 그 원인을 파악하고 대응 전략을 마련하는 것이 중요합니다. 이를 위해 다양한 시나리오 분석을 통해 리스크 관리 방안을 강화할 것을 권장합니다.\n",
      "            리포트: 1. 요약\n",
      "2024년 5월부터 2024년 10월까지의 변액종신CMIP 데이터 분석 결과, CMIP 값은 비교적 안정적인 추세를 보이며 큰 변동 없이 17315.90에서 17327.54 사이에서 움직였습니다. 2024년 10월에 약간의 감소가 있었으나, 전체적인 추세에 큰 영향을 미치지 않았습니다. 이러한 안정적인 추세를 유지하기 위해 지속적인 모니터링과 외부 경제 환경 변화에 대한 민감도 분석이 필요합니다.\n",
      "\n",
      "2. 분석 방법\n",
      "분석은 2024년 5월부터 2024년 10월까지의 월별 CMIP 데이터를 기반으로 하여, 시간에 따른 추세를 파악하는 방식으로 진행되었습니다. 데이터의 변동성을 확인하기 위해 월별 CMIP 값을 비교하였으며, 이를 통해 안정성 여부를 평가하였습니다.\n",
      "\n",
      "3. 주요 발견사항\n",
      "- CMIP 값은 17315.90에서 17327.54 사이에서 움직이며, 월별로 큰 변화는 없었습니다.\n",
      "- 2024년 10월에 CMIP 값이 약간 감소한 17315.90을 기록했으나, 이는 전체적인 추세에 큰 영향을 미치지 않았습니다.\n",
      "- 전반적으로 CMIP는 안정적인 수준을 유지하고 있습니다.\n",
      "\n",
      "4. 결론 및 제언\n",
      "CMIP의 안정적인 추세를 유지하기 위해 현재의 보험 상품 및 투자 전략을 지속적으로 모니터링하고, 외부 경제 환경 변화에 대한 민감도를 분석하여 필요 시 조정할 수 있는 준비가 필요합니다. 또한, CMIP의 장기적인 추세를 파악하기 위해 더 긴 기간의 데이터를 분석하고, 계절적 요인이나 외부 경제 지표와의 상관관계를 검토하는 것도 유용할 것입니다. 만약 CMIP의 변동성이 증가할 경우, 그 원인을 파악하고 대응 전략을 마련하는 것이 중요합니다. 이를 위해 다양한 시나리오 분석을 통해 리스크 관리 방안을 강화할 것을 권장합니다.\n",
      "            \n",
      "\n",
      "[유사도: 1.19]\n",
      "\n",
      "            사용자 질문: 그래프 해석 가능할까요?\n",
      "            AI 응답: ❌ 활성화된 마트가 없습니다. 먼저 마트를 활성화해주세요.\n",
      "            실행된 코드: None\n",
      "            분석 결과: None\n",
      "            생성된 인사이트: None\n",
      "            리포트: None\n",
      "            \n",
      "\n",
      "[유사도: 1.16]\n",
      "\n",
      "            사용자 질문: 그래프 컴파일\n",
      "            AI 응답: 그래프 컴파일은 일반적으로 데이터 시각화 또는 데이터 분석의 한 부분으로, 데이터를 그래프로 변환하여 시각적으로 표현하는 과정을 의미합니다. 그래프 컴파일을 통해 복잡한 데이터 세트를 더 쉽게 이해할 수 있으며, 데이터 간의 관계나 패턴을 시각적으로 파악할 수 있습니다.\n",
      "\n",
      "그래프 컴파일을 수행하는 방법은 여러 가지가 있으며, 주로 사용하는 도구와 프로그래밍 언어에 따라 다릅니다. 예를 들어, Python에서는 Matplotlib, Seaborn, Plotly와 같은 라이브러리를 사용하여 그래프를 생성할 수 있습니다. R에서는 ggplot2가 널리 사용됩니다.\n",
      "\n",
      "그래프를 컴파일할 때 고려해야 할 몇 가지 요소는 다음과 같습니다:\n",
      "\n",
      "1. **데이터 준비**: 그래프에 사용할 데이터를 정리하고 필요한 형식으로 변환합니다.\n",
      "2. **그래프 유형 선택**: 데이터의 특성과 분석 목적에 맞는 그래프 유형(예: 막대 그래프, 선 그래프, 산점도 등)을 선택합니다.\n",
      "3. **레이블 및 제목 추가**: 그래프의 축, 제목, 범례 등을 추가하여 그래프의 의미를 명확히 합니다.\n",
      "4. **스타일링**: 그래프의 색상, 폰트, 크기 등을 조정하여 가독성을 높입니다.\n",
      "\n",
      "이러한 과정을 통해 데이터를 효과적으로 시각화하고, 이를 기반으로 인사이트를 도출할 수 있습니다.\n",
      "            실행된 코드: None\n",
      "            분석 결과: None\n",
      "            생성된 인사이트: None\n",
      "            리포트: None\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "internal_id = \"temp_KSW_20250225_1118\"\n",
    "query = \"그래프 해석 가능할까요?\"\n",
    "retrieved_context = search_similar_questions(internal_id, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 핵심 개념/용어 설명\n",
      "- **그래프 해석**: 그래프 해석은 데이터를 시각적으로 표현하여 데이터 간의 관계나 패턴을 파악하는 과정입니다. 이를 통해 복잡한 데이터 세트를 더 쉽게 이해할 수 있습니다.\n",
      "- **그래프 컴파일**: 그래프 컴파일은 데이터를 그래프로 변환하여 시각적으로 표현하는 과정입니다. Python에서는 Matplotlib, Seaborn, Plotly와 같은 라이브러리를 사용하여 그래프를 생성할 수 있습니다.\n",
      "\n",
      "### 관련 코드 예시\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# 기준년월별 변액종신CMIP의 평균 추세 계산\n",
      "cmip_trend = df.groupby('기준년월')['변액종신CMIP'].mean().round(2)\n",
      "\n",
      "# 결과 저장\n",
      "analytic_results = {\n",
      "    'CMIP_Trend': cmip_trend\n",
      "}\n",
      "\n",
      "# 집계성 데이터 출력\n",
      "print(cmip_trend)\n",
      "```\n",
      "\n",
      "### 주요 인사이트/팁\n",
      "1. **데이터 준비**: 그래프에 사용할 데이터를 정리하고 필요한 형식으로 변환합니다.\n",
      "2. **그래프 유형 선택**: 데이터의 특성과 분석 목적에 맞는 그래프 유형(예: 막대 그래프, 선 그래프, 산점도 등)을 선택합니다.\n",
      "3. **레이블 및 제목 추가**: 그래프의 축, 제목, 범례 등을 추가하여 그래프의 의미를 명확히 합니다.\n",
      "4. **스타일링**: 그래프의 색상, 폰트, 크기 등을 조정하여 가독성을 높입니다.\n",
      "\n",
      "### 추가 인사이트\n",
      "- CMIP(변액종신CMIP)의 추세를 분석한 결과, 2024년 5월부터 2024년 10월까지의 데이터에서 큰 변동 없이 비교적 안정적인 추세를 보이고 있습니다. CMIP 값은 17315.90에서 17327.54 사이에서 움직이고 있으며, 월별로 큰 변화는 관찰되지 않았습니다.\n",
      "- CMIP의 안정적인 추세를 유지하기 위해 지속적인 모니터링과 외부 경제 환경 변화에 대한 민감도 분석이 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m     summarized_result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mask(prompt)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summarized_result\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 19\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_retrieved_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrieved_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m res\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36msummarize_retrieved_documents\u001b[1;34m(filtered_results)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered_results:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m document_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[유사도: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;241m.\u001b[39mpage_content\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m filtered_results\n\u001b[0;32m      9\u001b[0m ])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# LLM을 사용하여 문서 요약\u001b[39;00m\n\u001b[0;32m     12\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m다음 문서들을 참고하여 핵심 내용을 요약하세요. 불필요한 정보를 제거하고 유용한 정보만 유지하세요.\u001b[39m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_texts\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
