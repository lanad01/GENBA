{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key, temperature=0.0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ {ability} ì— ëŠ¥ìˆ™í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 20ì ì´ë‚´ë¡œ ì‘ë‹µí•˜ì„¸ìš”\",\n",
    "        ),\n",
    "        # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, history ê°€ MessageHistory ì˜ key ê°€ ë¨\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # ì‚¬ìš©ì ì…ë ¥ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model  # í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ runnable ê°ì²´ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_retrieved_documents(filtered_results, query):\n",
    "    \"\"\"ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ LLMì„ í™œìš©í•˜ì—¬ ìš”ì•½\"\"\"\n",
    "    if not filtered_results:\n",
    "        return \"\"\n",
    "\n",
    "    document_texts = \"\\n\\n\".join([\n",
    "        f\"[ìœ ì‚¬ë„: {score:.2f}]\\n{doc.page_content}\" \n",
    "        for doc, score in filtered_results\n",
    "    ])\n",
    "\n",
    "    print(f'#################################################\\ndocument_texts: \\n{document_texts}')\n",
    "\n",
    "    # LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒì€ ì´ì „ ëŒ€í™” ë‚´ì—­ì—ì„œ í˜„ì¬ ì§ˆë¬¸ \"{query}\"ì™€ ê´€ë ¨ì„±ì´ ë†’ì€ ë¶€ë¶„ë“¤ì…ë‹ˆë‹¤. ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "    1. í˜„ì¬ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "    2. ì½”ë“œ ë¸”ë¡ê³¼ ê·¸ ì„¤ëª…ì€ ì˜¨ì „íˆ ë³´ì¡´í•˜ì„¸ìš”.\n",
    "    3. ìœ ì‚¬ë„ ì ìˆ˜ê°€ ë†’ì€ ë‚´ìš©ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë‘ì„¸ìš”.\n",
    "    4. ì •ë³´ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ì„¸ìš”:\n",
    "    - í•µì‹¬ ê°œë…/ìš©ì–´ ì„¤ëª…\n",
    "    - ê´€ë ¨ ì½”ë“œ ì˜ˆì‹œ\n",
    "    - ì£¼ìš” ì¸ì‚¬ì´íŠ¸/íŒ\n",
    "    5. ê¸°ìˆ ì  ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì¤‘ë³µ ì •ë³´ëŠ” ì œê±°í•˜ì„¸ìš”.\n",
    "    6. ìµœì‹  ëŒ€í™” ë‚´ìš©ì„ ë” ê´€ë ¨ì„± ë†’ê²Œ ì²˜ë¦¬í•˜ì„¸ìš”.\n",
    "\n",
    "    {document_texts}\n",
    "    \"\"\"\n",
    "    summarized_result = model.invoke(prompt)\n",
    "    return summarized_result.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vector_handler import initialize_vector_store\n",
    "\n",
    "def search_similar_questions(internal_id, query, top_k=5, similarity_threshold=0.7):\n",
    "    \"\"\"ë²¡í„°DBì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì§ˆë¬¸ ê²€ìƒ‰\"\"\"\n",
    "    vectorstore = initialize_vector_store(internal_id)  # ì„¸ì…˜ë³„ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ\n",
    "    \n",
    "    # ğŸ” ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰ ì‹¤í–‰\n",
    "    search_results = vectorstore.similarity_search_with_score(query, k=top_k*2)  # ë” ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ í•„í„°ë§\n",
    "    \n",
    "    # ìœ ì‚¬ë„ ì ìˆ˜ê°€ thresholdë¥¼ ë„˜ëŠ” ê²°ê³¼ë§Œ í•„í„°ë§\n",
    "    filtered_results = []\n",
    "    seen_content = set()  # ì¤‘ë³µ ì½˜í…ì¸  í™•ì¸ìš© ì§‘í•©\n",
    "    \n",
    "    for doc, score in search_results:\n",
    "        # FAISSì˜ scoreëŠ” L2 ê±°ë¦¬ì´ë¯€ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (1 - score/2ê°€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì˜ ê·¼ì‚¬ê°’)\n",
    "        cosine_sim = 1 - (score / 2)\n",
    "        \n",
    "        if cosine_sim >= similarity_threshold:\n",
    "            # ì½˜í…ì¸  í•µì‹¬ ë¶€ë¶„ ì¶”ì¶œ (ì‚¬ìš©ì ì§ˆë¬¸ ë¶€ë¶„ë§Œ)\n",
    "            content_key = \"\"\n",
    "            for line in doc.page_content.split('\\n'):\n",
    "                if \"ì‚¬ìš©ì ì§ˆë¬¸:\" in line:\n",
    "                    content_key = line.strip()\n",
    "                    break\n",
    "            \n",
    "            # ì¤‘ë³µ ì½˜í…ì¸  ê±´ë„ˆë›°ê¸°\n",
    "            if content_key and content_key in seen_content:\n",
    "                continue\n",
    "            \n",
    "            # ê°€ì¤‘ì¹˜ ê³„ì‚° (ì½˜í…ì¸  í’ˆì§ˆ ê¸°ë°˜)\n",
    "            weight = 1.0\n",
    "            if \"validated_code: None\" in doc.page_content or \"ì½”ë“œ ì—†ìŒ\" in doc.page_content:\n",
    "                weight *= 0.8  # ì½”ë“œê°€ ì—†ëŠ” ê²½ìš° ê°€ì¤‘ì¹˜ ê°ì†Œ\n",
    "            \n",
    "            if \"ì¸ì‚¬ì´íŠ¸: None\" in doc.page_content or \"ì¸ì‚¬ì´íŠ¸ ì—†ìŒ\" in doc.page_content:\n",
    "                weight *= 0.9  # ì¸ì‚¬ì´íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ê°€ì¤‘ì¹˜ ê°ì†Œ\n",
    "                \n",
    "            if \"ì‹¤í–‰ëœ ì½”ë“œ:\" in doc.page_content and \"ì½”ë“œ ì—†ìŒ\" not in doc.page_content:\n",
    "                weight *= 1.3  # ì‹¤í–‰ëœ ì½”ë“œê°€ ìˆëŠ” ê²½ìš° ê°€ì¤‘ì¹˜ ì¦ê°€\n",
    "                \n",
    "            if \"ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸:\" in doc.page_content and \"ì¸ì‚¬ì´íŠ¸ ì—†ìŒ\" not in doc.page_content:\n",
    "                weight *= 1.2  # ì¸ì‚¬ì´íŠ¸ê°€ ìˆëŠ” ê²½ìš° ê°€ì¤‘ì¹˜ ì¦ê°€\n",
    "            \n",
    "            # ìµœì¢… ìŠ¤ì½”ì–´ ì¡°ì •\n",
    "            adjusted_score = cosine_sim * weight\n",
    "            \n",
    "            if content_key:\n",
    "                seen_content.add(content_key)\n",
    "            \n",
    "            filtered_results.append((doc, adjusted_score))\n",
    "    \n",
    "    # ì¡°ì •ëœ ì ìˆ˜ë¡œ ìƒìœ„ ê²°ê³¼ ì„ íƒ\n",
    "    filtered_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    filtered_results = filtered_results[:3]  # ìƒìœ„ top_kê°œë§Œ ìœ ì§€\n",
    "    \n",
    "    # ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
    "    if filtered_results:\n",
    "        retrieved_context = \"\\n\\n\".join([\n",
    "            f\"[ìœ ì‚¬ë„: {score:.2f}]\\n{doc.page_content}\" \n",
    "            for doc, score in filtered_results\n",
    "        ])\n",
    "    else:\n",
    "        retrieved_context = \"\"\n",
    "    retrieved_context = summarize_retrieved_documents(filtered_results, query)\n",
    "    \n",
    "    return retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¢ [initialize_vector_store] ë²¡í„°DB ë¡œë“œ ì‹œì‘ (ì„¸ì…˜: temp_KSW_20250225_1118)\n",
      "#################################################\n",
      "document_texts: \n",
      "[ìœ ì‚¬ë„: 1.19]\n",
      "\n",
      "            ì‚¬ìš©ì ì§ˆë¬¸: ê¸°ì¤€ë…„ì›”ì— ë”°ë¥¸  CMIPì˜ ì¶”ì„¸ë¥¼ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
      "            AI ì‘ë‹µ: ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
      "            ì‹¤í–‰ëœ ì½”ë“œ: ```python\n",
      "import pandas as pd\n",
      "\n",
      "# ê¸°ì¤€ë…„ì›”ë³„ ë³€ì•¡ì¢…ì‹ CMIPì˜ í‰ê·  ì¶”ì„¸ ê³„ì‚°\n",
      "cmip_trend = df.groupby('ê¸°ì¤€ë…„ì›”')['ë³€ì•¡ì¢…ì‹ CMIP'].mean().round(2)\n",
      "\n",
      "# ê²°ê³¼ ì €ì¥\n",
      "analytic_results = {\n",
      "    'CMIP_Trend': cmip_trend\n",
      "}\n",
      "\n",
      "# ì§‘ê³„ì„± ë°ì´í„° ì¶œë ¥\n",
      "print(cmip_trend)\n",
      "```\n",
      "            ë¶„ì„ ê²°ê³¼: {'CMIP_Trend': ê¸°ì¤€ë…„ì›”\n",
      "202405    17327.30\n",
      "202406    17320.91\n",
      "202407    17322.96\n",
      "202408    17323.08\n",
      "202409    17327.54\n",
      "202410    17315.90\n",
      "Name: ë³€ì•¡ì¢…ì‹ CMIP, dtype: float64}\n",
      "            ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸: 1. ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
      "   - CMIP(ë³€ì•¡ì¢…ì‹ CMIP)ì˜ ì¶”ì„¸ë¥¼ ë¶„ì„í•œ ê²°ê³¼, 2024ë…„ 5ì›”ë¶€í„° 2024ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„°ì—ì„œ í° ë³€ë™ ì—†ì´ ë¹„êµì  ì•ˆì •ì ì¸ ì¶”ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. CMIP ê°’ì€ 17315.90ì—ì„œ 17327.54 ì‚¬ì´ì—ì„œ ì›€ì§ì´ê³  ìˆìœ¼ë©°, ì›”ë³„ë¡œ í° ë³€í™”ëŠ” ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. íŠ¹ì´ì \n",
      "   - 2024ë…„ 10ì›”ì— CMIP ê°’ì´ ì•½ê°„ ê°ì†Œí•œ 17315.90ì„ ê¸°ë¡í•˜ì˜€ìœ¼ë‚˜, ì´ëŠ” ì „ì²´ì ì¸ ì¶”ì„¸ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ” ìˆ˜ì¤€ì…ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ CMIP ê°’ì€ ì•ˆì •ì ì¸ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. ì¶”ì²œ ì‚¬í•­\n",
      "   - CMIPì˜ ì•ˆì •ì ì¸ ì¶”ì„¸ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ í˜„ì¬ì˜ ë³´í—˜ ìƒí’ˆ ë° íˆ¬ì ì „ëµì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ , ì™¸ë¶€ ê²½ì œ í™˜ê²½ ë³€í™”ì— ëŒ€í•œ ë¯¼ê°ë„ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš” ì‹œ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "   - ì¶”ê°€ì ìœ¼ë¡œ, CMIPì˜ ì¥ê¸°ì ì¸ ì¶”ì„¸ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ ë” ê¸´ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ê³„ì ˆì  ìš”ì¸ì´ë‚˜ ì™¸ë¶€ ê²½ì œ ì§€í‘œì™€ì˜ ìƒê´€ê´€ê³„ë¥¼ ê²€í† í•˜ëŠ” ê²ƒë„ ìœ ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n",
      "   - ë§Œì•½ CMIPì˜ ë³€ë™ì„±ì´ ì¦ê°€í•  ê²½ìš°, ê·¸ ì›ì¸ì„ íŒŒì•…í•˜ê³  ëŒ€ì‘ ì „ëµì„ ë§ˆë ¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ì„ í†µí•´ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ì•ˆì„ ê°•í™”í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "            ë¦¬í¬íŠ¸: 1. ìš”ì•½\n",
      "2024ë…„ 5ì›”ë¶€í„° 2024ë…„ 10ì›”ê¹Œì§€ì˜ ë³€ì•¡ì¢…ì‹ CMIP ë°ì´í„° ë¶„ì„ ê²°ê³¼, CMIP ê°’ì€ ë¹„êµì  ì•ˆì •ì ì¸ ì¶”ì„¸ë¥¼ ë³´ì´ë©° í° ë³€ë™ ì—†ì´ 17315.90ì—ì„œ 17327.54 ì‚¬ì´ì—ì„œ ì›€ì§ì˜€ìŠµë‹ˆë‹¤. 2024ë…„ 10ì›”ì— ì•½ê°„ì˜ ê°ì†Œê°€ ìˆì—ˆìœ¼ë‚˜, ì „ì²´ì ì¸ ì¶”ì„¸ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì•ˆì •ì ì¸ ì¶”ì„¸ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ì™¸ë¶€ ê²½ì œ í™˜ê²½ ë³€í™”ì— ëŒ€í•œ ë¯¼ê°ë„ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. ë¶„ì„ ë°©ë²•\n",
      "ë¶„ì„ì€ 2024ë…„ 5ì›”ë¶€í„° 2024ë…„ 10ì›”ê¹Œì§€ì˜ ì›”ë³„ CMIP ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ì‹œê°„ì— ë”°ë¥¸ ì¶”ì„¸ë¥¼ íŒŒì•…í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„°ì˜ ë³€ë™ì„±ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì›”ë³„ CMIP ê°’ì„ ë¹„êµí•˜ì˜€ìœ¼ë©°, ì´ë¥¼ í†µí•´ ì•ˆì •ì„± ì—¬ë¶€ë¥¼ í‰ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
      "- CMIP ê°’ì€ 17315.90ì—ì„œ 17327.54 ì‚¬ì´ì—ì„œ ì›€ì§ì´ë©°, ì›”ë³„ë¡œ í° ë³€í™”ëŠ” ì—†ì—ˆìŠµë‹ˆë‹¤.\n",
      "- 2024ë…„ 10ì›”ì— CMIP ê°’ì´ ì•½ê°„ ê°ì†Œí•œ 17315.90ì„ ê¸°ë¡í–ˆìœ¼ë‚˜, ì´ëŠ” ì „ì²´ì ì¸ ì¶”ì„¸ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n",
      "- ì „ë°˜ì ìœ¼ë¡œ CMIPëŠ” ì•ˆì •ì ì¸ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. ê²°ë¡  ë° ì œì–¸\n",
      "CMIPì˜ ì•ˆì •ì ì¸ ì¶”ì„¸ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ í˜„ì¬ì˜ ë³´í—˜ ìƒí’ˆ ë° íˆ¬ì ì „ëµì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ , ì™¸ë¶€ ê²½ì œ í™˜ê²½ ë³€í™”ì— ëŒ€í•œ ë¯¼ê°ë„ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš” ì‹œ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ, CMIPì˜ ì¥ê¸°ì ì¸ ì¶”ì„¸ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ ë” ê¸´ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ê³„ì ˆì  ìš”ì¸ì´ë‚˜ ì™¸ë¶€ ê²½ì œ ì§€í‘œì™€ì˜ ìƒê´€ê´€ê³„ë¥¼ ê²€í† í•˜ëŠ” ê²ƒë„ ìœ ìš©í•  ê²ƒì…ë‹ˆë‹¤. ë§Œì•½ CMIPì˜ ë³€ë™ì„±ì´ ì¦ê°€í•  ê²½ìš°, ê·¸ ì›ì¸ì„ íŒŒì•…í•˜ê³  ëŒ€ì‘ ì „ëµì„ ë§ˆë ¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ì„ í†µí•´ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ì•ˆì„ ê°•í™”í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "            \n",
      "\n",
      "[ìœ ì‚¬ë„: 1.19]\n",
      "\n",
      "            ì‚¬ìš©ì ì§ˆë¬¸: ê·¸ë˜í”„ í•´ì„ ê°€ëŠ¥í• ê¹Œìš”?\n",
      "            AI ì‘ë‹µ: âŒ í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë§ˆíŠ¸ë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”.\n",
      "            ì‹¤í–‰ëœ ì½”ë“œ: None\n",
      "            ë¶„ì„ ê²°ê³¼: None\n",
      "            ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸: None\n",
      "            ë¦¬í¬íŠ¸: None\n",
      "            \n",
      "\n",
      "[ìœ ì‚¬ë„: 1.16]\n",
      "\n",
      "            ì‚¬ìš©ì ì§ˆë¬¸: ê·¸ë˜í”„ ì»´íŒŒì¼\n",
      "            AI ì‘ë‹µ: ê·¸ë˜í”„ ì»´íŒŒì¼ì€ ì¼ë°˜ì ìœ¼ë¡œ ë°ì´í„° ì‹œê°í™” ë˜ëŠ” ë°ì´í„° ë¶„ì„ì˜ í•œ ë¶€ë¶„ìœ¼ë¡œ, ë°ì´í„°ë¥¼ ê·¸ë˜í”„ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê³¼ì •ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê·¸ë˜í”„ ì»´íŒŒì¼ì„ í†µí•´ ë³µì¡í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë” ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„° ê°„ì˜ ê´€ê³„ë‚˜ íŒ¨í„´ì„ ì‹œê°ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê·¸ë˜í”„ ì»´íŒŒì¼ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìœ¼ë©°, ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë„êµ¬ì™€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Pythonì—ì„œëŠ” Matplotlib, Seaborn, Plotlyì™€ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Rì—ì„œëŠ” ggplot2ê°€ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•  ë•Œ ê³ ë ¤í•´ì•¼ í•  ëª‡ ê°€ì§€ ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ë°ì´í„° ì¤€ë¹„**: ê·¸ë˜í”„ì— ì‚¬ìš©í•  ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  í•„ìš”í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
      "2. **ê·¸ë˜í”„ ìœ í˜• ì„ íƒ**: ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ ë¶„ì„ ëª©ì ì— ë§ëŠ” ê·¸ë˜í”„ ìœ í˜•(ì˜ˆ: ë§‰ëŒ€ ê·¸ë˜í”„, ì„  ê·¸ë˜í”„, ì‚°ì ë„ ë“±)ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "3. **ë ˆì´ë¸” ë° ì œëª© ì¶”ê°€**: ê·¸ë˜í”„ì˜ ì¶•, ì œëª©, ë²”ë¡€ ë“±ì„ ì¶”ê°€í•˜ì—¬ ê·¸ë˜í”„ì˜ ì˜ë¯¸ë¥¼ ëª…í™•íˆ í•©ë‹ˆë‹¤.\n",
      "4. **ìŠ¤íƒ€ì¼ë§**: ê·¸ë˜í”„ì˜ ìƒ‰ìƒ, í°íŠ¸, í¬ê¸° ë“±ì„ ì¡°ì •í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹œê°í™”í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "            ì‹¤í–‰ëœ ì½”ë“œ: None\n",
      "            ë¶„ì„ ê²°ê³¼: None\n",
      "            ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸: None\n",
      "            ë¦¬í¬íŠ¸: None\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "internal_id = \"temp_KSW_20250225_1118\"\n",
    "query = \"ê·¸ë˜í”„ í•´ì„ ê°€ëŠ¥í• ê¹Œìš”?\"\n",
    "retrieved_context = search_similar_questions(internal_id, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### í•µì‹¬ ê°œë…/ìš©ì–´ ì„¤ëª…\n",
      "- **ê·¸ë˜í”„ í•´ì„**: ê·¸ë˜í”„ í•´ì„ì€ ë°ì´í„°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ì—¬ ë°ì´í„° ê°„ì˜ ê´€ê³„ë‚˜ íŒ¨í„´ì„ íŒŒì•…í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³µì¡í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë” ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ê·¸ë˜í”„ ì»´íŒŒì¼**: ê·¸ë˜í”„ ì»´íŒŒì¼ì€ ë°ì´í„°ë¥¼ ê·¸ë˜í”„ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. Pythonì—ì„œëŠ” Matplotlib, Seaborn, Plotlyì™€ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ê´€ë ¨ ì½”ë“œ ì˜ˆì‹œ\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# ê¸°ì¤€ë…„ì›”ë³„ ë³€ì•¡ì¢…ì‹ CMIPì˜ í‰ê·  ì¶”ì„¸ ê³„ì‚°\n",
      "cmip_trend = df.groupby('ê¸°ì¤€ë…„ì›”')['ë³€ì•¡ì¢…ì‹ CMIP'].mean().round(2)\n",
      "\n",
      "# ê²°ê³¼ ì €ì¥\n",
      "analytic_results = {\n",
      "    'CMIP_Trend': cmip_trend\n",
      "}\n",
      "\n",
      "# ì§‘ê³„ì„± ë°ì´í„° ì¶œë ¥\n",
      "print(cmip_trend)\n",
      "```\n",
      "\n",
      "### ì£¼ìš” ì¸ì‚¬ì´íŠ¸/íŒ\n",
      "1. **ë°ì´í„° ì¤€ë¹„**: ê·¸ë˜í”„ì— ì‚¬ìš©í•  ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  í•„ìš”í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
      "2. **ê·¸ë˜í”„ ìœ í˜• ì„ íƒ**: ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ ë¶„ì„ ëª©ì ì— ë§ëŠ” ê·¸ë˜í”„ ìœ í˜•(ì˜ˆ: ë§‰ëŒ€ ê·¸ë˜í”„, ì„  ê·¸ë˜í”„, ì‚°ì ë„ ë“±)ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "3. **ë ˆì´ë¸” ë° ì œëª© ì¶”ê°€**: ê·¸ë˜í”„ì˜ ì¶•, ì œëª©, ë²”ë¡€ ë“±ì„ ì¶”ê°€í•˜ì—¬ ê·¸ë˜í”„ì˜ ì˜ë¯¸ë¥¼ ëª…í™•íˆ í•©ë‹ˆë‹¤.\n",
      "4. **ìŠ¤íƒ€ì¼ë§**: ê·¸ë˜í”„ì˜ ìƒ‰ìƒ, í°íŠ¸, í¬ê¸° ë“±ì„ ì¡°ì •í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
      "\n",
      "### ì¶”ê°€ ì¸ì‚¬ì´íŠ¸\n",
      "- CMIP(ë³€ì•¡ì¢…ì‹ CMIP)ì˜ ì¶”ì„¸ë¥¼ ë¶„ì„í•œ ê²°ê³¼, 2024ë…„ 5ì›”ë¶€í„° 2024ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„°ì—ì„œ í° ë³€ë™ ì—†ì´ ë¹„êµì  ì•ˆì •ì ì¸ ì¶”ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. CMIP ê°’ì€ 17315.90ì—ì„œ 17327.54 ì‚¬ì´ì—ì„œ ì›€ì§ì´ê³  ìˆìœ¼ë©°, ì›”ë³„ë¡œ í° ë³€í™”ëŠ” ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n",
      "- CMIPì˜ ì•ˆì •ì ì¸ ì¶”ì„¸ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ì™¸ë¶€ ê²½ì œ í™˜ê²½ ë³€í™”ì— ëŒ€í•œ ë¯¼ê°ë„ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ í˜„ì¬ ì ‘ê·¼ ê°€ëŠ¥ ë§ˆíŠ¸ ëª©ë¡: ['cust_enroll_history', 'cust_intg', 'product_info']\n",
      "âœ… ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ê¶Œìƒìš°\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        feature        VIF\n",
      "0          ê³ ê°ID       1.01\n",
      "1         ìˆ˜ìµìì—¬ë¶€       1.01\n",
      "2        CBì‹ ìš©í‰ì        1.01\n",
      "3        CBì‹ ìš©ë“±ê¸‰       2.81\n",
      "4         ë‘ë‚«ì½œì—¬ë¶€       1.01\n",
      "..          ...        ...\n",
      "113    ë³€ì•¡ì¢…ì‹ ë³´ìœ ì—¬ë¶€       1.01\n",
      "114  ë³€ì•¡ì¢…ì‹ ìµœëŒ€ë‚©ì…íšŒì°¨       1.01\n",
      "115   ë³€ì•¡ì¢…ì‹ ìœ ì§€ê³„ì•½ìˆ˜       1.01\n",
      "116  ë³€ì•¡ì¢…ì‹ ê¸°ë‚©ì…ë³´í—˜ë£Œ       1.01\n",
      "117        ê¸°ì¤€ë…„ì›”  271226.19\n",
      "\n",
      "[118 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ì—ì„œ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì„ íƒ\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# VIF ê³„ì‚°ì„ ìœ„í•´ ê²°ì¸¡ê°’ ì²˜ë¦¬ (ì„ì‹œë¡œ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´)\n",
    "numeric_df = numeric_df.fillna(numeric_df.mean())\n",
    "\n",
    "# VIF ê³„ì‚°\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = numeric_df.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_df.values, i) for i in range(numeric_df.shape[1])]\n",
    "\n",
    "# 'ë³€ì•¡ì¢…ì‹ CMIP' ì»¬ëŸ¼ì˜ VIF ê°’ í™•ì¸\n",
    "vif_value = vif_data[vif_data['feature'] == 'ë³€ì•¡ì¢…ì‹ CMIP']['VIF'].values[0]\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "analytic_results = {\n",
    "    \"VIF Analysis\": vif_data.round(2).head().to_dict(orient='list'),\n",
    "    \"VIF of ë³€ì•¡ì¢…ì‹ CMIP\": round(vif_value, 2)\n",
    "}\n",
    "\n",
    "print(vif_data.round(2))\n",
    "\n",
    "\"\"\"\n",
    "# í™˜ê²½ ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from ai_agent_v2 import DataAnayticsAssistant\n",
    "\n",
    "# OpenAI API í‚¤ ë¡œë“œ\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "PROCESSED_DATA_PATH = \"../output/stage1/processed_data_info.xlsx\"\n",
    "mart_name = \"cust_intg\"\n",
    "def load_processed_data_info():\n",
    "    \"\"\"ì‚¬ì „ì— ë¶„ì„ëœ ë°ì´í„° ì •ë³´ ë¡œë“œ\"\"\"\n",
    "    if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "        return None\n",
    "    else:\n",
    "        # ëª¨ë“  ì‹œíŠ¸ ë¡œë“œ\n",
    "        return pd.read_excel(PROCESSED_DATA_PATH, sheet_name=mart_name)\n",
    "\n",
    "# âœ… Streamlit ì‹¤í–‰ ì‹œ ë°ì´í„° ë¡œë“œ\n",
    "mart_info = load_processed_data_info()\n",
    "\n",
    "# ì–´ì‹œìŠ¤í„´íŠ¸ ì´ˆê¸°í™”\n",
    "assistant = DataAnayticsAssistant(openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import traceback\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import Dict, Any, Optional, List\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "# âœ… MongoDB ì—°ê²° ì„¤ì •\n",
    "uri = \"mongodb+srv://swkwon:1q2w3e$r@cluster0.3rvbn.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client[\"chat_history\"]\n",
    "collection = db[\"conversations\"]\n",
    "\n",
    "def get_recent_history_weighted(thread_id: str) -> str:\n",
    "    \"\"\"\n",
    "    ìµœê·¼ 5ê°œì˜ ëŒ€í™” ì´ë ¥ì„ ê°€ì ¸ì™€, ìµœì‹  ëŒ€í™”ì¼ìˆ˜ë¡ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì—¬ì„œ Contextë¡œ êµ¬ì„±.\n",
    "    \"\"\"\n",
    "    existing_messages = collection.find({\"internal_id\": thread_id}).sort(\"timestamp\", -1).limit(5)\n",
    "    \n",
    "    messages = []\n",
    "    for document in existing_messages:\n",
    "        messages.extend(document.get(\"messages\", []))\n",
    "    \n",
    "    # ë©”ì‹œì§€ë¥¼ ì§ˆë¬¸-ë‹µë³€ ìŒìœ¼ë¡œ ê·¸ë£¹í™”\n",
    "    message_pairs = []\n",
    "    for i in range(0, len(messages), 2):\n",
    "        if i + 1 < len(messages):  # ë‹µë³€ì´ ìˆëŠ” ê²½ìš°ë§Œ ìŒìœ¼ë¡œ ì¶”ê°€\n",
    "            message_pairs.append((messages[i], messages[i+1]))\n",
    "    \n",
    "    # ìµœì‹  5ê°œì˜ ì§ˆë¬¸-ë‹µë³€ ìŒë§Œ ìœ ì§€\n",
    "    message_pairs = message_pairs[:5]\n",
    "    \n",
    "    # âœ… ê°€ì¤‘ì¹˜ ì„¤ì • (ìµœì‹  ëŒ€í™”ì¼ìˆ˜ë¡ ë†’ê²Œ)\n",
    "    weights = [2.0, 1.5, 1.2, 1.0, 0.8]  # ìµœì‹  ì§ˆë¬¸-ë‹µë³€ì¼ìˆ˜ë¡ ê°€ì¤‘ì¹˜ë¥¼ ë†’ê²Œ ì„¤ì •\n",
    "    weights = weights[:len(message_pairs)]  # ìŒì˜ ìˆ˜ì— ë§ê²Œ ì¡°ì •\n",
    "    \n",
    "    weighted_context = \"\"\n",
    "    for i, (question, answer) in enumerate(reversed(message_pairs)):  # ê³¼ê±° â†’ ìµœì‹  ìˆœì„œë¡œ ì •ë ¬\n",
    "        # ì§ˆë¬¸ ì²˜ë¦¬\n",
    "        content = f\"ì‚¬ìš©ì (ê°€ì¤‘ì¹˜ {weights[i]}): {question['content']}\\n\"\n",
    "        \n",
    "        # ë‹µë³€ ì²˜ë¦¬\n",
    "        content += f\"ì–´ì‹œìŠ¤í„´íŠ¸ (ê°€ì¤‘ì¹˜ {weights[i]}): {answer['content']}\\n\"\n",
    "\n",
    "        # ì½”ë“œê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€\n",
    "        if answer.get(\"validated_code\"):\n",
    "            content += f\"ì‹¤í–‰ëœ ì½”ë“œ:\\n{answer['validated_code']}\\n\"\n",
    "        \n",
    "        # ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€\n",
    "        if answer.get(\"analytic_result\"):\n",
    "            content += f\"ë¶„ì„ ê²°ê³¼:\\n{answer['analytic_result']}\\n\"\n",
    "        \n",
    "        # ì¸ì‚¬ì´íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€\n",
    "        if answer.get(\"insights\"):\n",
    "            content += f\"ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸:\\n{answer['insights']}\\n\"\n",
    "        \n",
    "        weighted_context += content + \"\\n\"\n",
    "\n",
    "    return weighted_context\n",
    "\n",
    "\n",
    "# âœ… ìƒˆë¡œìš´ ì§ˆë¬¸ì— ëŒ€í•´ Context ê¸°ë°˜ ì§ˆë¬¸ ì¬êµ¬ì„±\n",
    "def handle_chat_response(assistant: Any, query: str, internal_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ê¸°ì¡´ ì§ˆë¬¸-ë‹µë³€ì„ ë°˜ì˜í•˜ì—¬ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•˜ê³  ì‘ë‹µì„ ìƒì„±\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"ğŸ¤µ ì§ˆë¬¸ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"ğŸ¤µ Context Window ì²˜ë¦¬ ì‹œì‘\")\n",
    "\n",
    "        # âœ… ìµœê·¼ ëŒ€í™” ë‚´ì—­ ê°€ì ¸ì˜¤ê¸°\n",
    "        chat_history = get_recent_history_weighted(internal_id)\n",
    "        # âœ… LLMì—ê²Œ í˜„ì¬ ì§ˆë¬¸ì´ ì–´ë–¤ íë¦„ì—ì„œ ë‚˜ì™”ëŠ”ì§€ ì¸ì‹ì‹œí‚¤ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ íë¦„ì„ íŒŒì•…í•˜ì—¬, í˜„ì¬ ì§ˆë¬¸ì´ ê¸°ì¡´ ëŒ€í™” ë§¥ë½ì—ì„œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ”ì§€ ë¶„ì„í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. \n",
    "            \n",
    "            ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ìµœê·¼ 5ê°œì˜ ì§ˆë¬¸-ë‹µë³€ ê¸°ë¡ì…ë‹ˆë‹¤. \n",
    "            ì´ë¥¼ ì°¸ê³ í•˜ì—¬, í˜„ì¬ ì§ˆë¬¸ì´ ì–´ë–¤ ì˜ë„ë¡œ ì´ë£¨ì–´ì§„ ê²ƒì¸ì§€ ë¶„ì„í•˜ê³ , \n",
    "            ì´ì „ ì½”ë“œ ë˜ëŠ” ë¶„ì„ íë¦„ì„ ìœ ì§€í•˜ë©´ì„œ ì–´ë–»ê²Œ ë°˜ì˜í•´ì•¼ í•˜ëŠ”ì§€ ê²°ì •í•˜ì„¸ìš”.\n",
    "            \n",
    "            - ê¸°ì¡´ íë¦„ì„ ìœ ì§€í•˜ë©´ì„œ í˜„ì¬ ì§ˆë¬¸ì´ ì¶”ê°€ì ìœ¼ë¡œ ìš”êµ¬í•˜ëŠ” ê²ƒì´ ë¬´ì—‡ì¸ì§€ ë¶„ì„\n",
    "            - ê¸°ì¡´ ì½”ë“œ ë˜ëŠ” ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°, ì–´ë–¤ ë¶€ë¶„ì„ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨\n",
    "            - í•„ìš”í•˜ë©´, ê¸°ì¡´ ê²°ê³¼ í˜•ì‹ì„ ìœ ì§€í•˜ë©´ì„œ ì ì ˆí•œ ì¡°ì •ì„ ìˆ˜í–‰\n",
    "            \"\"\"),\n",
    "            (\"user\", \"### ìµœê·¼ ëŒ€í™” ê¸°ë¡\\n{previous_context}\"),\n",
    "            (\"user\", \"### í˜„ì¬ ì§ˆë¬¸\\n{query}\"),\n",
    "            (\"user\", \"### ë¶„ì„í•´ì•¼ í•  ì§ˆë¬¸ ì˜ë„ ë° ìˆ˜ì •í•  ì½”ë“œ ì˜ì—­\\n(ê¸°ì¡´ íë¦„ì„ ìœ ì§€í•˜ë©° ë°˜ì˜í•  ì‚¬í•­ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.)\")\n",
    "        ])\n",
    "\n",
    "        # âœ… LLMì„ í™œìš©í•˜ì—¬ ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ì„\n",
    "        model = assistant.llm\n",
    "        analyzed_intent = model.invoke({\n",
    "            \"previous_context\": previous_context,\n",
    "            \"query\": query\n",
    "        }).content.strip()\n",
    "\n",
    "        # print(f\"ğŸ¤– ë¶„ì„ëœ ì§ˆë¬¸ ì˜ë„:\\n{analyzed_intent}\")\n",
    "\n",
    "        # # âœ… LLMì„ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ ì§ˆë¬¸ ì¬êµ¬ì„±\n",
    "        # prompt = ChatPromptTemplate.from_messages([\n",
    "        #     (\"system\", \"\"\"ë‹¹ì‹ ì€ ì§ˆë¬¸ íë¦„ì„ ë°˜ì˜í•˜ì—¬ ì§ˆë¬¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¬êµ¬ì„±í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. \n",
    "            \n",
    "        #     ì•„ë˜ ë¶„ì„ëœ ì§ˆë¬¸ ì˜ë„ë¥¼ ì°¸ê³ í•˜ì—¬, ê¸°ì¡´ íë¦„ì„ ìœ ì§€í•˜ë©´ì„œ ì§ˆë¬¸ì„ ì ì ˆí•˜ê²Œ ë³´ê°•í•˜ì„¸ìš”.\n",
    "            \n",
    "        #     - ì§ˆë¬¸ ì˜ë„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ì ì¸ ì„¤ëª…ì„ ë³´ì™„\n",
    "        #     - í•„ìš”í•˜ë©´, ë¶„ì„ ì½”ë“œì— ì ìš©í•´ì•¼ í•˜ëŠ” ì‚¬í•­ì„ ëª…í™•íˆ í¬í•¨\n",
    "        #     - ë¶ˆí•„ìš”í•œ í™•ì¥ì€ ì§€ì–‘í•˜ê³ , ì‚¬ìš©ìì˜ ìš”ì²­ì— ì¶©ì‹¤í•œ ì§ˆë¬¸ìœ¼ë¡œ ë³´ê°•\n",
    "        #     \"\"\"),\n",
    "        #     (\"user\", \"### ë¶„ì„ëœ ì§ˆë¬¸ ì˜ë„\\n{analyzed_intent}\"),\n",
    "        #     (\"user\", \"### ë³´ê°•ëœ ì§ˆë¬¸\\n(ê¸°ì¡´ íë¦„ì„ ìœ ì§€í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ê°•í™”ëœ ì§ˆë¬¸ì„ ì‘ì„±)\")\n",
    "        # ])\n",
    "\n",
    "        # final_query = model.invoke({\n",
    "        #     \"analyzed_intent\": analyzed_intent\n",
    "        # }).content.strip()\n",
    "\n",
    "        # print(f\"ğŸ¤µ ì¬êµ¬ì„±ëœ ì§ˆë¬¸:\\n{final_query}\")\n",
    "\n",
    "        # # âœ… ìµœì¢… ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ LLM í˜¸ì¶œ\n",
    "        # result = assistant.ask(final_query)\n",
    "        # print(f\"ğŸ¤µ ê²°ê³¼:\\n{result}\")\n",
    "\n",
    "        # # âœ… ì‘ë‹µ ë°ì´í„° ì •ë¦¬\n",
    "        # response_data = {\n",
    "        #     \"role\": \"assistant\",\n",
    "        #     \"content\": result.get(\"response\", \"ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"),\n",
    "        #     \"validated_code\": result.get(\"validated_code\"),\n",
    "        #     \"analytic_result\": result.get(\"analytic_result\"),\n",
    "        #     \"chart_filename\": result.get(\"chart_filename\"),\n",
    "        #     \"insights\": result.get(\"insights\"),\n",
    "        #     \"report\": result.get(\"report\"),\n",
    "        #     \"request_summary\": result.get(\"request_summary\"),\n",
    "        # }\n",
    "\n",
    "        # # âœ… MongoDBì— ëŒ€í™” ì´ë ¥ ì €ì¥\n",
    "        # collection.update_one(\n",
    "        #     {\"internal_id\": internal_id},\n",
    "        #     {\n",
    "        #         \"$push\": {\n",
    "        #             \"messages\": {\n",
    "        #                 \"$each\": [\n",
    "        #                     {\n",
    "        #                         \"role\": \"user\", \n",
    "        #                         \"content\": query, \n",
    "        #                         \"timestamp\": datetime.now()\n",
    "        #                     },\n",
    "        #                     {\n",
    "        #                         \"role\": \"assistant\",\n",
    "        #                         \"content\": response_data[\"content\"],\n",
    "        #                         \"validated_code\": response_data[\"validated_code\"],\n",
    "        #                         \"chart_filename\": response_data[\"chart_filename\"],\n",
    "        #                         \"insights\": response_data[\"insights\"],\n",
    "        #                         \"report\": response_data[\"report\"],\n",
    "        #                         \"request_summary\": response_data[\"request_summary\"],\n",
    "        #                         \"timestamp\": datetime.now(),\n",
    "        #                     }   \n",
    "        #                 ]\n",
    "        #             }\n",
    "        #         }\n",
    "        #     },\n",
    "        #     upsert=True\n",
    "        # )\n",
    "\n",
    "        # return response_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {traceback.format_exc()}\")\n",
    "        return { \"role\": \"assistant\", \"content\": f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {traceback.format_exc()}\" }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì‚¬ìš©ì (ê°€ì¤‘ì¹˜ 2.0): ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê¸°ê°€ ì–´ë µë„¤ìš”. ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ì„ transpose í•´ì£¼ì„¸ìš”~\\nì–´ì‹œìŠ¤í„´íŠ¸ (ê°€ì¤‘ì¹˜ 2.0): ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\\nì‹¤í–‰ëœ ì½”ë“œ:\\n```python\\nimport pandas as pd\\n\\n# cust_enroll_history ë°ì´í„°í”„ë ˆì„ì˜ ì „ì¹˜\\ncust_enroll_history_transposed = cust_enroll_history.transpose()\\n\\n# cust_intg ë°ì´í„°í”„ë ˆì„ì˜ ì „ì¹˜\\ncust_intg_transposed = cust_intg.transpose()\\n\\n# ê²°ê³¼ ì €ì¥\\nanalytic_results = {\\n    \\'cust_enroll_history_transposed\\': cust_enroll_history_transposed.head().round(2),\\n    \\'cust_intg_transposed\\': cust_intg_transposed.head().round(2)\\n}\\n\\n# ì§‘ê³„ ë°ì´í„° ì¶œë ¥\\nprint(cust_enroll_history_transposed)\\nprint(cust_intg_transposed)\\n```\\nìƒì„±ëœ ì¸ì‚¬ì´íŠ¸:\\n1. ì£¼ìš” ë°œê²¬ì‚¬í•­\\n   - ë°ì´í„°í”„ë ˆì„ì˜ ì „ì¹˜ë¥¼ í†µí•´ ê° ê³ ê°ì˜ ì •ë³´ë¥¼ í–‰ ë‹¨ìœ„ë¡œ ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ê³ ê°ë³„ë¡œ ê°€ì…í•œ ë³´í—˜ ìƒí’ˆì˜ ì¢…ë¥˜ì™€ ê¸ˆì•¡, ê·¸ë¦¬ê³  ê³ ê°ì˜ ì¸êµ¬í†µê³„í•™ì  íŠ¹ì„±ì„ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.\\n   - `cust_enroll_history_transposed` ë°ì´í„°í”„ë ˆì„ì€ ê³ ê°ì˜ ë³´í—˜ ê°€ì… ë‚´ì—­ì„, `cust_intg_transposed` ë°ì´í„°í”„ë ˆì„ì€ ê³ ê°ì˜ í†µí•© ì •ë³´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ê°ê°ì˜ ë°ì´í„°í”„ë ˆì„ì€ ê³ ê° IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆì–´, ê³ ê°ë³„ë¡œ ë°ì´í„°ë¥¼ ì‰½ê²Œ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n2. íŠ¹ì´ì \\n   - `cust_intg_transposed` ë°ì´í„°í”„ë ˆì„ì—ì„œ ì¼ë¶€ ê³ ê°ì˜ CBì‹ ìš©í‰ì ì´ NaNìœ¼ë¡œ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” í•´ë‹¹ ê³ ê°ì˜ ì‹ ìš©í‰ì  ë°ì´í„°ê°€ ëˆ„ë½ë˜ì—ˆìŒì„ ì˜ë¯¸í•˜ë©°, ë°ì´í„° ë¶„ì„ ì‹œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\\n   - `cust_enroll_history_transposed` ë°ì´í„°í”„ë ˆì„ì˜ ê²½ìš°, ê³ ê°ì´ ê°€ì…í•œ ë³´í—˜ì˜ ì¢…ë¥˜ì™€ ê¸ˆì•¡ì´ ë‹¤ì–‘í•˜ê²Œ ë¶„í¬ë˜ì–´ ìˆì–´, íŠ¹ì • ë³´í—˜ ìƒí’ˆì— ëŒ€í•œ ì„ í˜¸ë„ë‚˜ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤.\\n\\n3. ì¶”ì²œ ì‚¬í•­\\n   - CBì‹ ìš©í‰ì ì´ NaNì¸ ê³ ê°ì— ëŒ€í•´ì„œëŠ” ì¶”ê°€ì ì¸ ë°ì´í„° ìˆ˜ì§‘ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹ ìš©í‰ì ì€ ê³ ê°ì˜ ë¦¬ìŠ¤í¬ í‰ê°€ì— ì¤‘ìš”í•œ ìš”ì†Œì´ë¯€ë¡œ, ì´ë¥¼ ë³´ì™„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\\n   - ê³ ê°ë³„ë¡œ ê°€ì…í•œ ë³´í—˜ ìƒí’ˆì˜ ì¢…ë¥˜ì™€ ê¸ˆì•¡ì„ ë¶„ì„í•˜ì—¬, íŠ¹ì • ì—°ë ¹ëŒ€ë‚˜ ì„±ë³„ì— ë”°ë¥¸ ë³´í—˜ ìƒí’ˆ ì„ í˜¸ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë§ì¶¤í˜• ë³´í—˜ ìƒí’ˆì„ ì œì•ˆí•˜ê±°ë‚˜ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ë° í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - ë°ì´í„°í”„ë ˆì„ì˜ ì „ì¹˜ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬, ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ë³´í—˜ ìƒí’ˆì˜ íŒë§¤ ì „ëµì„ ìµœì í™”í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ëª¨ìƒ‰í•´ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì—°ë ¹ëŒ€ë‚˜ ì„±ë³„ì—ì„œ ì¸ê¸° ìˆëŠ” ë³´í—˜ ìƒí’ˆì„ ì¤‘ì‹¬ìœ¼ë¡œ í”„ë¡œëª¨ì…˜ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\nì‚¬ìš©ì (ê°€ì¤‘ì¹˜ 1.5): ê°€ì…ë‹´ë³´ëª…ì´ \\'ì§ˆë³‘ì‚¬ë§\\'ì¸ ê²ƒì„ Yê°’ìœ¼ë¡œ í•´ì„œ, ê³ ê° ì •ë³´(cust_intg) í”¼ì³ì™€ ê²°í•©í•˜ì—¬, ì–´ë–¤ ì •ë³´ë“¤ì´ ì§ˆë³‘ì‚¬ë§ ë‹´ë³´ ê°€ì…ì— ì˜í–¥ë ¥ì„ ë¼ì³¤ëŠ”ì§€ ë¶„ì„í•´ì¤˜.\\nì–´ì‹œìŠ¤í„´íŠ¸ (ê°€ì¤‘ì¹˜ 1.5): ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\\nì‹¤í–‰ëœ ì½”ë“œ:\\n```python\\nfrom sklearn.utils import resample\\nimport pandas as pd\\n\\n# \\'ì§ˆë³‘ì‚¬ë§\\' ë‹´ë³´ ê°€ì… ì—¬ë¶€ë¥¼ Yê°’ìœ¼ë¡œ ì„¤ì •\\ncust_enroll_history[\\'ì§ˆë³‘ì‚¬ë§_ê°€ì…ì—¬ë¶€\\'] = cust_enroll_history[\\'ê°€ì…ë‹´ë³´ëª…\\'].apply(lambda x: 1 if x == \\'ì§ˆë³‘ì‚¬ë§\\' else 0)\\n\\n# ê³ ê° ì •ë³´ì™€ ê²°í•©\\nmerged_data = pd.merge(cust_intg, cust_enroll_history[[\\'ê³ ê°ID\\', \\'ì§ˆë³‘ì‚¬ë§_ê°€ì…ì—¬ë¶€\\']], on=\\'ê³ ê°ID\\', how=\\'left\\')\\n\\n# í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°: ë‹¤ìˆ˜ í´ë˜ìŠ¤ ë‹¤ìš´ìƒ˜í”Œë§\\nmajority_class = merged_data[merged_data[\\'ì§ˆë³‘ì‚¬ë§_ê°€ì…ì—¬ë¶€\\'] == 0]\\nminority_class = merged_data[merged_data[\\'ì§ˆë³‘ì‚¬ë§_ê°€ì…ì—¬ë¶€\\'] == 1]\\n\\n# ë‹¤ìˆ˜ í´ë˜ìŠ¤ ë‹¤ìš´ìƒ˜í”Œë§\\nif len(minority_class) > 0:\\n    majority_downsampled = resample(majority_class, \\n                                    replace=False, \\n                                    n_samples=len(minority_class), \\n                                    random_state=42)\\n\\n    # ë‹¤ìš´ìƒ˜í”Œë§ëœ ë°ì´í„°ì™€ ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„° ê²°í•©\\n    balanced_data = pd.concat([majority_downsampled, minority_class])\\nelse:\\n    balanced_data = merged_data\\n\\n# ê²°ê³¼ ì €ì¥\\nanalytic_results = {\\n    \\'balanced_data\\': balanced_data.head().round(2)\\n}\\n\\nprint(balanced_data.round(2))\\n```\\nìƒì„±ëœ ì¸ì‚¬ì´íŠ¸:\\n1. ì£¼ìš” ë°œê²¬ì‚¬í•­\\n   - í˜„ì¬ ë°ì´í„°ì…‹ì—ì„œ \\'ì§ˆë³‘ì‚¬ë§\\' ë‹´ë³´ ê°€ì… ì—¬ë¶€ê°€ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë§Œ í¬í•¨ë˜ì–´ ìˆì–´, ì´ë¥¼ Yê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë¶„ì„í•˜ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥í•œ ìƒí™©ì…ë‹ˆë‹¤. ì´ëŠ” í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¡œ, ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ë‹¤ì–‘í•œ í´ë˜ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë°œìƒí•©ë‹ˆë‹¤.\\n\\n2. íŠ¹ì´ì \\n   - ë°ì´í„°ì…‹ì— \\'ì§ˆë³‘ì‚¬ë§\\' ë‹´ë³´ ê°€ì… ì—¬ë¶€ê°€ ëª¨ë‘ 0ìœ¼ë¡œ ë˜ì–´ ìˆì–´, ì‹¤ì œë¡œ ì´ ë‹´ë³´ì— ê°€ì…í•œ ê³ ê°ì´ ë°ì´í„°ì— í¬í•¨ë˜ì§€ ì•Šì•˜ê±°ë‚˜, ë°ì´í„° ìˆ˜ì§‘ ê³¼ì •ì—ì„œ ëˆ„ë½ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\\n   - ê³ ê° ì •ë³´ì™€ ê²°í•©ëœ ë°ì´í„°ì…‹ì—ì„œ \\'ì§ˆë³‘ì‚¬ë§\\' ë‹´ë³´ ê°€ì… ì—¬ë¶€ê°€ ëª¨ë‘ ë™ì¼í•œ ê°’ìœ¼ë¡œ ë‚˜íƒ€ë‚˜, ë°ì´í„°ì˜ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\\n\\n3. ì¶”ì²œ ì‚¬í•­\\n   - ì¶”ê°€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ \\'ì§ˆë³‘ì‚¬ë§\\' ë‹´ë³´ì— ê°€ì…í•œ ê³ ê°ì˜ ë°ì´í„°ë¥¼ í™•ë³´í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í´ë˜ìŠ¤ì˜ ë‹¤ì–‘ì„±ì„ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - ë°ì´í„° ì¦ê°• ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ì¸ìœ„ì ìœ¼ë¡œ ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ë„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, SMOTE(Synthetic Minority Over-sampling Technique)ì™€ ê°™ì€ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - ë°ì´í„° ìˆ˜ì§‘ ê³¼ì •ì—ì„œ \\'ì§ˆë³‘ì‚¬ë§\\' ë‹´ë³´ ê°€ì… ì—¬ë¶€ê°€ ì œëŒ€ë¡œ ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë°ì´í„° ì…ë ¥ ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ ê²€í† í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.\\n   - ë§Œì•½ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì´ ì–´ë ¤ìš´ ê²½ìš°, ë‹¤ë¥¸ ë¶„ì„ ëª©í‘œë¥¼ ì„¤ì •í•˜ê±°ë‚˜, ë‹¤ë¥¸ Yê°’ì„ ì„¤ì •í•˜ì—¬ ë¶„ì„ì„ ì§„í–‰í•˜ëŠ” ê²ƒë„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\nì‚¬ìš©ì (ê°€ì¤‘ì¹˜ 1.2): ê°€ì…ë‹´ë³´ëª…ì´ \\'ì§ˆë³‘ì‚¬ë§\\'ì¸ ê²ƒì„ Yê°’ìœ¼ë¡œ í•´ì„œ, ê³ ê° ì •ë³´(cust_intg) í”¼ì³ì™€ ê²°í•©í•˜ì—¬, ì–´ë–¤ ì •ë³´ë“¤ì´ ì§ˆë³‘ì‚¬ë§ ë‹´ë³´ ê°€ì…ì— ì˜í–¥ë ¥ì„ ë¼ì³¤ëŠ”ì§€ ë¶„ì„í•´ì¤˜.\\nì–´ì‹œìŠ¤í„´íŠ¸ (ê°€ì¤‘ì¹˜ 1.2): {\\'error_type\\': \\'ValueError\\', \\'error_message\\': \\'This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\\', \\'traceback\\': \\'Traceback (most recent call last):\\\\n  File \"C:\\\\\\\\Users\\\\\\\\user\\\\\\\\RAG\\\\\\\\PINE_GENBA\\\\\\\\genba\\\\\\\\src\\\\\\\\utils\\\\\\\\analytic_agent.py\", line 375, in execute_sample_code\\\\n    self._execute_code_with_capture(code_to_execute, exec_globals, is_sample=True)\\\\n  File \"C:\\\\\\\\Users\\\\\\\\user\\\\\\\\RAG\\\\\\\\PINE_GENBA\\\\\\\\genba\\\\\\\\src\\\\\\\\utils\\\\\\\\analytic_agent.py\", line 1005, in _execute_code_with_capture\\\\n    raise e\\\\n  File \"C:\\\\\\\\Users\\\\\\\\user\\\\\\\\RAG\\\\\\\\PINE_GENBA\\\\\\\\genba\\\\\\\\src\\\\\\\\utils\\\\\\\\analytic_agent.py\", line 968, in _execute_code_with_capture\\\\n    exec(code, exec_globals, safe_locals)  # **ì œí•œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì‹¤í–‰**\\\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\n  File \"<string>\", line 35, in <module>\\\\n  File \"C:\\\\\\\\Users\\\\\\\\user\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\sklearn\\\\\\\\base.py\", line 1474, in wrapper\\\\n    return fit_method(estimator, *args, **kwargs)\\\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\n  File \"C:\\\\\\\\Users\\\\\\\\user\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\sklearn\\\\\\\\linear_model\\\\\\\\_logistic.py\", line 1246, in fit\\\\n    raise ValueError(\\\\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\\\\n\\'}\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = get_recent_history_weighted('temp_KSW_20250228_1715')\n",
    "chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ğŸ¤µ ì§ˆë¬¸ì‹œê°: 2025-02-28 19:12:53\n",
      "ğŸ¤µ Context Window ì²˜ë¦¬ ì‹œì‘\n",
      "âŒ ì˜¤ë¥˜ ë°œìƒ: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_34780\\1695025663.py\", line 78, in handle_chat_response\n",
      "    role = \"ì‚¬ìš©ì\" if msg[\"role\"] == \"user\" else \"ì–´ì‹œìŠ¤í„´íŠ¸\"\n",
      "                       ~~~^^^^^^^^\n",
      "TypeError: string indices must be integers, not 'str'\n",
      "\n",
      "{'role': 'assistant', 'content': 'âŒ ì˜¤ë¥˜ ë°œìƒ: Traceback (most recent call last):\\n  File \"C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_34780\\\\1695025663.py\", line 78, in handle_chat_response\\n    role = \"ì‚¬ìš©ì\" if msg[\"role\"] == \"user\" else \"ì–´ì‹œìŠ¤í„´íŠ¸\"\\n                       ~~~^^^^^^^^\\nTypeError: string indices must be integers, not \\'str\\'\\n'}\n"
     ]
    }
   ],
   "source": [
    "res = handle_chat_response(assistant = '' , query = 'ë°ì´í„°í”„ë ˆì„ ê²°ê³¼ê°€ ë§˜ì—ì•ˆë“¤ì–´' ,internal_id='temp_KSW_20250228_1715')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
