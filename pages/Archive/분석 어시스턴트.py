import os
from glob import glob
import streamlit as st
from loguru import logger
from openai import OpenAIError
from dotenv import load_dotenv
load_dotenv()  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
import warnings
import traceback  # ì¶”ê°€ëœ ë¶€ë¶„

# âœ… LangGraph ë° LangChain ê´€ë ¨ ëª¨ë“ˆ
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_openai import OpenAIEmbeddings

# âœ… AI Assistant LangGraph Class Import
from utils.ai_agent import AIAnalysisAssistant  # ai_agent.pyì— í•´ë‹¹ í´ë˜ìŠ¤ ì •ì˜

warnings.filterwarnings('ignore')

st.set_page_config(page_title="ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸", page_icon="ğŸ”", layout='wide')

# âœ… ìŠ¤íƒ€ì¼ ìµœì í™”
st.markdown(
    """
    <style>
        [data-testid="stSidebar"] {
            min-width: 250px;
            max-width: 250px;
        }
        .stChatMessage { max-width: 90% !important; }
        .stMarkdown { font-size: 16px; }
    </style>
    """,
    unsafe_allow_html=True
)

st.markdown(
    """
    <style>
        .reference-doc {
            font-size: 12px !important;
        }
        /* í…Œì´ë¸” í°íŠ¸ í¬ê¸° ì¡°ì • */
        table {
            font-size: 12px !important;  /* í…Œì´ë¸” í°íŠ¸ í¬ê¸° */
        }
    </style>
    """,
    unsafe_allow_html=True
)

def main():
    # âœ… OpenAI API Key í™•ì¸
    openai_api_key = os.getenv('OPENAI_API_KEY')
    if not openai_api_key:
        st.warning("âš ï¸ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # âœ… ë²¡í„°ìŠ¤í† ì–´ (FAISS) ë¡œë“œ
    if "vectorstore" not in st.session_state:
        with st.spinner("ğŸ”„ ë¬¸ë§¥ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            vectorstore = load_vectorstore()
            if vectorstore:
                st.session_state["vectorstore"] = vectorstore
            else:
                st.warning("âš ï¸ ë¬¸ë§¥ì´ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë¬¸ë§¥ ë“±ë¡' í˜ì´ì§€ì—ì„œ ë¬¸ì„œë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
                return
    else:
        vectorstore = st.session_state["vectorstore"]

    # âœ… LangGraph ê¸°ë°˜ AI Assistant ì´ˆê¸°í™”
    if "assistant" not in st.session_state:
        with st.spinner("ğŸ¤– AI Agentë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            st.session_state.assistant = AIAnalysisAssistant(vectorstore, openai_api_key)

    # âœ… ë¬¸ì„œ ëª©ë¡ì„ ì¢Œìƒë‹¨ì— í‘œì‹œ
    with st.sidebar:
        st.subheader("ğŸ“„ ë“±ë¡ëœ ë¬¸ì„œ ëª©ë¡")
        document_list = st.session_state.get("document_list", [])
        if document_list:
            for doc in document_list:
                st.write(f"- {doc}")
        else:
            st.info("ë“±ë¡ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    # âœ… ë¬¸ë§¥ê³¼ API Keyê°€ ì •ìƒì ìœ¼ë¡œ ë“±ë¡ëœ ê²½ìš° ì±„íŒ… í™œì„±í™”
    st.success("âœ… ë¬¸ë§¥ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    st.success("âœ… OpenAI API Keyê°€ ì •ìƒì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")

    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! AI ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"}]

    # âœ… ì´ì „ ëŒ€í™” í‘œì‹œ
    for message in st.session_state["messages"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    if query:
        st.session_state["messages"].append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.markdown(query)

        with st.chat_message("assistant"):
            assistant = st.session_state.assistant
            try:
                with st.spinner("ğŸ” ë‹µë³€ì„ ìƒì„± ì¤‘..."):
                    result = assistant.ask(query)
                    # print(f"ğŸ” result: {result}")
                    # response = result['generation']\
                    response =  ["messages"][-1].content
                    
                    if "documents" in result:
                        source_documents = result['documents']
                        # print(f"ğŸ” source_documents: {response}")

                    st.markdown(response)

                    # âœ… ì¿¼ë¦¬ 
                    if "dataframe" in result:
                        st.markdown("**ì‹¤í–‰ ì¿¼ë¦¬ :**")
                        st.code(result["query"])

                    # âœ… ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼ ì¶œë ¥
                    if "dataframe" in result:
                        st.markdown("**ì‹¤í–‰ ì¿¼ë¦¬ ê²°ê³¼(ìµœëŒ€ 20í–‰ë§Œ ì¶œë ¥):**")
                        st.dataframe(result["dataframe"])

                    # âœ… ì°¨íŠ¸ ì´ë¯¸ì§€ ì¶œë ¥
                    if "chart_filename" in result and result["chart_filename"]:
                        st.markdown("**ì°¨íŠ¸ ê²°ê³¼:**")
                        st.image(f"./img/{result['chart_filename']}", caption="ì°¨íŠ¸ ê²°ê³¼")

                    # âœ… ì¸ì‚¬ì´íŠ¸ ì¶œë ¥
                    if "insights" in result:
                        st.markdown("**ì¸ì‚¬ì´íŠ¸:**")
                        st.markdown(result["insights"])

                    # âœ… ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
                    if "report_filename" in result and result["report_filename"] == "success":
                        excel_file_path = max(glob(os.path.join("../output", '*.xlsx')), key=os.path.getctime)  # ìƒì„±ëœ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
                        if os.path.exists(excel_file_path):
                            with open(excel_file_path, 'rb') as file:
                                st.download_button(
                                    label="ğŸ“¥ ì—‘ì…€ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                                    data=file,
                                    file_name='final_report.xlsx',
                                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                                )

                    st.session_state["messages"].append({"role": "assistant", "content": response})

                    if "documents" in result:
                        with st.expander("ğŸ“‚ ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                            st.markdown('<div class="reference-doc">', unsafe_allow_html=True)
                            for i, doc in enumerate(source_documents[:3]):
                                st.markdown(f"ğŸ“„ **ì¶œì²˜ {i+1}:** {doc.metadata['source']}")
                                st.markdown(f"> {doc.page_content[:200]} ...")
                            st.markdown('</div>', unsafe_allow_html=True)

            except Exception as e:
                st.error(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n\n {traceback.format_exc()}")


        st.session_state["messages"].append({"role": "assistant", "content": response})

# âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ í•¨ìˆ˜
def load_vectorstore():
    if os.path.exists("./vectordb"):
        # embeddings = HuggingFaceEmbeddings(
        #     model_name="jhgan/ko-sroberta-multitask",
        #     model_kwargs={'device': 'cpu'},
        #     encode_kwargs={'normalize_embeddings': True}
        # )
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

        return FAISS.load_local("./vectordb", embeddings, allow_dangerous_deserialization=True)
    else:
        return None  # ì €ì¥ëœ ì¸ë±ìŠ¤ê°€ ì—†ì„ ê²½ìš° None ë°˜í™˜

if __name__ == '__main__':
    main()
