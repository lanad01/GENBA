{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key, temperature=0.0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 {ability} 에 능숙한 어시스턴트입니다. 20자 이내로 응답하세요\",\n",
    "        ),\n",
    "        # 대화 기록을 변수로 사용, history 가 MessageHistory 의 key 가 됨\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # 사용자 입력을 변수로 사용\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model  # 프롬프트와 모델을 연결하여 runnable 객체 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('67bc931f63ff371c56b373df'),\n",
       " 'thread_id': 'User Introduction',\n",
       " 'messages': [{'role': 'user', 'content': '제 이름이 뭐라구요?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '죄송하지만, 저는 사용자의 이름을 알 수 없습니다. 개인 정보를 저장하거나 접근할 수 있는 기능이 없기 때문에, 사용자의 이름을 알 수 없습니다. 다른 질문이나 도움이 필요하시면 언제든지 말씀해 주세요!'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_conversation = collection.(\n",
    "    {\"thread_id\": thread_id},\n",
    "    {\"messages\": 1}  # messages 필드만 조회\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 질문시각: 2025-02-25 00:42:45\n",
      "[DEBUG] [handle_chat_response] 이전 대화 기록:\n",
      "사용자: 제 이름이 뭐라구요?\n",
      "어시스턴트: 죄송하지만, 저는 사용자의 이름을 알 수 없습니다. 개인 정보를 저장하거나 접근할 수 있는 기능이 없기 때문에, 사용자의 이름을 알 수 없습니다. 다른 질문이나 도움이 필요하시면 언제든지 말씀해 주세요!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import traceback\n",
    "import streamlit as st\n",
    "from typing import Dict, Any, Optional, Union\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "# 사용자 패키지\n",
    "from utils.vector_handler import save_chat_to_vector_db, search_similar_questions\n",
    "\n",
    "# ✅ MongoDB Atlas 연결 설정\n",
    "uri = \"mongodb+srv://swkwon:1q2w3e$r@cluster0.3rvbn.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client[\"chat_history\"]\n",
    "collection = db[\"conversations\"]\n",
    "\n",
    "# ✅ 메모리 저장소 (thread_id별로 관리)\n",
    "memory_store = {}\n",
    "\n",
    "def get_memory(thread_id: str) -> ConversationBufferMemory:\n",
    "    \"\"\"\n",
    "    특정 thread_id에 대한 ConversationBufferMemory를 반환.\n",
    "    기존 데이터가 있으면 불러오고, 없으면 새로 생성.\n",
    "    \"\"\"\n",
    "    if thread_id not in memory_store:\n",
    "        memory_store[thread_id] = ConversationBufferMemory(memory_key=f\"history_{thread_id}\", return_messages=True)\n",
    "    \n",
    "        # ✅ MongoDB에서 이전 대화 기록 불러오기\n",
    "        existing_messages = collection.find_one({\"thread_id\": thread_id})\n",
    "        if existing_messages:\n",
    "            for msg in existing_messages.get(\"messages\", []):\n",
    "                if msg[\"role\"] == \"user\":\n",
    "                    memory_store[thread_id].chat_memory.add_user_message(msg[\"content\"])\n",
    "                elif msg[\"role\"] == \"assistant\":\n",
    "                    memory_store[thread_id].chat_memory.add_ai_message(msg[\"content\"])\n",
    "\n",
    "    return memory_store[thread_id]\n",
    "\n",
    "# ✅ 채팅 응답 처리\n",
    "try:\n",
    "    thread_id = 'User Introduction'\n",
    "    print(f\"🔍 질문시각: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # ✅ thread_id별 memory 가져오기\n",
    "    memory = get_memory(thread_id)\n",
    "\n",
    "    # ✅ 기존 대화 기록 가져오기\n",
    "    messages = memory.load_memory_variables({}).get(f\"history_{thread_id}\", \"\")\n",
    "\n",
    "    # 메시지 객체를 읽기 쉬운 대화 형식으로 변환\n",
    "    previous_context = \"\"\n",
    "    if messages:\n",
    "        for msg in messages:\n",
    "            if msg.type == 'human':\n",
    "                previous_context += f\"사용자: {msg.content}\\n\"\n",
    "            elif msg.type == 'ai':\n",
    "                previous_context += f\"어시스턴트: {msg.content}\\n\"\n",
    "\n",
    "    print(f\"[DEBUG] [handle_chat_response] 이전 대화 기록:\\n{previous_context}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] [handle_chat_response] 오류 발생: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ thread_id별 memory 가져오기\n",
    "memory = get_memory(thread_id)\n",
    "\n",
    "# ✅ 기존 대화 기록 가져오기\n",
    "messages = memory.load_memory_variables({}).get(f\"history_{thread_id}\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history_Location Inquiry': [AIMessage(content='분석이 완료되었습니다! 아래 결과를 확인해주세요.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='분석이 완료되었습니다! 아래 결과를 확인해주세요.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://swkwon:1q2w3e$r@cluster0.3rvbn.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history_12345': 'Human: 안녕하세요?\\nAI: 안녕하세요! 무엇을 도와드릴까요?'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6884\\2605556453.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory_store[thread_id] = ConversationBufferMemory(memory_key=f\"history_{thread_id}\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 각 thread_id별 메모리를 딕셔너리로 관리\n",
    "memory_store = {}\n",
    "\n",
    "def get_memory(thread_id):\n",
    "    if thread_id not in memory_store:\n",
    "        memory_store[thread_id] = ConversationBufferMemory(memory_key=f\"history_{thread_id}\")\n",
    "    return memory_store[thread_id]\n",
    "\n",
    "# 특정 thread_id에 대한 메모리 사용\n",
    "thread_id = \"12345\"\n",
    "memory = get_memory(thread_id)\n",
    "\n",
    "# 히스토리 추가\n",
    "memory.save_context({\"input\": \"안녕하세요?\"}, {\"output\": \"안녕하세요! 무엇을 도와드릴까요?\"})\n",
    "\n",
    "# 해당 thread_id의 히스토리 가져오기\n",
    "print(memory.load_memory_variables({}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}  # 세션 기록을 저장할 딕셔너리\n",
    "\n",
    "\n",
    "# 세션 ID를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids: str) -> BaseChatMessageHistory:\n",
    "    print(session_ids)\n",
    "    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(  # RunnableWithMessageHistory 객체 생성\n",
    "        runnable,  # 실행할 Runnable 객체\n",
    "        get_session_history,  # 세션 기록을 가져오는 함수\n",
    "        input_messages_key=\"input\",  # 입력 메시지의 키\n",
    "        history_messages_key=\"history\",  # 기록 메시지의 키\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_message': AIMessage(content='The cosine of an angle in a right-angled triangle is the ratio of the length of the side adjacent to the angle to the length of the hypotenuse of the triangle. Alternatively, the cosine of an angle in a unit circle is the x-coordinate of the point where the terminal side of the angle intersects the circle. The cosine function is a trigonometric function that is periodic with a period of 2π and has a range of -1 to 1.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 96, 'prompt_tokens': 14, 'total_tokens': 110, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-615edc0d-5f6f-4fbf-b3be-3a61090639c6-0', usage_metadata={'input_tokens': 14, 'output_tokens': 96, 'total_tokens': 110, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# chain 생성\n",
    "chain = RunnableParallel({\"output_message\": ChatOpenAI()})\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    # 세션 ID에 해당하는 대화 기록이 저장소에 없으면 새로운 ChatMessageHistory를 생성합니다.\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    # 세션 ID에 해당하는 대화 기록을 반환합니다.\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "# 체인에 대화 기록 기능을 추가한 RunnableWithMessageHistory 객체를 생성합니다.\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    # 입력 메시지의 키를 \"input\"으로 설정합니다.(생략시 Message 객체로 입력)\n",
    "    # input_messages_key=\"input\",\n",
    "    # 출력 메시지의 키를 \"output_message\"로 설정합니다. (생략시 Message 객체로 출력)\n",
    "    output_messages_key=\"output_message\",\n",
    ")\n",
    "\n",
    "# 주어진 메시지와 설정으로 체인을 실행합니다.\n",
    "with_message_history.invoke(\n",
    "    # 혹은 \"what is the definition of cosine?\" 도 가능\n",
    "    [HumanMessage(content=\"what is the definition of cosine?\")],\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi! Need any help?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: what is the definition of cosine?\n",
      "AI: The cosine of an angle in a right-angled triangle is the ratio of the length of the side adjacent to the angle to the length of the hypotenuse of the triangle. Alternatively, the cosine of an angle in a unit circle is the x-coordinate of the point where the terminal side of the angle intersects the circle. The cosine function is a trigonometric function that is periodic with a period of 2π and has a range of -1 to 1.\n",
      "Human: 이전의 내용을 한글로 답변해 주세요!\n",
      "AI: 코사인은 직각삼각형에서 각의 인접변의 길이와 빗변의 길이의 비율을 나타내는 것입니다. 또는 단위 원에서의 각의 코사인은 각의 종단면이 원과 만나는 지점의 x좌표를 나타냅니다. 코사인 함수는 주기가 2π이고 범위가 -1에서 1까지인 삼각함수입니다.\n",
      "Human: 이전의 내용을 한글로 답변해 주세요!\n",
      "AI: 코사인은 직각삼각형에서 한 각의 코사인을 정의할 때, 그 각의 인접변의 길이를 빗변의 길이로 나눈 비율로 정의됩니다. 또는 단위 원에서 각의 코사인은 그 각의 종선이 원과 만나는 점의 x좌표로 정의됩니다. 코사인 함수는 주기가 \\(2\\pi\\)인 주기 함수이며, 함수 값의 범위는 -1에서 1 사이입니다.\n"
     ]
    }
   ],
   "source": [
    "print(get_session_history(\"abc123\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='코사인은 직각삼각형에서 한 각의 코사인을 정의할 때, 그 각의 인접변의 길이를 빗변의 길이로 나눈 비율로 정의됩니다. 또는 단위 원에서 각의 코사인은 그 각의 종선이 원과 만나는 점의 x좌표로 정의됩니다. 코사인 함수는 주기가 \\\\(2\\\\pi\\\\)인 주기 함수이며, 함수 값의 범위는 -1에서 1 사이입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 241, 'total_tokens': 347, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-0b2c7320-03b2-466a-a13b-5bb3c565b5c1-0', usage_metadata={'input_tokens': 241, 'output_tokens': 106, 'total_tokens': 347, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,  # ChatOpenAI 언어 모델을 사용합니다.\n",
    "    get_session_history,  # 대화 세션 기록을 가져오는 함수를 지정합니다.\n",
    "    # 입력 메시지의 키를 \"input\"으로 설정합니다.(생략시 Message 객체로 입력)\n",
    "    # input_messages_key=\"input\",\n",
    "    # 출력 메시지의 키를 \"output_message\"로 설정합니다. (생략시 Message 객체로 출력)\n",
    "    # output_messages_key=\"output_message\",\n",
    ")\n",
    "\n",
    "res = with_message_history.invoke(\n",
    "    # 이전의 답변에 대하여 한글로 답변을 재요청합니다.\n",
    "    [HumanMessage(content=\"이전의 내용을 한글로 답변해 주세요!\")],\n",
    "    # 설정 옵션을 딕셔너리 형태로 전달합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\", \"conversation_id\": \"1\"}},\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector + RunnableWithMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import streamlit as st\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "# ✅ 사용자별 벡터DB 저장 경로 설정\n",
    "VECTOR_DB_BASE_PATH = \"./vector_dbs\"\n",
    "\n",
    "def get_vector_db_path(session_id):\n",
    "    \"\"\"세션 ID 기반으로 개별 벡터DB 경로 생성\"\"\"\n",
    "    return os.path.join(VECTOR_DB_BASE_PATH, f\"{session_id}_vectorstore\")\n",
    "\n",
    "def initialize_vector_store(session_id):\n",
    "    \"\"\"사용자(쓰레드)별 FAISS 벡터스토어 초기화 및 불러오기\"\"\"\n",
    "    vector_db_path = get_vector_db_path(session_id)\n",
    "    \n",
    "    if os.path.exists(vector_db_path):\n",
    "        # allow_dangerous_deserialization 매개변수 추가\n",
    "        return FAISS.load_local(\n",
    "            vector_db_path, \n",
    "            OpenAIEmbeddings(),\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "    else:\n",
    "        return FAISS.from_texts([\"\"], OpenAIEmbeddings())\n",
    "\n",
    "def save_vector_store(session_id, vectorstore):\n",
    "    \"\"\"사용자(쓰레드)별 FAISS 벡터스토어 저장\"\"\"\n",
    "    vector_db_path = get_vector_db_path(session_id)\n",
    "    os.makedirs(os.path.dirname(vector_db_path), exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "    vectorstore.save_local(vector_db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable\n",
    "from typing import Any, Optional, Dict\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "class ThreadBasedQuestionAnsweringRunnable(Runnable):\n",
    "    \"\"\"\n",
    "    사용자(쓰레드)별 벡터DB와 대화 이력을 관리하는 Runnable\n",
    "    \"\"\"\n",
    "    def __init__(self, message_history_runnable: RunnableWithMessageHistory, session_id: str):\n",
    "        self._session_id = session_id\n",
    "        self.message_history = message_history_runnable\n",
    "        self.vectorstore = initialize_vector_store(session_id)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "    \n",
    "    \n",
    "    def invoke(self, input_data: Dict, config: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        input_data: {\"query\": \"사용자의 질문\"}\n",
    "        \"\"\"\n",
    "        user_query = input_data[\"query\"]\n",
    "        \n",
    "        # 벡터DB에서 유사 질문 검색\n",
    "        search_results = self.vectorstore.similarity_search(user_query, k=2)\n",
    "        retrieved_context = \"\\n\\n\".join([doc.page_content for doc in search_results])\n",
    "\n",
    "        # 새로운 질문을 벡터DB에 저장\n",
    "        self.vectorstore.add_texts([user_query])\n",
    "        save_vector_store(self._session_id, self.vectorstore)  # _session_id 사용\n",
    "\n",
    "        # 메시지 기록 처리\n",
    "        config = config or {}\n",
    "        config[\"configurable\"] = {\"session_id\": self._session_id}\n",
    "        \n",
    "        # 메시지 기록에 추가하고 LLM 응답 얻기\n",
    "        llm_response = self.message_history.invoke(\n",
    "            [HumanMessage(content=f\"{retrieved_context}\\n\\n{user_query}\")],\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"query\": user_query,\n",
    "            \"retrieved_context\": retrieved_context,\n",
    "            \"llm_response\": llm_response,\n",
    "            \"session_id\": self._session_id\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔵 [사용자 1] 질문 저장 및 검색\n",
      "\n",
      "🟢 [사용자 2] 질문 저장 및 검색\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '새로운 분석 결과를 다시 확인할 수 있을까?',\n",
       " 'retrieved_context': '새로운 분석 결과를 다시 확인할 수 있을까?\\n\\n새로운 데이터로 이상치를 제거하고 싶어.',\n",
       " 'llm_response': AIMessage(content='새로운 데이터로 이상치를 제거하고 분석 결과를 확인하는 것은 가능합니다. 하지만, 이전에 수행한 분석 결과를 저장하거나 불러오는 기능은 제공되지 않기 때문에, 새로운 데이터에 대해 이상치를 제거하고 분석을 수행하는 방법을 안내해 드리겠습니다.\\n\\n1. **이상치 제거**: 새로운 데이터에서 이상치를 제거하는 방법 중 하나는 IQR(Interquartile Range) 방법입니다. 이 방법을 사용하여 이상치를 제거할 수 있습니다.\\n\\n2. **분석 결과 확인**: 이상치를 제거한 후, 데이터에 대한 다양한 분석을 수행할 수 있습니다. 예를 들어, 데이터의 기초 통계량을 확인하거나, 상관관계를 분석할 수 있습니다.\\n\\n다음은 이러한 과정을 수행하는 예제 코드입니다:\\n\\n```python\\nimport pandas as pd\\n\\n# 예시 데이터프레임 생성\\n# df_new = pd.read_csv(\\'your_new_data.csv\\')  # 실제 데이터 로드\\n\\ndef remove_outliers_iqr(df, column):\\n    # 1사분위수와 3사분위수 계산\\n    Q1 = df[column].quantile(0.25)\\n    Q3 = df[column].quantile(0.75)\\n    IQR = Q3 - Q1\\n\\n    # 이상치 경계 설정\\n    lower_bound = Q1 - 1.5 * IQR\\n    upper_bound = Q3 + 1.5 * IQR\\n\\n    # 이상치 제거\\n    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\\n    return df_filtered\\n\\n# 모든 수치형 컬럼에 대해 이상치 제거\\nfor col in df_new.select_dtypes(include=[\\'float64\\', \\'int64\\']).columns:\\n    df_new = remove_outliers_iqr(df_new, col)\\n\\n# 이상치 제거 후 데이터프레임 확인\\nprint(\"이상치 제거 후 데이터프레임:\")\\nprint(df_new.describe())\\n\\n# 상관관계 분석\\ncorrelation_matrix = df_new.corr()\\nprint(\"상관관계 행렬:\")\\nprint(correlation_matrix)\\n\\n# 상관관계 히트맵 시각화 (옵션)\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(10, 8))\\nsns.heatmap(correlation_matrix, annot=True, cmap=\\'coolwarm\\', fmt=\".2f\")\\nplt.title(\\'Correlation Matrix\\')\\nplt.show()\\n```\\n\\n이 코드는 새로운 데이터에서 이상치를 제거하고, 이상치가 제거된 데이터의 기초 통계량과 상관관계를 분석하는 방법을 보여줍니다. `describe()` 메소드를 사용하여 데이터의 기초 통계량을 확인할 수 있으며, `corr()` 메소드를 사용하여 상관관계를 분석할 수 있습니다. 또한, `seaborn` 라이브러리를 사용하여 상관관계 히트맵을 시각화할 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 617, 'prompt_tokens': 1344, 'total_tokens': 1961, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-a641c0a6-994a-4e3a-a8c1-334b0bfc35c9-0', usage_metadata={'input_tokens': 1344, 'output_tokens': 617, 'total_tokens': 1961, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'session_id': 'abc123'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = {}  # 세션 기록을 저장할 딕셔너리\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    # 세션 ID에 해당하는 대화 기록이 저장소에 없으면 새로운 ChatMessageHistory를 생성합니다.\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    # 세션 ID에 해당하는 대화 기록을 반환합니다.\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,  # ChatOpenAI 언어 모델을 사용합니다.\n",
    "    get_session_history,  # 대화 세션 기록을 가져오는 함수를 지정합니다.\n",
    "    # 입력 메시지의 키를 \"input\"으로 설정합니다.(생략시 Message 객체로 입력)\n",
    "    # input_messages_key=\"input\",\n",
    "    # 출력 메시지의 키를 \"output_message\"로 설정합니다. (생략시 Message 객체로 출력)\n",
    "    # output_messages_key=\"output_message\",\n",
    ")\n",
    "\n",
    "# ✅ 쓰레드별 인스턴스 생성 (사용자 1, 사용자 2)\n",
    "user_1_runnable = ThreadBasedQuestionAnsweringRunnable(with_message_history, 'abc123')\n",
    "user_2_runnable = ThreadBasedQuestionAnsweringRunnable(with_message_history, 'abc123')\n",
    "\n",
    "# ✅ 사용자 1의 질문 저장 및 검색\n",
    "print(\"\\n🔵 [사용자 1] 질문 저장 및 검색\")\n",
    "user_1_runnable.invoke({\"query\": \"df_cust에 대한 컬럼별로 결측치가 20% 이상인 컬럼은 제거하는 코드를 생성해줘.\"})\n",
    "user_1_runnable.invoke({\"query\": \"이전 분석 결과에서 상관관계를 확인하고 싶어.\"})\n",
    "\n",
    "# ✅ 사용자 2의 질문 저장 및 검색\n",
    "print(\"\\n🟢 [사용자 2] 질문 저장 및 검색\")\n",
    "user_2_runnable.invoke({\"query\": \"새로운 데이터로 이상치를 제거하고 싶어.\"})\n",
    "user_2_runnable.invoke({\"query\": \"새로운 분석 결과를 다시 확인할 수 있을까?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.vector_handler import initialize_vector_store\n",
    "\n",
    "thread_id = 'new_chat'\n",
    "query = 'columns_with_20_percent_missing 가 뭐라구 했죠?'\n",
    "vectorstore = initialize_vector_store(thread_id)  # 세션별 벡터스토어 로드\n",
    "\n",
    "\n",
    "# 🔎 검색 실행\n",
    "search_results = vectorstore.similarity_search(query, k=2)\n",
    "retrieved_context = \"\\n\\n\".join([doc.page_content for doc in search_results])\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x24744a56fc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VECTOR_DB_SESSION_PATH = './vector_db_session' \n",
    "vector_db_path = os.path.join(VECTOR_DB_SESSION_PATH, f\"new_chat_vectorstore\")\n",
    "\n",
    "DDS = FAISS.load_local(vector_db_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)  # ✅ 신뢰할 수 있는 로컬 데이터이므로 허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document ID: 94c4d233-b717-42f3-a7f4-a7b1e8916706\n",
      "Content: \n"
     ]
    }
   ],
   "source": [
    "all_docs = vectorstore.docstore._dict\n",
    "all_docs\n",
    "\n",
    "for doc_id, doc in all_docs.items():\n",
    "    print(f\"\\nDocument ID: {doc_id}\")\n",
    "    print(f\"Content: {doc.page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
