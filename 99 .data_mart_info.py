import pandas as pd
import os
from dotenv import load_dotenv
import warnings
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ì„¤ì •
pd.options.display.float_format = '{:.3f}'.format
warnings.filterwarnings('ignore')
load_dotenv()

# âœ… OpenAI API Key í™•ì¸
openai_api_key = os.getenv('OPENAI_API_KEY')
llm = ChatOpenAI(model="gpt-4o", openai_api_key=openai_api_key, temperature=0)

# âœ… ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ê°ì²´ ì„ ì–¸
results = {}
list_df = {}

# âœ… ë°ì´í„° ë¡œë“œ: ../data ê²½ë¡œì˜ ëª¨ë“  pkl íŒŒì¼ ì½ê¸°
data_path = os.path.join('..', 'data')
for file in os.listdir(data_path):
    if file.endswith('.pkl'):
        file_path = os.path.join(data_path, file)
        df_name = file.replace('.pkl', '')
        list_df[df_name] = pd.read_pickle(file_path)

list_df_text = ", ".join(list_df.keys())

# âœ… í”„ë¡¬í”„íŠ¸ ë° í•¨ìˆ˜ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°
prompt = open(f'prompt/001_prompt_data_summary.txt', 'r', encoding='utf-8').read().format(list_df_text=list_df_text)
func_code = open(f'sample_func/func_data_summary.py', 'r', encoding='utf-8').read()

# âœ… LLMì— ì²« ë²ˆì§¸ ì½”ë“œ ìš”ì²­ (ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë‹¨ê³„)
chain = ChatPromptTemplate.from_messages([
    ("system", prompt),
    ("user", "### ì°¸ê³  ì½”ë“œ:\n{func_code}\n\n"),
    ("user", "### list_df:\n{list_df_text}\n\n")
]) | llm

response = chain.invoke({"func_code": func_code, "list_df_text": list_df_text}).content

attempt_count = 0  # ì‹¤í–‰ ì‹œë„ íšŸìˆ˜
success = False  # ì½”ë“œ ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€

while attempt_count < 2:  # ìµœì´ˆ ì‹¤í–‰ + 1íšŒ ì¬ì‹œë„ ê°€ëŠ¥
    try:
        if "```python" in response:
            modified_code = response.split("```python")[-1].split("```")[0]
            print(f"[LOG] ì‹¤í–‰í•  ì½”ë“œ:\n{modified_code}")
            exec(modified_code, globals())  # LLMì´ ìƒì„±í•œ ì½”ë“œ ì‹¤í–‰
            print(f"[Stage 1. ë°ì´í„° êµ¬ì¡° íŒŒì•…] 1ì°¨ ì‹œë„ | âœ… ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!")
            success = True
            break  # ì‹¤í–‰ ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ
    except Exception as e:
        error_message = str(e)
        print(f"âŒ {attempt_count+1}ì°¨ ì‹œë„ : LLM ìƒì„± ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_message}")

        if attempt_count == 0:  # ìµœì´ˆ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ 1íšŒë§Œ ì¬ìƒì„±
            print("ğŸ”„ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½”ë“œ ìˆ˜ì • ìš”ì²­ ì¤‘...")

            # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì— ì½”ë“œ ìˆ˜ì • ìš”ì²­
            prompt_error_fix = f"""
            ### ì½”ë“œ ìˆ˜ì • ìš”ì²­

            ì´ì „ ì½”ë“œ ì‹¤í–‰ ì¤‘ ë‹¤ìŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:
            ```
            {error_message}
            ```

            ìœ„ ì˜¤ë¥˜ë¥¼ í•´ê²°í•œ ìƒˆë¡œìš´ ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.
            - ê¸°ì¡´ ì½”ë“œì—ì„œ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ ë²„ì „ìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
            - ì½”ë“œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ë³´ì™„í•´ì•¼ í•©ë‹ˆë‹¤.

            ```python
            # í•„ìš”í•œ ì½”ë“œ ì‚½ì…
            ```
            """
            chain_error_fix = ChatPromptTemplate.from_messages([
                ("system", prompt_error_fix),
                ("user", "### ê¸°ì¡´ ì½”ë“œ:\n{modified_code}\n\n")
            ]) | llm

            response = chain_error_fix.invoke({"modified_code": modified_code}).content
        else:
            print("âŒ ì½”ë“œ ì‹¤í–‰ ìµœì¢…ì ìœ¼ë¡œ ì‹¤íŒ¨. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")

        attempt_count += 1  # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€

# âœ… Stage 1 ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ ë‚´ ë³€ìˆ˜ë¡œ ì €ì¥
stage1_results = analyze_multiple_dataframes(list_df, save_format="memory")
results["stage1"] = stage1_results  # âœ… Stage 1 ê²°ê³¼ ì €ì¥

# âœ… RAG ê¸°ë°˜ ì»¬ëŸ¼ ì„¤ëª… ì¶”ê°€
def load_vectorstore():
    if os.path.exists("./vectordb"):
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large",
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        try:
            return FAISS.load_local("./vectordb", embeddings, allow_dangerous_deserialization=True)
        except Exception as e:
            print(f"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    return None

vectorstore = load_vectorstore()

def search_column_descriptions(col_desc_df, vectorstore):
    """RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¬ëŸ¼ ì„¤ëª…ì„ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜"""
    data = []
    df_after_llm = col_desc_df[['ë°ì´í„°í”„ë ˆì„ëª…', 'ì»¬ëŸ¼ëª…']]
    
    for i, row in df_after_llm.iterrows():
        table_name = row['ë°ì´í„°í”„ë ˆì„ëª…']
        col = row['ì»¬ëŸ¼ëª…']
        
        search_query = f"í…Œì´ë¸”ëª… : {table_name} | ì»¬ëŸ¼ëª… : {col}"
        docs = vectorstore.similarity_search(search_query, k=1)
        
        if docs:
            best_match = docs[0].page_content
            data.append({
                'ë°ì´í„°í”„ë ˆì„ëª…': table_name,
                'ì»¬ëŸ¼ëª…': col,
                'ì»¬ëŸ¼ì„¤ëª…': best_match.split('\n')[3].split('ì„¤ëª…')[1].strip()
            })
        else:
            data.append({
                'ë°ì´í„°í”„ë ˆì„ëª…': table_name,
                'ì»¬ëŸ¼ëª…': col,
                'ì»¬ëŸ¼ì„¤ëª…': "ì„¤ëª… ì—†ìŒ"
            })
    
    return pd.DataFrame(data)

# âœ… Stage 2: RAG ê¸°ë°˜ ì»¬ëŸ¼ ì„¤ëª… ì¶”ê°€
stage1_df = stage1_results["ë°ì´í„° ê°œìš”"]
rag_results = search_column_descriptions(stage1_df, vectorstore)

# âœ… Stage 1 ê²°ê³¼ì™€ RAG ê²°ê³¼ë¥¼ í†µí•©
final_df = pd.merge(
    stage1_df,     # Stage 1 ê²°ê³¼ (ë°ì´í„° êµ¬ì¡° ì •ë³´)
    rag_results,   # RAG ê²€ìƒ‰ ê²°ê³¼ (ì»¬ëŸ¼ ì„¤ëª…)
    on=['ë°ì´í„°í”„ë ˆì„ëª…', 'ì»¬ëŸ¼ëª…'],
    how='left'
)

# âœ… ìµœì¢… ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ ë‚´ ì €ì¥
results["stage2"] = final_df

print("âœ… ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
