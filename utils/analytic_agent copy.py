##########################################################################################
# Program Description
##########################################################################################
##########################################################################################
# ë¼ì´ë¸ŒëŸ¬ë¦¬
##########################################################################################
# Built-in Packages
import os, sys
import io
import pickle
import pandas as pd
import numpy as np
import traceback
import ast
import pkg_resources
from datetime import datetime
import threading
import time

# Thire Party Packages
from typing import TypedDict, List, Literal, Annotated, Dict, Union
from pydantic import BaseModel, Field
import tiktoken
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, END, START
from langchain_core.messages import HumanMessage, BaseMessage
from langchain_openai import ChatOpenAI
from langgraph.types import Command
from fuzzywuzzy import process

# User Defined Packages
from prompt.prompts import *
from utils.vector_handler import load_vectorstore

##########################################################################################
# ìƒìˆ˜ ë° ë³€ìˆ˜ ì„ ì–¸ë¶€
##########################################################################################
# âœ… í•œê¸€ í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
matplotlib.rcParams['font.family'] = 'Malgun Gothic'
matplotlib.rcParams['axes.unicode_minus'] = False

VECTOR_DB_BASE_PATH = "./vectordb/analysis"
PROCESSED_DATA_PATH = "../output/stage1/processed_data_info.xlsx"
MAX_RETRIES = 3
TOKEN_LIMIT = 10000 # âœ… í† í° ì œí•œ ì„¤ì • (ì˜ˆ: 5000 í† í° ì´ˆê³¼ ì‹œ ì°¨ë‹¨)
RECURSION_LIMIT = 100

##########################################################################################
# êµ¬í˜„ ì½”ë“œ
##########################################################################################
# âœ… AI ë¶„ì„ ì—ì´ì „íŠ¸ ìƒíƒœ ì •ì˜(stateì— ì ìž¬ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë™)
class State(TypedDict):
    messages: List[BaseMessage]  # ðŸ”¹ ì‚¬ìš©ìžì™€ AI ê°„ì˜ ëª¨ë“  ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡ (HumanMessage, AIMessage ë“±)
    mart_info: str  # ðŸ”¹ í˜„ìž¬ í™œì„±í™”ëœ ë°ì´í„°í”„ë ˆìž„ (ë¶„ì„ ëŒ€ìƒ)
    generated_code: str  # ðŸ”¹ ì´ˆê¸° ìƒì„±ëœ ì½”ë“œ
    q_category: str  # ðŸ”¹ Supervisorê°€ íŒë‹¨í•œ ì§ˆë¬¸ ìœ í˜• (Analytics, General, Knowledge)
    content: str  # ðŸ”¹ ì¼ë°˜/ì§€ì‹ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ
    retry_count: int  # ðŸ”¹ ì½”ë“œ ìž¬ìƒì„± ì‹¤íŒ¨ ì‹œ ìž¬ì‹œë„ íšŸìˆ˜ (ìµœëŒ€ 3íšŒ)
    regenerated_code: str  # ðŸ”¹ ìž¬ìƒì„±ëœ ì½”ë“œ
    validated_code: str  # ì „ì²´ ì‹¤í–‰ê¹Œì§€ í†µê³¼í•œ ì½”ë“œ
    analytic_result: Dict  # ðŸ”¹ ì „ì²´ ë°ì´í„°ë¥¼ ì‹¤í–‰í•˜ì—¬ ì–»ì€ ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    error_message: dict  # ðŸ”¹ ì½”ë“œ ì‹¤í–‰ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ ë©”ì‹œì§€ (ìžˆë‹¤ë©´ ìž¬ì‹œë„í•  ë•Œ í™œìš©)
    data_id: str  # ðŸ”¹ ë¶„ì„ ê²°ê³¼ë¥¼ ì €ìž¥í•  ë•Œ ë¶€ì—¬ë˜ëŠ” ê³ ìœ  ID (íŒŒì¼ ì €ìž¥ ì‹œ í™œìš©)
    insights: str  # ðŸ”¹ LLMì´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±í•œ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
    report: str  # ðŸ”¹ ìƒì„±ëœ ë¦¬í¬íŠ¸
    chart_needed: bool  # ðŸ”¹ ì°¨íŠ¸ê°€ í•„ìš”í•œì§€ ì—¬ë¶€ (True: í•„ìš”í•¨, False: ë¶ˆí•„ìš”)
    chart_filename: str  # ðŸ”¹ ìƒì„±ëœ ì°¨íŠ¸ì˜ íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ None)
    chart_error: int  # ðŸ”¹ ì°¨íŠ¸ ì—ëŸ¬ ë©”ì‹œì§€
    from_full_execution: bool  # ðŸ”¹ ì½”ë“œ ìž¬ìƒì„± ì‹œ ì´ˆê¸° ì‹¤í–‰ ì—¬ë¶€
    from_token_limit: bool  # ðŸ”¹ í† í° ì œí•œ ì´ˆê³¼ ì‹œ ì´ˆê¸° ì‹¤í–‰ ì—¬ë¶€
    request_summary: str  # ðŸ”¹ ë¶„ì„ ìš”ì²­ì„ í•œê¸€ë¡œ ìš”ì•½í•œ ë‚´ìš©
    installed_packages: Dict[str, str]  # ðŸ”¹ íŒ¨í‚¤ì§€ ì´ë¦„ ë° ë²„ì „ ì €ìž¥
    feedback: str  # ðŸ”¹ í”¼ë“œë°± ë‚´ìš©
    feedback_point: list  # ðŸ”¹ í”¼ë“œë°± í¬ì¸íŠ¸
    start_from_analytics: bool  # ðŸ”¹ ë¶„ì„ ì‹œìž‘ ì—¬ë¶€

class Feedback(BaseModel):
    feedback_point: list[str]  # ë¦¬ìŠ¤íŠ¸ í•­ëª©ì˜ íƒ€ìž…ì„ ëª…ì‹œì ìœ¼ë¡œ strë¡œ ì§€ì •

# í”¼ë“œë°± í•„ìš” ì—¬ë¶€ë¥¼ ìœ„í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ëª¨ë¸
class YesNo(BaseModel):
    decision: Literal["yes", "no"] = Field(description="ì—¬ë¶€ (yes ë˜ëŠ” no)")

# ì§ˆë¬¸ ë¶„ë¥˜ ë¼ìš°í„°
class Question_Classifier(BaseModel):
    next: Literal["Analytics", "General", "Knowledge"]

class DataAnayticsAssistant:
    """Python DataFrame ê¸°ë°˜ AI ë¶„ì„ ì—ì´ì „íŠ¸ (LangGraph ê¸°ë°˜)"""
    ###############################################################################################
    # âœ… ì´ˆê¸°í™”
    ###############################################################################################
    def __init__(self, openai_api_key: str):
        print("="*100)
        print("ðŸ”¹ ë¶„ì„ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”")
        print("="*100)
        self.llm = ChatOpenAI(model="gpt-4o", openai_api_key=openai_api_key, temperature=0.0)
        self.active_marts = None
        self.mart_info = None
        self.retry_count = 0

        # ì§ˆì˜ ê´€ë ¨ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.original_query = None  # ì›ë³¸ ì‚¬ìš©ìž ì§ˆì˜
        self.context = None  # ì´ì „ ëŒ€í™” ê¸°ë¡ ë° ë¬¸ë§¥ ì •ë³´
        self.context_query = None  # ë¬¸ë§¥ì´ í¬í•¨ëœ ìµœì¢… ì§ˆì˜
        
        # ë§ˆíŠ¸ ì •ë³´ ì´ˆê¸° ë¡œë“œ
        try:
            self.mart_info_df = pd.read_excel(PROCESSED_DATA_PATH, sheet_name=None)
            print(f"ðŸ”¹ í˜„ìž¬ ì ‘ê·¼ ê°€ëŠ¥ ë§ˆíŠ¸ ëª©ë¡: {list(self.mart_info_df.keys())}")
        except Exception as e:
            print(f"âš ï¸ ë§ˆíŠ¸ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.mart_info_df = {}
            
        self.build_graph()

    ###############################################################################################
    # âœ… ê·¸ëž˜í”„ êµ¬ì„±
    ###############################################################################################
    def build_graph(self):
        """LangGraphë¥¼ í™œìš©í•˜ì—¬ ë¶„ì„ íë¦„ êµ¬ì„±"""
        workflow = StateGraph(State)

        # ë…¸ë“œ ì„ ì–¸
        workflow.add_node("Context", self.handle_context)
        workflow.add_node("Supervisor", self.supervisor)
        workflow.add_node("Analytics", self.handle_analytics)
        workflow.add_node("General", self.handle_general)
        workflow.add_node("Knowledge", self.handle_knowledge)
        workflow.add_node("Generate_Code", self.generate_python_code)
        workflow.add_node("Execute_Sample", self.execute_sample_code)
        workflow.add_node("Regenerate_Code", self.regenerate_code)
        workflow.add_node("Execute_Full", self.execute_full_data)
        workflow.add_node("Save_Data", self.save_data)
        workflow.add_node("Insight_Builder", self.generate_insights)
        workflow.add_node("Chart_Builder", self.generate_chart)
        workflow.add_node("Regenerate_Chart", self.regenerate_chart)
        workflow.add_node("Report_Builder", self.generate_report)
        workflow.add_node("After_Feedback", self.after_feedback)

        # ê¸°ë³¸ íë¦„ ì •ì˜
        workflow.add_edge(START, "Context")
        workflow.add_edge("Context", "Supervisor")
        workflow.add_conditional_edges(
            "Supervisor",
            lambda state: state["q_category"],  # Supervisorê°€ ê²°ì •í•œ ê²½ë¡œë¡œ ì´ë™
            {
                "Analytics": "Analytics",
                "General": "General",
                "Knowledge": "Knowledge",
            }
        )
        
        workflow.add_edge("Analytics", "Generate_Code")
        workflow.add_conditional_edges(
            "Generate_Code",
            self.route_after_generate_code,
            {
                "Execute_Sample": "Execute_Sample",
                END: END
            }
        )
        workflow.add_conditional_edges( # âœ… ìƒ˜í”Œ ì‹¤í–‰ í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •
            "Execute_Sample",
            self.route_after_sample,
            {
                "Execute_Full": "Execute_Full",
                "Regenerate_Code": "Regenerate_Code",
                END : END
            }
        )
        workflow.add_conditional_edges( # âœ… ì½”ë“œ ìž¬ìƒì„± íë¦„
            "Regenerate_Code",
            self.route_after_regenerate,  # ìƒˆë¡œìš´ ë¼ìš°í„° í•¨ìˆ˜ ì‚¬ìš©
            {
                "Execute_Sample": "Execute_Sample",
                "Execute_Full": "Execute_Full",
                END: END  # âœ… 3íšŒ ì´ìƒì´ë©´ ì¢…ë£Œ
            }
        )
        workflow.add_conditional_edges( # âœ… ì „ì²´ ë°ì´í„° ì‹¤í–‰ í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •
            "Execute_Full",
            self.route_after_full_execution,
            {
                "Save_Data": "Save_Data",
                "Regenerate_Code": "Regenerate_Code",
                END : END
            }
        )
        workflow.add_edge("Save_Data", "Insight_Builder")
        workflow.add_conditional_edges( # âœ… ì¸ì‚¬ì´íŠ¸ ìƒì„± í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •
            "Insight_Builder",
            self.route_after_insights,
            {
                "Chart_Builder": "Chart_Builder",
                "Report_Builder": "Report_Builder"
            }
        )
        workflow.add_conditional_edges( # âœ… ì°¨íŠ¸ ìƒì„± í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •
            "Chart_Builder",
            self.route_after_chart,
            {
                "Regenerate_Chart": "Regenerate_Chart",  # ì‹¤íŒ¨ ì‹œ ìž¬ìƒì„±
                "Report_Builder": "Report_Builder",  # ì„±ê³µ ë˜ëŠ” ìµœëŒ€ ìž¬ì‹œë„ ì´ˆê³¼
            }
        )
        workflow.add_conditional_edges( # âœ… ì°¨íŠ¸ ìž¬ìƒì„± í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •
            "Regenerate_Chart",
            self.route_after_chart,
            {
                "Regenerate_Chart": "Regenerate_Chart",  # ì—¬ì „ížˆ ì‹¤íŒ¨ ì‹œ ë‹¤ì‹œ ìž¬ìƒì„±
                "Report_Builder": "Report_Builder",  # ì„±ê³µ ë˜ëŠ” ìµœëŒ€ ìž¬ì‹œë„ ì´ˆê³¼
            }
        )
        workflow.add_conditional_edges(
            "Report_Builder",
            self.route_after_report,  # ìƒˆë¡œìš´ ë¼ìš°í„° í•¨ìˆ˜ ì¶”ê°€
            {
                "After_Feedback": "After_Feedback",
                END: END
            }
        )
        workflow.add_edge("After_Feedback", END)
        self.graph = workflow.compile()
        print("âœ… ê·¸ëž˜í”„ ì»´íŒŒì¼ ì™„ë£Œ")        
        
    ###############################################################################################
    # âœ… ì‹¤í–‰
    ###############################################################################################
    def ask(self, query: str, context: list, start_from_analytics=False, feedback_point=None):
        """LangGraph ì‹¤í–‰"""

        # ì»¨í…ìŠ¤íŠ¸ ì €ìž¥
        self.context = context
        # print(f"ðŸ” ì»¨í…ìŠ¤íŠ¸:\n{self.context}")

        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "messages": [HumanMessage(content=query)],  # ì›ë³¸ ì¿¼ë¦¬ë§Œ ì „ë‹¬
        }

        # ê°œì„  ìš”ì²­ì¼ ê²½ìš°
        if start_from_analytics:

            # ê°œì„  ìš”ì²­ ì‚¬í•­ì„ ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ì„¤ì •
            self.original_query = feedback_point

            # ì´ˆê¸° ìƒíƒœì— ì§ˆë¬¸ ë¶„ë¥˜ë¥¼ 'Analytics'ë¡œ ì„¤ì • ë° í”Œëž˜ê·¸ ì¶”ê°€
            initial_state.update({
                "q_category": "Analytics",
                "start_from_analytics": True 
            })

            # ë¬¸ë§¥ì´ ë‹´ê¸´ ì§ˆì˜ ìƒì„±
            self.context_query = f"""
# ê°œì„  ìš”ì²­ ì‚¬í•­
{self.original_query}

{self.context}
        """
        # ì¼ë°˜ ì§ˆë¬¸ì¼ ê²½ìš°
        else:
            self.original_query = query
        
        # ê·¸ëž˜í”„ ì‹¤í–‰
        result = self.graph.invoke(initial_state, config={"recursion_limit": RECURSION_LIMIT})
        
        return result

    ###############################################################################################
    # âœ… ë…¸ë“œ êµ¬í˜„
    ###############################################################################################
    #########################################################
    # âœ… Context Windows ë…¸ë“œ
    # -> Context_Filter
    #########################################################
    def handle_context(self, state: State) -> Command:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ê³ , í˜„ìž¬ ì§ˆë¬¸ì„ ìµœìš°ì„ ìœ¼ë¡œ ê°•ì¡°í•˜ëŠ” ê°œì„ ëœ ë…¸ë“œ"""
        print("ðŸ—ƒï¸ ì»¨í…ìŠ¤íŠ¸ í•„í„°ë§ ë‹¨ê³„")

        # Analyticsë¶€í„° ì‹œìž‘í•˜ëŠ” ê²½ìš° Supervisorë¡œ ë°”ë¡œ ì´ë™(ê°œì„  ìš”ì²­)
        if state.get("start_from_analytics", False):
            print("ðŸ—ƒï¸ [handle_context] ê°œì„  ìš”ì²­ ì²˜ë¦¬ì´ë¯€ë¡œ ë°”ë¡œ Supervisorë¡œ ì´ë™")
            return Command(goto="Supervisor")
        
        # ê¸°ì¡´ ëŒ€í™” ì´ë ¥ì´ ì—†ëŠ” ê²½ìš° ì›ë³¸ ì§ˆì˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if not self.context:
            print("ðŸ—ƒï¸ [handle_context] ì´ì „ ëŒ€í™” ê¸°ë¡ ì—†ìŒ -> Supervisorë¡œ ì´ë™")
            self.context_query = self.original_query  # ë¬¸ë§¥ì´ ì—†ìœ¼ë©´ ì›ë³¸ ì§ˆì˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            return Command(goto="Supervisor")
        # ê¸°ì¡´ ëŒ€í™” ì´ë ¥ì´ ìžˆëŠ” ê²½ìš° ì»¨í…ìŠ¤íŠ¸ í•„í„°ë§
        else:
            prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_CONTEXT_FILTER),
                ("user", "##### í˜„ìž¬ ì§ˆë¬¸\n{user_request}"),
                ("user", "##### ìµœê·¼ ëŒ€í™” ê¸°ë¡\n{context}"),
                ("user", "##### ì •ë¦¬ëœ ë¬¸ë§¥"),
            ])

            chain = prompt | self.llm
            context_str = "\n".join([f"\nì‚¬ìš©ìž: {chat['query']}\nì–´ì‹œìŠ¤í„´íŠ¸: {chat['response']}" for chat in self.context])
            
            # ì»¨í…ìŠ¤íŠ¸ í•„í„°ë§
            filtered_context = chain.invoke({
                "user_request": self.original_query,
                "context": context_str
            }).content.strip()

            print(f"ðŸ—ƒï¸ [handle_context] í•„í„°ë§ í›„ ëŒ€í™” ê¸°ë¡ :\n{filtered_context}")
            
            # ðŸ”¹ ìµœì¢… Context êµ¬ì„± (í˜„ìž¬ ì§ˆë¬¸ì„ ìµœìƒë‹¨ìœ¼ë¡œ)
            self.context_query = f"""
# ðŸ¤” í˜„ìž¬ ì§ˆë¬¸ (ìµœìš°ì„ )
{self.original_query}

{filtered_context}
            """
            return Command(goto="Supervisor")

    #########################################################
    # âœ… Supervisor ë…¸ë“œ
    # -> General / Knowledge / Analytics 
    #########################################################
    def supervisor(self, state: State) -> Command:
        """ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” Supervisor"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ðŸ‘¨â€ðŸ’¼ Supervisor ë‹¨ê³„:")

        # Request Summary ìƒì„±
        prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_REQUEST_SUMMARY),
            ("user", "{user_request}")
        ])
        
        chain = prompt | self.llm
        request_summary = chain.invoke({
            "user_request": self.original_query # request summaryëŠ” ì›ë³¸ ì§ˆì˜ë¡œ ìƒì„±
        }).content.strip()
        
        print(f"ðŸ‘¨â€ðŸ’¼ ìš”ì•½ëœ ì§ˆì˜ ë‚´ìš©: {request_summary}")
        
        # ë¬¸ë§¥ì´ í¬í•¨ëœ ìµœì¢… ì§ˆì˜ ì‚¬ìš©
        user_request = self.context_query
        
        # Analyticsë¶€í„° ì‹œìž‘í•˜ëŠ” ê²½ìš° ë°”ë¡œ Analyticsë¡œ ì´ë™
        if state.get("start_from_analytics", False):
            print("ðŸ‘¨â€ðŸ’¼ ê°œì„  ìš”ì²­ -> Analytics ë‹¨ê³„ë¡œ ë°”ë¡œ ì´ë™")
            return Command(
                update={
                    "q_category": 'Analytics', 
                    "request_summary": request_summary,
                }, 
                goto="Analytics"
            )

        # ì§ˆë¬¸ ìœ í˜• ê²°ì •
        prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_SUPERVISOR),
                ("user", " user_request:\n{user_request}\n\n")
        ])
        chain = prompt | self.llm.with_structured_output(Question_Classifier)
        response = chain.invoke({"user_request": user_request})
        print(f"ðŸ‘¨â€ðŸ’¼ ë‹¤ìŒ ë‹¨ê³„(Analytics or General or Knowledge): {response.next}")
        return Command(
            update={
                "q_category": response.next, 
                "request_summary": request_summary,
            }, 
            goto=response.next
        )
    
    #########################################################
    # âœ… General ë…¸ë“œ
    #########################################################
    def handle_general(self, state: State) -> Command:
        """ì¼ë°˜ì ì¸ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ"""
        print("\nðŸ’¬ [handle_general] ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬")
        user_request = self.original_query
        prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_GENERAL),
                ("user", " user_request:\n{user_request}\n\n")
        ])
        chain = prompt | self.llm
        response = chain.invoke({"user_request": user_request})
        print(f"ðŸ’¬ ì¼ë°˜ ì‘ë‹µ: {response.content}")
        return Command(update={"content": response.content}, goto=END)

    #########################################################
    # âœ… Knowledge ë…¸ë“œ
    #########################################################
    def handle_knowledge(self, state: State) -> Command:
        """ì§€ì‹ ê¸°ë°˜ ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ"""
        print("\nðŸ“š [handle_knowledge] ì§€ì‹ ê¸°ë°˜ ì§ˆë¬¸ ì²˜ë¦¬")
        
        user_request = self.context_query or self.original_query

        # ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ(ë¯¸ë¦¬ ë¬¸ë§¥ ë“±ë¡ì´ í•„ìš”)
        vectorstore = load_vectorstore('./vectordb/analysis')
        if vectorstore is None:
            print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì‹¤íŒ¨: FAISS ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLMìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤.")
            # ì¼ë°˜ LLM ì‘ë‹µ ìƒì„±
            prompt = ChatPromptTemplate.from_messages([
                    ("system", PROMPT_GENERAL),
                    ("user", "{user_question}")
            ])
            chain = prompt | self.llm
            response = chain.invoke({"user_question": user_request})
            return Command(update={"content": response.content}, goto=END)

        # Retriever ìƒì„±
        retriever = vectorstore.as_retriever()

        # ì‚¬ìš©ìž ì§ˆë¬¸ ê²€ìƒ‰
        retrieved_docs = retriever.get_relevant_documents(user_request)

        if not retrieved_docs:
            response = "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            # ê²€ìƒ‰ëœ ë¬¸ì„œ ìƒìœ„ 3ê°œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©
            context = "\n".join([doc.page_content for doc in retrieved_docs[:3]])
            prompt = ChatPromptTemplate.from_messages([
                    ("system", PROMPT_KNOWLEDGE),
                    ("user", "\nì§ˆë¬¸:\n{user_question}"),
                    ("user", "\ndocument:\n{context}")
            ])
            chain = prompt | self.llm
            response = chain.invoke({"user_question": user_request, "context": context})
        print(f"ðŸ“– ì§€ì‹ ê¸°ë°˜ ì‘ë‹µ: {response.content}")
        return Command(update={"content": response.content}, goto=END)
    
    #########################################################
    # âœ… Analytics ë…¸ë“œ
    # -> Generate_Code
    #########################################################
    def handle_analytics(self, state: State) -> Command:
        """ë¶„ì„ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ"""
        print("ðŸ‘¨â€ðŸ’¼ [handle_analytics] ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì‹œìž‘")
        return Command(goto="Generate_Code")

    #########################################################
    # âœ… Generate_Code ë…¸ë“œ
    # -> Execute_Sample / END
    #########################################################
    def generate_python_code(self, state)-> Command:
        """
        ì‚¬ìš©ìžì˜ ìš”ì²­ì„ ê¸°ë°˜ìœ¼ë¡œ Python ì½”ë“œ ìƒì„±
        IF í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŒ -> END ë…¸ë“œë¡œ ì´ë™
        ELSE ë°ì´í„°í”„ë ˆìž„ ì •ë³´ ìƒì„± ë° ì½”ë“œ ìƒì„± -> Execute_Sample ë…¸ë“œë¡œ ì´ë™
        """
        print("="*100)
        print("ðŸ¤– ì½”ë“œ ìƒì„± ë‹¨ê³„:")
        
        # í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ìžˆëŠ”ì§€ í™•ì¸
        if not self.active_marts:
            print("âŒ í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë§ˆíŠ¸ë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”.")
            return Command(
                update={
                    "error_message": self._normalize_error_message("âŒ í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë§ˆíŠ¸ë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”.")
                }, 
                goto=END
            )
        
        user_request = self.context_query
        
        # ë§ˆíŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì¤‘ê´„í˜¸ ì´ìŠ¤ì¼€ì´í”„ ì ìš©)
        mart_info = self._get_mart_info()

        # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt_text = PROMPT_GENERATE_CODE.format(mart_info=mart_info)
        prompt = ChatPromptTemplate.from_messages([
            ("system", prompt_text),
            ("user", "\nuser_request:\n{user_request}")
        ])
        chain = prompt | self.llm
        response = chain.invoke({
            "user_request": user_request,
        })
            
        print(f"ðŸ¤– ìƒì„±ëœ ì½”ë“œ:\n{response.content}\n")
        return Command(update={
            "generated_code": response.content,
            "regenerated_code": None,  # ì´ˆê¸°í™”
            "validated_code": None     # ì´ˆê¸°í™”
        }, goto="Execute_Sample")
    
    #########################################################
    # âœ… Execute_Sample ë…¸ë“œ
    # -> Execute_Full / Regenerate_Code / END
    #########################################################
    def execute_sample_code(self, state):
        """ìƒ˜í”Œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ Python ì½”ë“œ ì‹¤í–‰"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ðŸ§ª ìƒ˜í”Œ ì‹¤í–‰ ë‹¨ê³„")
        
        # ê° ë§ˆíŠ¸ë³„ë¡œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_marts = {}
        for mart_name, df in self.active_marts.items():
            sample_size = min(50, len(df))
            sample_marts[mart_name] = df.sample(n=sample_size)
            print(f"ðŸ§ª {mart_name}: {sample_size}ê°œ ìƒ˜í”Œ ì¶”ì¶œ")
    
        # print(f"ðŸ§ª ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ ì§ì „ ê¸€ë¡œë²Œ í‚¤ í™•ì¸(ì ‘ê·¼ ê°€ëŠ¥ ë°ì´í„°í”„ë ˆìž„) \n {globals().keys()} ")
        
        # ìž¬ìƒì„±ëœ ì½”ë“œê°€ ìžˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ì´ˆê¸° ìƒì„± ì½”ë“œ ì‚¬ìš©
        code_to_execute = self._extract_code_from_llm_response(
            state.get("regenerated_code") or state["generated_code"]
        )
            
        # âœ… ì‚¬ìš©ëœ íŒ¨í‚¤ì§€ ìžë™ ì¶”ì¶œ
        used_packages = self._extract_imported_packages(code_to_execute)
        installed_versions = self._get_installed_versions(used_packages)

        print(f"ðŸ§ª ì‚¬ìš©ëœ íŒ¨í‚¤ì§€ ëª©ë¡: {used_packages} | íŒ¨í‚¤ì§€ ë²„ì „ ì •ë³´: {installed_versions}")
        try:
            # ì‹¤í–‰ í™˜ê²½ì— ìƒ˜í”Œ ë°ì´í„°í”„ë ˆìž„ ì¶”ê°€
            exec_globals = {}

            # ëª¨ë“  ë°ì´í„°í”„ë ˆìž„ì„ exec_globalsì— ì¶”ê°€
            exec_globals.update(sample_marts)

            print(f"ðŸ”¹ ì‹¤í–‰ í™˜ê²½ì— ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆìž„ ëª©ë¡: {list(exec_globals.keys())}")

            # ì¶”ì¶œëœ ì½”ë“œ ì‹¤í–‰
            self._execute_code_with_capture(code_to_execute, exec_globals, is_sample=True)
            
            print(f"âœ… ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ ì„±ê³µ")
            self.retry_count = 0  # ì„±ê³µ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={
                "error_message": None,
                "installed_packages": installed_versions
            }, goto="Execute_Full")

        except Exception as e:
            print(f"âŒ ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨")
            print(traceback.format_exc())
            error_details = {
                "error_type": type(e).__name__,
                "error_msg": str(e),
                "traceback": traceback.format_exc(),
                "installed_packages": installed_versions
            }
            self.retry_count += 1
            if self.retry_count >= MAX_RETRIES:
                print("âš ï¸ ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ 3íšŒ ì‹¤íŒ¨ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
                return Command(update={
                    "error_message": self._normalize_error_message(error_details), 
                    "installed_packages": installed_versions
                }, goto=END)
            return Command(update={
                "error_message": self._normalize_error_message(error_details), 
                "installed_packages": installed_versions
            }, goto="Regenerate_Code")

    #########################################################
    # âœ… Regenerate_Code ë…¸ë“œ
    # -> Execute_Full / Execute_Sample / END
    #########################################################
    def regenerate_code(self, state):
        """ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ ì‹œ LLMì„ í™œìš©í•˜ì—¬ ì½”ë“œ ìž¬ìƒì„±"""
        from_full_execution = state.get("from_full_execution", False)  # í”Œëž˜ê·¸ í™•ì¸

        if self.retry_count >= MAX_RETRIES:  # âœ… 3íšŒ ì´ˆê³¼ ì‹œ ì¢…ë£Œ
            return Command(goto=END)
        
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("âš’ï¸ ì½”ë“œ ìž¬ìƒì„± ë‹¨ê³„")
        user_request = self.context_query or self.original_query
        error_message = state["error_message"]
        original_code = state["generated_code"]
        installed_packages = state.get("installed_packages", {})  # ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°

        # í† í° ì´ˆê³¼ ì‹œ ì½”ë“œ ìž¬ìƒì„±
        if state.get("from_token_limit", False):
            print(f"âš’ï¸ í† í° ì´ˆê³¼ ì‹œì˜ ì½”ë“œ ìž¬ìƒì„± ì§„í–‰")
            prompt = ChatPromptTemplate.from_messages([
                    ("system", PROMPT_REGENERATE_CODE_WHEN_TOKEN_OVER),
                    ("user", "\nuser_request:\n{user_request}"),
            ])
        # ì¼ë°˜ ì½”ë“œ ìž¬ìƒì„±
        else:
            prompt = ChatPromptTemplate.from_messages([
                        ("system", PROMPT_REGENERATE_CODE),
                        ("user", "\nuser_request:\n{user_request}"),
                        ("user", "\noriginal_code:\n{original_code}"),
                        ("user", "\nerror_message:\n{error_message}"),
                        ("user", "\ninstalled_packages:\n{installed_packages}")
                ])
        
        chain = prompt | self.llm
        
        # ì½”ë“œ ìž¬ìƒì„±
        response = chain.invoke({
            "user_request": user_request,
            "original_code": original_code,
            "error_message": error_message,       
            "installed_packages": installed_packages  # íŒ¨í‚¤ì§€ ì •ë³´ ì „ë‹¬
        })
        print(f"âš’ï¸ ìž¬ìƒì„±ëœ ì½”ë“œ:\n{response.content}\n")
        next_step = "Execute_Full" if from_full_execution else "Execute_Sample"
        
        return Command(update={
            "regenerated_code": response.content,  # ìž¬ìƒì„±ëœ ì½”ë“œ ì €ìž¥
            "validated_code": None,  # validated_code ì´ˆê¸°í™”
            "from_full_execution": from_full_execution
        }, goto=next_step)

    #########################################################
    # âœ… Execute_Full ë…¸ë“œ
    # -> Save_Data / Regenerate_Code 
    #########################################################
    def execute_full_data(self, state):
        """ì „ì²´ ë°ì´í„°ë¡œ Python ì½”ë“œ ì‹¤í–‰ (300ì´ˆ ì œí•œ)"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ðŸ”„ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ë‹¨ê³„ (ìµœëŒ€ 300ì´ˆ ì œí•œ)")

        # ì „ì²´ ë°ì´í„°í”„ë ˆìž„ ì„¤ì •
        full_marts = self.active_marts  # ì „ì²´ ë°ì´í„°í”„ë ˆìž„ ì‚¬ìš©

        # ì‹¤í–‰ í™˜ê²½ì— ì „ì²´ ë°ì´í„°í”„ë ˆìž„ ì¶”ê°€
        exec_globals = {}

        # ëª¨ë“  ë°ì´í„°í”„ë ˆìž„ì„ exec_globalsì— ì¶”ê°€
        exec_globals.update(full_marts)

        print(f"ðŸ”„ ì „ì²´ ë°ì´í„° ì‹¤í–‰ í™˜ê²½ì— ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆìž„ ëª©ë¡: {list(exec_globals.keys())}")

        # LLM ìƒì„± ì½”ë“œì—ì„œ ```python ë¸”ë¡ ì œê±°
        code_to_execute = self._extract_code_from_llm_response(
            state.get("regenerated_code") or state["generated_code"]
        )
        # âœ… ì‚¬ìš©ëœ íŒ¨í‚¤ì§€ ìžë™ ì¶”ì¶œ
        used_packages = self._extract_imported_packages(code_to_execute)
        installed_versions = self._get_installed_versions(used_packages)

        print(f"ðŸ”„ ì‚¬ìš©ëœ íŒ¨í‚¤ì§€ ëª©ë¡: {used_packages} | íŒ¨í‚¤ì§€ ë²„ì „ ì •ë³´: {installed_versions}")

        try:
            # íƒ€ìž„ì•„ì›ƒ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëž˜í¼ í•¨ìˆ˜ (ìŠ¤ë ˆë“œ ê¸°ë°˜ íƒ€ìž„ì•„ì›ƒ êµ¬í˜„)
            def execute_with_timeout(code, globals_dict, timeout=50):
                
                result = {"output": None, "analytic_result": None, "error": None, "timeout": False}
                
                def target():
                    try:
                        output, analytic_result = self._execute_code_with_capture(code, globals_dict, is_sample=False)
                        result["output"] = output
                        result["analytic_result"] = analytic_result
                    except Exception as e:
                        result["error"] = e
                
                thread = threading.Thread(target=target)
                thread.daemon = True
                thread.start()
                thread.join(timeout)
                
                if thread.is_alive():
                    # íƒ€ìž„ì•„ì›ƒ ë°œìƒ
                    result["timeout"] = True
                    print(f"âš ï¸ ì‹¤í–‰ ì‹œê°„ì´ {timeout}ì´ˆë¥¼ ì´ˆê³¼í•˜ì—¬ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    # ìŠ¤ë ˆë“œëŠ” daemon=Trueë¡œ ì„¤ì •ë˜ì–´ ìžˆì–´ ë©”ì¸ ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë˜ë©´ ìžë™ìœ¼ë¡œ ì¢…ë£Œë¨
                
                return result
            
            # ì½”ë“œ ì‹¤í–‰ (íƒ€ìž„ì•„ì›ƒ 300ì´ˆ)
            execution_result = execute_with_timeout(code_to_execute, exec_globals, timeout=50)
            
            # íƒ€ìž„ì•„ì›ƒ ë°œìƒ
            if execution_result["timeout"]:
                return Command(update={
                    "analytic_result": None,  # ê²°ê³¼ ë¯¸ì €ìž¥
                    "validated_code": state.get("regenerated_code") or state["generated_code"],  # ì‹¤í–‰ëœ ì½”ë“œ ìœ ì§€
                    "error_message": self._normalize_error_message("âš ï¸ ì‹¤í–‰ ì‹œê°„ì´ 300ì´ˆë¥¼ ì´ˆê³¼í•˜ì—¬ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."),
                    "from_full_execution": True,  # ì „ì²´ ì‹¤í–‰ í”Œëž˜ê·¸ ì¶”ê°€
                    "installed_packages": installed_versions
                }, goto="Save_Data")  # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
            
            # ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ
            if execution_result["error"]:
                e = execution_result["error"]
                print(f"âŒ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì‹¤íŒ¨\n {code_to_execute}")
                print(f"ì—ëŸ¬ íƒ€ìž…: {type(e).__name__}")
                print(f"ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
                print(f"ì—ëŸ¬ ë°œìƒ ìœ„ì¹˜:")
                print(traceback.format_exc())
                error_details = {
                    "error_type": type(e).__name__,
                    "error_msg": str(e),
                    "traceback": traceback.format_exc(),
                    "installed_packages": installed_versions
                }
                self.retry_count += 1
                return Command(update={
                    "error_message": self._normalize_error_message(error_details),
                    "from_full_execution": True,  # í”Œëž˜ê·¸ ì¶”ê°€
                    "installed_packages": installed_versions
                }, goto="Regenerate_Code")
            
            # ì •ìƒ ì‹¤í–‰ ì™„ë£Œ
            output = execution_result["output"]
            analytic_result = execution_result["analytic_result"]
            
            token_count = self._calculate_tokens(str(analytic_result))
            
            print(f"ðŸ”„ ê²°ê³¼ ë°ì´í„° í† í° ìˆ˜: {token_count}")
            
            if token_count > TOKEN_LIMIT:
                print(f"âš ï¸ í† í° ìˆ˜ ì´ˆê³¼: {token_count} > {TOKEN_LIMIT}")
                self.retry_count += 1
                return Command(update={
                    "error_message": self._normalize_error_message(f"ê²°ê³¼ ë°ì´í„° analytic_resultì˜ ì ì • í† í° ìˆ˜ë¥¼ ì´ˆê³¼í•˜ì˜€ìŠµë‹ˆë‹¤. analytic_resultì— Raw ë°ì´í„° í˜¹ì€ ë¶ˆí•„ìš”í•œ ë°˜ë³µ ì ìž¬ë¥¼ í”¼í•´ì£¼ì„¸ìš”: {token_count} > {TOKEN_LIMIT}"),
                    "from_full_execution": True,  # í”Œëž˜ê·¸ ì¶”ê°€
                    "from_token_limit": True,
                    "installed_packages": installed_versions
                }, goto="Regenerate_Code")
            
            print(f"ðŸ”„ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì„±ê³µ")
            # print(f'ðŸ”„ analytic_result\n {analytic_result}')

            # ë¶„ì„ ê²°ê³¼ê°€ ìžˆëŠ” ê²½ìš°
            if analytic_result is not None:
                unique_id = datetime.now().strftime("%Y%m%d%H%M%S")
                # ì „ì²´ ì‹¤í–‰ ì„±ê³µ ì‹œ validated_code ì„¤ì •
                current_code = state.get("regenerated_code") or state["generated_code"]
                return Command(update={
                    "analytic_result": analytic_result,
                    "data_id": unique_id,
                    "validated_code": current_code,  # ì„±ê³µí•œ ì½”ë“œë¥¼ validated_codeë¡œ ì €ìž¥
                    "installed_packages": installed_versions
                }, goto="Save_Data")
            # ë¶„ì„ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
            else:
                print("âš ï¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                self.retry_count += 1
                return Command(update={
                    "error_message": self._normalize_error_message("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."),
                    "from_full_execution": True,  # í”Œëž˜ê·¸ ì¶”ê°€
                    "installed_packages": installed_versions
                }, goto="Regenerate_Code")

        except Exception as e:
            print(f"âŒ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì‹¤íŒ¨\n {code_to_execute}")
            print(f"ì—ëŸ¬ íƒ€ìž…: {type(e).__name__}")
            print(f"ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
            print(f"ì—ëŸ¬ ë°œìƒ ìœ„ì¹˜:")
            print(traceback.format_exc())
            error_details = {
                "error_type": type(e).__name__,
                "error_msg": str(e),
                "traceback": traceback.format_exc(),
                "installed_packages": installed_versions
            }
            self.retry_count += 1
            return Command(update={
                "error_message": self._normalize_error_message(error_details),
                "from_full_execution": True,  # í”Œëž˜ê·¸ ì¶”ê°€
                "installed_packages": installed_versions
            }, goto="Regenerate_Code")

    #########################################################
    # âœ… Save_Data ë…¸ë“œ
    # -> Insight_Builder
    #########################################################
    def save_data(self, state):
        """ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì €ìž¥ (ID ë¶€ì—¬)"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ðŸ“‚ ì²˜ë¦¬ ë°ì´í„° ì €ìž¥ ë‹¨ê³„")
        # data_idê°€ ì—†ëŠ” ê²½ìš° ìƒì„±
        data_id = state.get("data_id", datetime.now().strftime("%Y%m%d%H%M%S"))
        analytic_result = state["analytic_result"]
        # ë¶„ì„ ê²°ê³¼ì™€ ì‹¤í–‰ ì¶œë ¥ì„ í•¨ê»˜ ì €ìž¥
        save_data = {
            'analytic_result': analytic_result,
        }

        # ì €ìž¥ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
        os.makedirs("../output", exist_ok=True)
        with open(f"../output/data_{data_id}.pkl", 'wb') as f:
            pickle.dump(save_data, f)

        print(f"ðŸ“‚ ì²˜ë¦¬ëœ ë°ì´í„° ì €ìž¥ ê²½ë¡œ: ../output/data_{data_id}.pkl")
        return Command(update={"data_id": data_id}, goto="Insight_Builder")
    
    #########################################################
    # âœ… Insight_Builder ë…¸ë“œ
    # -> Chart_Builder / Report_Builder
    #########################################################
    def generate_insights(self, state):
        """ì €ìž¥ëœ ë°ì´í„°ì—ì„œ ìžë™ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ë° ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ ê²°ì •"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ðŸ’¡ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ë‹¨ê³„")
        dict_result = state["analytic_result"]
        user_question = self.original_query

        # âœ… ì§‘ê³„ ë°ì´í„°ë©´ ì „ì²´ ë°ì´í„° ì „ë‹¬
        string_of_result = str(dict_result)

        ##############################
        # 1. ì¸ì‚¬ì´íŠ¸ ìƒì„±
        ##############################
        prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_INSIGHT_BUILDER),
            ("user", "user_question:\n{user_question}\n\n"),
            ("user", "analytic_result:\n{analytic_result}\n\n")
        ])

        chain = prompt | self.llm
        insight_response = chain.invoke({
            "user_question": user_question,
            "analytic_result": string_of_result
        })

        print(f"ðŸ’¡ ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸\n{insight_response.content}")
        
        ##############################
        # 2. ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ ê²°ì •
        ##############################
        prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_CHART_NEEDED),
            ("user", "user_question:\n{user_question}\n\n"),
            ("user", "analytic_result:\n{analytic_result}\n\n"),
            ("user", "insights:\n{insights}\n\n")
        ])
        
        # ì°¨íŠ¸ í™œìš© ì—¬ë¶€ 'yes' ë˜ëŠ” 'no' ë°˜í™˜
        chart_decision_messages = prompt | self.llm.with_structured_output(YesNo)
        chart_needed = chart_decision_messages.invoke({
            "user_question": user_question,
            "analytic_result": string_of_result,
            "insights": insight_response.content
        }).decision
        print(f"ðŸ’¡ ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ (yes/no): {chart_needed}")
        
        # ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ì— ë”°ë¼ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
        next_step = "Chart_Builder" if chart_needed == "yes" else "Report_Builder"
        
        return Command(update={
            "insights": insight_response.content,
            "chart_needed": chart_needed == "yes"
        }, goto=next_step)  # Supervisor ëŒ€ì‹  ì ì ˆí•œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
        
    #########################################################
    # âœ… Chart_Builder ë…¸ë“œ
    # -> Report_Builder / Regenerate_Chart
    #########################################################
    def generate_chart(self, state):
        """ì°¨íŠ¸ ìƒì„± ë¡œì§ (ìµœëŒ€ 3íšŒ ìž¬ì‹œë„)"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ðŸ“Š ì°¨íŠ¸ ìƒì„± ë‹¨ê³„")

        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì°¨íŠ¸ ìƒì„± 3íšŒ ì‹¤íŒ¨. ì°¨íŠ¸ ì—†ì´ ë¦¬í¬íŠ¸ ìƒì„±ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            self.retry_count = 0  # ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={"chart_filename": None}, goto="Report_Builder")
        
        try:
            analytic_result = state.get("analytic_result", {})
            string_of_result = str(analytic_result)
            insights = state.get('insights', 'ì¸ì‚¬ì´íŠ¸ ì—†ìŒ')
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_CHART_GENERATOR),
                ("user", """
Here are the analytic_result and insights to visualize:

Analysis Results Summary:
{analytic_result}

Key Insights:
{insights}

Please create an appropriate visualization that supports these insights.
Do not hardcode any values - use the analytic_result dictionary directly.
                """)            
            ])

            chain = prompt | self.llm
            chart_code = chain.invoke({
                "analytic_result": string_of_result,
                "insights": insights
            }).content
            
            print(f"ðŸ’¡ ìƒì„±ëœ ì°¨íŠ¸ ì½”ë“œ\n{chart_code}")
            
            # âœ… ì°¨íŠ¸ ì½”ë“œ ë¸”ë¡ì´ ìžˆëŠ” ê²½ìš° ì½”ë“œ ì¶”ì¶œ
            extracted_code = self._extract_code_from_llm_response(chart_code)
            
            # ðŸ”¹ ê¸°ì¡´ì— LLMì´ ìƒì„±í•œ ì½”ë“œì—ì„œ `plt.show()` ì œê±°
            extracted_code = extracted_code.replace("plt.show()", "").strip()

            # ðŸ”¹ ì°¨íŠ¸ ì €ìž¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs("../img", exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            filename = f"../img/chart_{timestamp}.png"

            # ðŸ”¹ `plt.savefig()`ë¥¼ ë¨¼ì € ì‹¤í–‰í•œ í›„ `plt.show()` ì¶”ê°€
            extracted_code += f"\nplt.savefig('{filename}', dpi=300)\nplt.show()"

            # âœ… ë””ë²„ê¹…ìš© ì¶œë ¥ (ìƒì„±ëœ ì½”ë“œ í™•ì¸)
            # print(f"ðŸ“Š ìƒì„±ëœ ì°¨íŠ¸ ì½”ë“œ\n{extracted_code}")
            
            # ì‹¤í–‰ í™˜ê²½ ì„¤ì •
            exec_globals = {
                'plt': plt,
                'np': np,
                'sns': sns,
                'pd': pd,
                'analytic_result': analytic_result,
            }
            
            # ì½”ë“œ ì‹¤í–‰
            exec(extracted_code, exec_globals)
            plt.close()

            print(f"âœ… ì°¨íŠ¸ ìƒì„± ì„±ê³µ: {filename}")
            self.retry_count = 0  # ì„±ê³µ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={
                "chart_filename": filename,
                "chart_error": None
            }, goto="Report_Builder")

        except Exception as e:
            print(f"âŒ ì°¨íŠ¸ ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            plt.close()
            error_details = {
                "error_msg": str(e),
                "executed_code": extracted_code,
                "traceback": traceback.format_exc()
            }
            # âŒ ì‹¤íŒ¨ ì‹œ Regenerate_Chartë¡œ ì´ë™
            self.retry_count += 1
            return Command(
                update={
                    "chart_filename": None,
                    "chart_error": self._normalize_error_message(error_details)
                },
                goto="Regenerate_Chart"
            )

    #########################################################
    # âœ… Regenerate_Chart ë…¸ë“œ
    # -> Report_Builder / Regenerate_Chart
    #########################################################
    def regenerate_chart(self, state):
        """ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì°¨íŠ¸ ìž¬ìƒì„±"""
        print("="*100)
        print("ðŸ”„ ì°¨íŠ¸ ìž¬ìƒì„± ë‹¨ê³„")
        
        dict_result = state["analytic_result"]
        string_of_result = str(dict_result)
        insights = state.get('insights', 'ì¸ì‚¬ì´íŠ¸ ì—†ìŒ')
        previous_error = state.get("chart_error", {})

        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì°¨íŠ¸ ìž¬ìƒì„± 3íšŒ ì‹¤íŒ¨. ì°¨íŠ¸ ì—†ì´ ë¦¬í¬íŠ¸ ìƒì„±ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            self.retry_count = 0  # ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={
                "chart_filename": None,
                "chart_error": self._normalize_error_message("ì°¨íŠ¸ ìž¬ìƒì„± 3íšŒ ì‹¤íŒ¨")
            }, goto="Report_Builder")

        prompt = ChatPromptTemplate.from_messages([
            ("system", "Python ì½”ë“œì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”."),  # ì°¨íŠ¸ ìž¬ìƒì„± ì „ìš© í”„ë¡¬í”„íŠ¸
            ("user", """
    ì´ì „ ì°¨íŠ¸ ìƒì„± ì‹œë„ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:
    ì—ëŸ¬ ë©”ì‹œì§€: {error_message}

    ì´ì „ ì½”ë“œ:
    {previous_code}

    ì „ì²´ ì—ëŸ¬ ë‚´ìš©:
    {error_traceback}

    ë¶„ì„í•  ë°ì´í„°:
    {analytic_result}

    ì¸ì‚¬ì´íŠ¸:
    {insights}

    ìœ„ì˜ ì—ëŸ¬ë¥¼ í•´ê²°í•œ ìƒˆë¡œìš´ ì°¨íŠ¸ ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            """)
        ])

        chain = prompt | self.llm
        chart_code = chain.invoke({
            "error_message": previous_error.get("error_message", "ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬"),
            "previous_code": previous_error.get("previous_code", "ì´ì „ ì½”ë“œ ì—†ìŒ"),
            "error_traceback": previous_error.get("traceback", "íŠ¸ë ˆì´ìŠ¤ë°± ì—†ìŒ"),
            "analytic_result": string_of_result,
            "insights": insights
        }).content

        extracted_code = self._extract_code_from_llm_response(chart_code)

        # âœ… ìœ íš¨í•œ Python ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš° ìž¬ì‹œë„
        if not extracted_code:
            print("ðŸ“Š [regenerate_chart] ìœ íš¨í•œ Python ì½”ë“œ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ìž¬ì‹œë„í•©ë‹ˆë‹¤.")
            self.retry_count += 1
            return Command(update={
                "retry_count": self.retry_count + 1,
                "chart_error": self._normalize_error_message("ìœ íš¨í•œ Python ì½”ë“œ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤")
            }, goto="Regenerate_Chart")

        # âœ… ì°¨íŠ¸ ì €ìž¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("../img", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        filename = f"../img/chart_{timestamp}.png"

        # ðŸ”¹ `plt.show()` ì œê±°
        extracted_code = extracted_code.replace("plt.show()", "").strip()

        # ðŸ”¹ `plt.savefig()` ì¶”ê°€
        extracted_code += f"\nplt.savefig('{filename}', dpi=300)\nplt.show()"
        
        print(f"ðŸ“Š ì‹¤í–‰í•  ì°¨íŠ¸ ì½”ë“œ:\n{extracted_code}")

        try:
            exec(extracted_code, globals())
            print(f"âœ… ì°¨íŠ¸ ìž¬ìƒì„± ì„±ê³µ: {filename}")
            plt.close()
            self.retry_count = 0  # ì„±ê³µ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={
                "chart_filename": filename,
                "chart_error": None
            }, goto="Report_Builder")

        except Exception as e:
            print(f"âŒ ì°¨íŠ¸ ìž¬ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            plt.close()
            error_details = {
                "error_msg": str(e),
                "executed_code": extracted_code,
                "traceback": traceback.format_exc()
            }
            self.retry_count += 1
            return Command(update={
                "chart_filename": None,
                "chart_error": self._normalize_error_message(error_details)
            }, goto="Regenerate_Chart")

    #########################################################
    # âœ… Report_Builder ë…¸ë“œ
    # -> After_Feedback
    #########################################################
    def generate_report(self, state):
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ðŸ“‘ ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„")
        dict_result = state["analytic_result"]
        string_of_result = str(dict_result)
        insights = state.get('insights', 'ì¸ì‚¬ì´íŠ¸ ì—†ìŒ')
        user_request = self.original_query
        prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_REPORT_GENERATOR),
            ("user", "1. ë¶„ì„ ê²°ê³¼ ë°ì´í„°\n{analytic_result}\n\n"),
            ("user", "2. ì‚¬ìš©ìž ìš”ì²­\n{user_request}\n\n"),
            ("user", "3. ë„ì¶œëœ ì¸ì‚¬ì´íŠ¸\n{insights}\n\n"),
        ])

        chain = prompt | self.llm
        response = chain.invoke({
            "user_request": user_request,
            "analytic_result": string_of_result,
            "insights": insights,
        })
        print("âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        print(f"{response.content}")

        # start_from_analyticsê°€ Trueì´ë©´ ë°”ë¡œ ENDë¡œ ì´ë™
        if state.get("start_from_analytics", False):
            return Command(update={
                "report": response.content, 
                "error_message": None # ì˜¤ë¥˜ ë©”ì‹œì§€ ì´ˆê¸°í™”  
            }, goto=END)
        else :
            # ì¼ë°˜ ë¶„ì„ì¸ ê²½ìš° After_Feedbackìœ¼ë¡œ ì´ë™
            return Command(update={
                "report": response.content, 
                "error_message": None # ì˜¤ë¥˜ ë©”ì‹œì§€ ì´ˆê¸°í™”  
            }, goto='After_Feedback')
    
    #########################################################
    # âœ… After_Feedback ë…¸ë“œ
    # -> END
    #########################################################
    def after_feedback(self, state):
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ðŸ’¡ í”¼ë“œë°± ë‹¨ê³„")
        dict_result = state["analytic_result"]
        string_of_result = str(dict_result)
        user_question = self.original_query
        validated_code = state["validated_code"]
        ############################################################
        # í”¼ë“œë°± í•„ìš” ì—¬ë¶€ ê²°ì •
        ############################################################
        prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_FEEDBACK_NEEDED),
            ("user", "user_question:\n{user_question}\n\n"),
            ("user", "analysis_result:\n{analysis_result}\n\n"),
            ("user", "validated_code:\n{validated_code}\n\n")
        ])
        
        feedback_decision = self.llm.with_structured_output(YesNo)
        feedback_needed = (prompt | feedback_decision).invoke({
            "user_question": user_question,
            "analysis_result": string_of_result,
            "validated_code": validated_code
        }).decision

        print(f"ðŸ’¡ í”¼ë“œë°± í•„ìš” ì—¬ë¶€: {feedback_needed}")
        
        # í”¼ë“œë°± í•„ìš”í•œ ê²½ìš° í”¼ë“œë°± ì²˜ë¦¬
        if feedback_needed == 'yes':            
            prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_FEEDBACK_PROCESS),
                ("user", "user_question:\n{user_question}\n\n"),
                ("user", "analysis_result:\n{analysis_result}\n\n"),
                ("user", "validated_code:\n{validated_code}\n\n")
            ])
            
            feedback_analysis_messages = prompt | self.llm
            feedback_analysis = feedback_analysis_messages.invoke({
                "user_question": user_question,
                "analysis_result": string_of_result,
                "validated_code": validated_code,
            }).content.strip().lower()
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_FEEDBACK_POINT),
                ("user", "feedback_analysis:\n{feedback_analysis}\n\n")
            ])
            
            feedback_point_messages = prompt | self.llm.with_structured_output(Feedback)
            feedback_point = feedback_point_messages.invoke({
                "user_question": user_question,
                "feedback_analysis": feedback_analysis
            }).feedback_point

            print(f"ðŸ’¡ í”¼ë“œë°± ë‚´ìš©: {feedback_analysis}")
            print("âœ… í”¼ë“œë°± ì™„ë£Œ")

            return Command(update={"feedback": feedback_analysis, 'feedback_point': feedback_point}, goto=END)
        else :
            return Command(goto=END)
    

    ##################################################################################################################
    # ë¼ìš°í„° ëª¨ìŒ
    ##################################################################################################################
    def route_after_generate_code(self, state: State):
        """ì½”ë“œ ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        print("âž¡ï¸ [route_after_generate_code] ì½”ë“œ ìƒì„± í›„ ê²½ë¡œ ê²°ì •")

        if state.get("generated_code"):
            print("âž¡ï¸ [route_after_generate_code] ìƒ˜í”Œ ì‹¤í–‰ ì§„í–‰")
            return "Execute_Sample"
        else:
            print("âž¡ï¸ [route_after_generate_code] ë§ˆíŠ¸ í™œì„±í™” í•„ìš” -> [í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ]")
            return END


    def route_after_sample(self, state: State):
        """ìƒ˜í”Œ ì‹¤í–‰ í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        print("âž¡ï¸ [route_after_sample] ìƒ˜í”Œ ì‹¤í–‰ í›„ ê²½ë¡œ ê²°ì •")
        
        if not self.active_marts or self.active_marts is None:
            print("âž¡ï¸ [route_after_sample] í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë§ˆíŠ¸ë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”.")
            return END
        
        if not state.get("error_message"):  # ì—ëŸ¬ê°€ ì—†ìœ¼ë©´
            print("âž¡ï¸ [route_after_sample] ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì§„í–‰")
            return "Execute_Full"
        else:
            if self.retry_count >= MAX_RETRIES:
                print("âš ï¸ ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ 3íšŒ ì‹¤íŒ¨ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
                self.retry_count = 0
                return END
            print(f"âš ï¸ ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ â†’ ì½”ë“œ ìž¬ìƒì„± í•„ìš” | ìž¬ì‹œë„ íšŸìˆ˜: {self.retry_count}")
            return "Regenerate_Code"


    def route_after_insights(self, state: State) -> str:
        """ì¸ì‚¬ì´íŠ¸ ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print(f"âž¡ï¸ [route_after_insights] ì¸ì‚¬ì´íŠ¸ ìƒì„± í›„ ê²½ë¡œ ê²°ì •(ì°¨íŠ¸ or ë³´ê³ ì„œ)")
        
        if state.get("chart_needed", False):
            print("âž¡ï¸ [route_after_insights] ì°¨íŠ¸ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤")
            return "Chart_Builder"
        print("âž¡ï¸ [route_after_insights] ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤")
        return "Report_Builder"
    
    def route_after_chart(self, state: State) -> str:
        """ì°¨íŠ¸ ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        print(f"âž¡ï¸ [route_after_chart] ì°¨íŠ¸ ìƒì„± í›„ ê²½ë¡œ ê²°ì •(ì°¨íŠ¸ ìž¬ìƒì„± or ë³´ê³ ì„œ)")

        if state.get("chart_filename"):
            print("âž¡ï¸ [route_after_chart] ì°¨íŠ¸ ìƒì„± ì„±ê³µ â†’ ë¦¬í¬íŠ¸ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰")
            return "Report_Builder"
        
        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì°¨íŠ¸ ìƒì„± 3íšŒ ì‹¤íŒ¨ â†’ ì°¨íŠ¸ ì—†ì´ ë¦¬í¬íŠ¸ ìƒì„±ìœ¼ë¡œ ì§„í–‰")
            self.retry_count = 0  # ì¹´ìš´í„° ì´ˆê¸°í™”
            return "Report_Builder"
        
        print(f"âž¡ï¸ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ â†’ ìž¬ìƒì„± ì‹œë„ (Regenerate_Chart) ({self.retry_count + 1}/3)")
        return "Regenerate_Chart"


    def route_after_regenerate(self, state: State) -> str:
        """ì½”ë“œ ìž¬ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        from_full_execution = state.get("from_full_execution", False)
        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì½”ë“œ ìž¬ìƒì„± 3íšŒ ì‹¤íŒ¨ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
            return END
        
        if from_full_execution:
            print("âž¡ï¸ [route_after_regenerate] ì „ì²´ ë°ì´í„° ì‹¤í–‰ìœ¼ë¡œ ì§„í–‰")
            return "Execute_Full"
        else:
            print("âž¡ï¸ [route_after_regenerate] ìƒ˜í”Œ ì‹¤í–‰ìœ¼ë¡œ ì§„í–‰")
            return "Execute_Sample"
        

    def route_after_full_execution(self, state: State) -> str:
        """ì „ì²´ ë°ì´í„° ì‹¤í–‰ í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°
        
        Returns:
            str: ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œì˜ ì´ë¦„
        """
        print("âž¡ï¸ [route_after_full_execution] ì „ì²´ ë°ì´í„° ì‹¤í–‰ í›„ ê²½ë¡œ ê²°ì •")
        
        if state.get("validated_code"):  # validated_codeê°€ ìžˆìœ¼ë©´ ì„±ê³µ
            print("âž¡ï¸ [route_after_full_execution] ë°ì´í„° ì €ìž¥ ë‹¨ê³„ë¡œ ì§„í–‰")
            return "Save_Data"
        
        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì „ì²´ ë°ì´í„° ì‹¤í–‰ 3íšŒ ì‹¤íŒ¨ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
            return END
        
        print(f"âš ï¸ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì‹¤íŒ¨ â†’ ì½”ë“œ ìž¬ìƒì„± í•„ìš” | ìž¬ì‹œë„ íšŸìˆ˜: {self.retry_count}")
        return "Regenerate_Code"

    def route_after_report(self, state: State) -> str:
        """ë¦¬í¬íŠ¸ ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°
        
        Returns:
            str: ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œì˜ ì´ë¦„ (After_Feedback ë˜ëŠ” END)
        """
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("âž¡ï¸ [route_after_report] ë¦¬í¬íŠ¸ ìƒì„± í›„ ê²½ë¡œ ê²°ì •")
        
        # start_from_analyticsê°€ Trueì´ë©´ ë°”ë¡œ ENDë¡œ ì´ë™
        if state.get("start_from_analytics", False):
            print("âž¡ï¸ [route_after_report] ê°œì„  ìš”ì²­ ì²˜ë¦¬ì´ë¯€ë¡œ ë°”ë¡œ ì¢…ë£Œ")
            return END
        
        print("âž¡ï¸ [route_after_report] í”¼ë“œë°± ë‹¨ê³„ë¡œ ì§„í–‰")
        return "After_Feedback"

    ##################################################################################################################
    # í•¨ìˆ˜ ëª¨ìŒ
    ##################################################################################################################
    def set_active_mart(self, data_mart: Union[pd.DataFrame, Dict[str, pd.DataFrame]], mart_name: Union[str, List[str], None] = None) -> None:
        """ë¶„ì„í•  ë°ì´í„°í”„ë ˆìž„ê³¼ ë§ˆíŠ¸ ì •ë³´ë¥¼ ì„¤ì •"""
        if isinstance(data_mart, pd.DataFrame):
            # ë‹¨ì¼ ë°ì´í„°í”„ë ˆìž„ ì„¤ì •
            mart_key = mart_name if mart_name else "default_mart"
            self.active_marts = {mart_key: data_mart}
        elif isinstance(data_mart, dict):
            # ë‹¤ì¤‘ ë°ì´í„°í”„ë ˆìž„ ì„¤ì •
            self.active_marts = data_mart
        else:
            raise TypeError("ìž…ë ¥ëœ ë°ì´í„°ê°€ pandas DataFrame ë˜ëŠ” DataFrame ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")

        # ë§ˆíŠ¸ ì •ë³´ ì„¤ì • (ì—‘ì…€ íŒŒì¼ì˜ sheetì—ì„œ ê°€ì ¸ì˜´)
        mart_info_list = []
        for mart_key in self.active_marts.keys():
            if mart_key in self.mart_info_df:
                mart_info_list.append(f"## {mart_key} ë§ˆíŠ¸ ì •ë³´\n{self.mart_info_df[mart_key].to_markdown()}")
        
        self.mart_info = "\n\n".join(mart_info_list) if mart_info_list else None

        # ë°ì´í„°í”„ë ˆìž„ ê°œìˆ˜ ë° ì •ë³´ ì¶œë ¥
        print(f"ðŸ”¹ {len(self.active_marts)}ê°œì˜ ë°ì´í„°í”„ë ˆìž„ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        for name, df in self.active_marts.items():
            print(f"ðŸ”¹ ë°ì´í„°ë§ˆíŠ¸ ì´ë¦„: {name}")
            print(f"ðŸ”¹ ë°ì´í„° í¬ê¸°: {df.shape[0]}í–‰ x {df.shape[1]}ì—´")
            if self.mart_info and name in self.mart_info_df:
                print(f"ðŸ”¹ ë§ˆíŠ¸ ì •ë³´ ë¡œë“œë¨")
    
    # ìƒì„±í˜• AIê°€ ìƒì„±í•œ ì½”ë“œë¥¼ ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ì¶œë ¥ì„ ì €ìž¥í•˜ëŠ” í•¨ìˆ˜
    def _execute_code_with_capture(self, code, exec_globals, is_sample=False):
        
        # í‘œì¤€ ì¶œë ¥ì„ ê°€ë¡œì±„ê¸° ìœ„í•´ StringIO ì‚¬ìš©
        captured_output = io.StringIO()
        original_stdout = sys.stdout  # ì›ëž˜ í‘œì¤€ ì¶œë ¥ ì €ìž¥

        # âœ… ì‹¤í–‰ ì „, exec_globals ì´ˆê¸°í™” (ì´ì „ ê°’ ìœ ì§€ ë°©ì§€)
        safe_locals = {}

        try:
            sys.stdout = captured_output  # í‘œì¤€ ì¶œë ¥ ë³€ê²½
            exec(code, exec_globals, safe_locals)  # **ì œí•œëœ ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ì—ì„œ ì‹¤í–‰**
            sys.stdout = original_stdout # í‘œì¤€ ì¶œë ¥ì„ ì›ëž˜ëŒ€ë¡œ ë³µì›
            
            print(f"ðŸ”„ [_execute_code_with_capture] ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ ê°ì²´ : {safe_locals.keys()}")

            # ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
            results = None
            analytic_result = None
            
            # ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì‹œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
            if not is_sample:
                if "result_df" in safe_locals:
                    results = safe_locals["result_df"]
                elif "analytic_result" in safe_locals:
                    results = safe_locals["analytic_result"]
                
                # ê²°ê³¼ íƒ€ìž…ì— ë”°ë¥¸ í‘œì¤€í™” ì²˜ë¦¬
                if results is not None:
                    if isinstance(results, pd.DataFrame):
                        # DataFrameì„ dictionaryë¡œ ë³€í™˜
                        analytic_result = results.to_dict('records') if not results.empty else {}
                    elif isinstance(results, dict):
                        # DictionaryëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        analytic_result = results
                    elif isinstance(results, list):
                        # ListëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        analytic_result = results
                    else:
                        # ê¸°íƒ€ íƒ€ìž…ì€ dictionaryë¡œ ë³€í™˜
                        analytic_result = {"result": str(results)}
            
            # ì¶œë ¥ ë° ë¶„ì„ ê²°ê³¼ ë°˜í™˜
            return captured_output.getvalue(), analytic_result
            
        except Exception as e:
            captured_output.write(f"Error: {str(e)}\n")  # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
            sys.stdout = original_stdout
            raise e

    def _calculate_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë©”ì†Œë“œ
        
        Args:
            text (str): í† í° ìˆ˜ë¥¼ ê³„ì‚°í•  í…ìŠ¤íŠ¸
            
        Returns:
            int: í† í° ìˆ˜
        """
        try:
            enc = tiktoken.get_encoding("cl100k_base")
            tokens = enc.encode(text)
            return len(tokens)
        except Exception as e:
            print(f"âš ï¸ í† í° ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return 0
        
    def _extract_code_from_llm_response(self, code_block: str) -> str:
        """LLM ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡ì„ ì¶”ì¶œí•˜ëŠ” ë©”ì†Œë“œ
        
        Args:
            response (str): LLMì´ ìƒì„±í•œ ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            str: ì¶”ì¶œëœ ì½”ë“œ (ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš° ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ì—¬ ë°˜í™˜)
        """
        try:
            if "```python" in code_block:
                return code_block.split("```python")[1].split("```")[0].strip()
            elif "```" in code_block:
                return code_block.split("```")[1].strip()
            return code_block.strip()
        except Exception as e:
            print(f"âš ï¸ ì½”ë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return code_block.strip()

   
    def _get_mart_info(self) -> str:
        """ë°ì´í„°í”„ë ˆìž„ì˜ ë§ˆíŠ¸ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì„œë“œ
        
        Returns:
            str: ë§ˆíŠ¸ ì •ë³´ ë¬¸ìžì—´ (ë§ˆíŠ¸ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜)
        """
        mart_info = ""
        if hasattr(self, 'active_marts') and self.active_marts:
            for mart_name in self.active_marts.keys():
                if mart_name in self.mart_info_df:
                    mart_info += f"\n- ë°ì´í„°í”„ë ˆìž„ : {mart_name}ì˜ ì»¬ëŸ¼ ë° ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ##\n"
                    mart_info += self.mart_info_df[mart_name].to_markdown().replace("{", "{{").replace("}", "}}")  # ì´ìŠ¤ì¼€ì´í”„ ì ìš©
                    mart_info += "\n"
                else:
                    mart_info += f"\n## {mart_name} ë§ˆíŠ¸ ì •ë³´ ì—†ìŒ ##\n"
        else:
            mart_info = "ë°ì´í„°í”„ë ˆìž„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        return mart_info


    def _extract_imported_packages(self, code):
        """LLMì´ ìƒì„±í•œ ì½”ë“œì—ì„œ importëœ íŒ¨í‚¤ì§€ ì´ë¦„ë§Œ ì¶”ì¶œ"""
        tree = ast.parse(code)
        imports = set()

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.add(alias.name.split('.')[0])  # ìµœìƒìœ„ íŒ¨í‚¤ì§€ë§Œ ì¶”ì¶œ
            elif isinstance(node, ast.ImportFrom):
                imports.add(node.module.split('.')[0])  # from X import Y í˜•ì‹ ì²˜ë¦¬

        return list(imports)

    def _get_installed_versions(self,used_packages):
        """ì‚¬ìš©ëœ íŒ¨í‚¤ì§€ì˜ ë²„ì „ë§Œ ê°€ì ¸ì˜¤ê¸°"""
        return {
            pkg: pkg_resources.get_distribution(pkg).version
            for pkg in used_packages if pkg in [p.key for p in pkg_resources.working_set]
        }
        
    def _normalize_error_message(self, error_message: Union[str, Dict]) -> Dict:
        """error_messageë¥¼ í‘œì¤€í™”ëœ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ"""
        if isinstance(error_message, dict):
            return error_message
    
    # ë¬¸ìžì—´ì¸ ê²½ìš° í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return {
                "error_type": "GeneralError",
                "error_msg": str(error_message),
                "traceback": "",
                "installed_packages": {}
            }