import os, sys
import io
import pickle
import pandas as pd
import numpy as np
import traceback
from IPython.display import display
from datetime import datetime
from typing import TypedDict, List, Literal, Annotated, Dict, Union
from pydantic import BaseModel
import tiktoken
from uuid import uuid4
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, END, START
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.types import Command
from fuzzywuzzy import process

from prompt.prompts import *
from common_txt import logo
from utils.vector_handler import load_vectorstore

# âœ… í•œê¸€ í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
matplotlib.rcParams['font.family'] = 'Malgun Gothic'
matplotlib.rcParams['axes.unicode_minus'] = False

VECTOR_DB_BASE_PATH = "./vectordb/analysis"
PROCESSED_DATA_PATH = "../output/stage1/processed_data_info.xlsx"
MAX_RETRIES = 3

# âœ… AI ë¶„ì„ ì—ì´ì „íŠ¸ ìƒíƒœ ì •ì˜(stateì— ì ì¬ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë™)
class State(TypedDict):
    messages: List[HumanMessage]  # ğŸ”¹ ì‚¬ìš©ìì™€ AI ê°„ì˜ ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡
    mart_info: str  # ğŸ”¹ í˜„ì¬ í™œì„±í™”ëœ ë°ì´í„°í”„ë ˆì„ (ë¶„ì„ ëŒ€ìƒ)
    generated_code: str  # ğŸ”¹ ì´ˆê¸° ìƒì„±ëœ ì½”ë“œ
    regenerated_code: str  # ğŸ”¹ ì¬ìƒì„±ëœ ì½”ë“œ
    validated_code: str  # ì „ì²´ ì‹¤í–‰ê¹Œì§€ í†µê³¼í•œ ì½”ë“œ
    analytic_result: Dict  # ğŸ”¹ ì „ì²´ ë°ì´í„°ë¥¼ ì‹¤í–‰í•˜ì—¬ ì–»ì€ ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    execution_output: str  # ğŸ”¹ ì½”ë“œ ì‹¤í–‰ ì¤‘ ìƒì„±ëœ ì¶œë ¥ í…ìŠ¤íŠ¸
    error_message: str  # ğŸ”¹ ì½”ë“œ ì‹¤í–‰ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ ë©”ì‹œì§€ (ìˆë‹¤ë©´ ì¬ì‹œë„í•  ë•Œ í™œìš©)
    data_id: str  # ğŸ”¹ ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë•Œ ë¶€ì—¬ë˜ëŠ” ê³ ìœ  ID (íŒŒì¼ ì €ì¥ ì‹œ í™œìš©)
    insights: str  # ğŸ”¹ LLMì´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±í•œ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
    chart_decision: str  # ğŸ”¹ ì°¨íŠ¸ ìƒì„± ì—¬ë¶€ë¥¼ íŒë‹¨í•œ ê²°ê³¼ (yes/no)
    chart_filename: str  # ğŸ”¹ ìƒì„±ëœ ì°¨íŠ¸ì˜ íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ None)
    report: str  # ğŸ”¹ ìƒì„±ëœ ë¦¬í¬íŠ¸
    chart_needed: bool  # ğŸ”¹ ì°¨íŠ¸ê°€ í•„ìš”í•œì§€ ì—¬ë¶€ (True: í•„ìš”í•¨, False: ë¶ˆí•„ìš”)
    retry_chart: int  # ğŸ”¹ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜ (ìµœëŒ€ 3íšŒ)
    retry_count: int  # ğŸ”¹ ì½”ë“œ ì¬ìƒì„± ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜ (ìµœëŒ€ 3íšŒ)
    q_category: str  # ğŸ”¹ Supervisorê°€ íŒë‹¨í•œ ì§ˆë¬¸ ìœ í˜• (Analytics, General, Knowledge)
    general_response: str  # ğŸ”¹ General ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ
    knowledge_response: str  # ğŸ”¹ Knowledge ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ
    chart_error: int  # ğŸ”¹ ì°¨íŠ¸ ìƒì„± íšŸìˆ˜ ì¹´ìš´í„°
    from_full_execution: bool  # ğŸ”¹ ì½”ë“œ ì¬ìƒì„± ì‹œ ì´ˆê¸° ì‹¤í–‰ ì—¬ë¶€
    from_token_limit: bool  # ğŸ”¹ í† í° ì œí•œ ì´ˆê³¼ ì‹œ ì´ˆê¸° ì‹¤í–‰ ì—¬ë¶€
    request_summary: str  # ğŸ”¹ ë¶„ì„ ìš”ì²­ì„ í•œê¸€ë¡œ ìš”ì•½í•œ ë‚´ìš©

# âœ… ê²½ë¡œ ê²°ì •ìš© ë¼ìš°í„°
class Router(BaseModel):
    next: Literal["Analytics", "General", "Knowledge", "Generate_Code", "Execute_Sample", "Regenerate_Code", "Execute_Full", 
                  "Save_Data", "Insight_Builder", "Chart_Builder", "Regenerate_Chart", "Report_Builder", "__end__"]

class DataAnayticsAssistant:
    """Python DataFrame ê¸°ë°˜ AI ë¶„ì„ ì—ì´ì „íŠ¸ (LangGraph ê¸°ë°˜)"""

    def __init__(self, openai_api_key: str):
        self.llm = ChatOpenAI(model="gpt-4o", openai_api_key=openai_api_key, temperature=0.0)
        self.active_marts = None
        self.mart_info = None
        self.retry_count = 0
        # ì¿¼ë¦¬ ê´€ë ¨ ìƒíƒœ ì¶”ê°€
        self.original_query = None
        self.context_query = None
        
        # ë§ˆíŠ¸ ì •ë³´ ì´ˆê¸° ë¡œë“œ
        try:
            self.mart_info_df = pd.read_excel(PROCESSED_DATA_PATH, sheet_name=None)
            print(f"ğŸ”¹ í˜„ì¬ ì ‘ê·¼ ê°€ëŠ¥ ë§ˆíŠ¸ ëª©ë¡: {list(self.mart_info_df.keys())}")
        except Exception as e:
            print(f"âš ï¸ ë§ˆíŠ¸ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.mart_info_df = {}
            
        self.build_graph()

    def build_graph(self):
        """LangGraphë¥¼ í™œìš©í•˜ì—¬ ë¶„ì„ íë¦„ êµ¬ì„±"""
        workflow = StateGraph(State)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("Supervisor", self.supervisor)
        workflow.add_node("Analytics", self.handle_analytics)
        workflow.add_node("General", self.handle_general)
        workflow.add_node("Knowledge", self.handle_knowledge)
        workflow.add_node("Generate_Code", self.generate_python_code)
        workflow.add_node("Execute_Sample", self.execute_sample_code)
        workflow.add_node("Regenerate_Code", self.regenerate_code)
        workflow.add_node("Execute_Full", self.execute_full_data)
        workflow.add_node("Save_Data", self.save_data)
        workflow.add_node("Insight_Builder", self.generate_insights)
        workflow.add_node("Chart_Builder", self.generate_chart)
        workflow.add_node("Regenerate_Chart", self.regenerate_chart)
        workflow.add_node("Report_Builder", self.generate_report)

        # ê¸°ë³¸ íë¦„ ì •ì˜
        workflow.add_edge(START, "Supervisor")
        workflow.add_conditional_edges(
            "Supervisor",
            lambda state: state["q_category"],  # Supervisorê°€ ê²°ì •í•œ ê²½ë¡œë¡œ ì´ë™
            {
                "Analytics": "Analytics",
                "General": "General",
                "Knowledge": "Knowledge",
            }
        )

        # âœ… ë¶„ì„ (analytics) íë¦„
        workflow.add_edge("Analytics", "Generate_Code")

        # âœ… ì½”ë“œ ìƒì„± ë…¸ë“œ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •
        workflow.add_conditional_edges(
            "Generate_Code",
            self.route_after_generate_code,
            {
                "Execute_Sample": "Execute_Sample",
                END : END,
            }
        )

        # âœ… ìƒ˜í”Œ ì‹¤í–‰ í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •
        workflow.add_conditional_edges(
            "Execute_Sample",
            self.route_after_sample,
            {
                "Execute_Full": "Execute_Full",
                "Regenerate_Code": "Regenerate_Code",
                END : END
            }
        )

        # âœ… ì½”ë“œ ì¬ìƒì„± íë¦„
        workflow.add_conditional_edges(
            "Regenerate_Code",
            self.route_after_regenerate,  # ìƒˆë¡œìš´ ë¼ìš°í„° í•¨ìˆ˜ ì‚¬ìš©
            {
                "Execute_Sample": "Execute_Sample",
                "Execute_Full": "Execute_Full",
                END: END  # âœ… 3íšŒ ì´ìƒì´ë©´ ì¢…ë£Œ
            }
        )

        workflow.add_conditional_edges(
            "Execute_Full",
            self.route_after_full_execution,
            {
                "Save_Data": "Save_Data",
                "Regenerate_Code": "Regenerate_Code",
                END : END
            }
        )
        workflow.add_edge("Save_Data", "Insight_Builder")
        workflow.add_conditional_edges(
            "Insight_Builder",
            self.route_after_insights,
            {
                "Chart_Builder": "Chart_Builder",
                "Report_Builder": "Report_Builder"
            }
        )

        # ì°¨íŠ¸ ìƒì„± ê´€ë ¨ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ìˆ˜ì •
        workflow.add_conditional_edges(
            "Chart_Builder",
            self.route_after_chart,
            {
                "Regenerate_Chart": "Regenerate_Chart",  # ì‹¤íŒ¨ ì‹œ ì¬ìƒì„±
                "Report_Builder": "Report_Builder",  # ì„±ê³µ ë˜ëŠ” ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼
            }
        )
        
        # ì°¨íŠ¸ ì¬ìƒì„± í›„ ë¼ìš°íŒ…
        workflow.add_conditional_edges(
            "Regenerate_Chart",
            self.route_after_chart,
            {
                "Regenerate_Chart": "Regenerate_Chart",  # ì—¬ì „íˆ ì‹¤íŒ¨ ì‹œ ë‹¤ì‹œ ì¬ìƒì„±
                "Report_Builder": "Report_Builder",  # ì„±ê³µ ë˜ëŠ” ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼
            }
        )

        workflow.add_edge("Report_Builder", END)
        self.graph = workflow.compile()
        print("âœ… ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ")        
        

    def ask(self, query: str, context_query: str = None):
        """LangGraph ì‹¤í–‰"""
        # ì¿¼ë¦¬ ìƒíƒœ ì €ì¥
        self.original_query = query
        self.context_query = context_query
        
        return self.graph.invoke({
            "messages": [HumanMessage(content=query)],  # ì›ë³¸ ì¿¼ë¦¬ë§Œ ì „ë‹¬
        }, config={"recursion_limit": 20})

    def supervisor(self, state: State) -> Command:
        """ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” Supervisor"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ğŸ‘¨â€ğŸ’¼ Supervisor ë‹¨ê³„:")
        user_request = self.context_query or self.original_query

        # ì‚¬ìš©ì ìš”ì²­ì„ 30ì ì´ë‚´ í•œê¸€ë¡œ ë³€í™˜
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ì‚¬ìš©ìì˜ ë¶„ì„ ìš”ì²­('user_request')ì„ 10ì ì´ë‚´ì˜ ëª…ì‚¬í˜•ìœ¼ë¡œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ë§Œ ì˜ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."),
            ("user", "{user_request}")
        ])
        
        chain = prompt | self.llm
        request_summary = chain.invoke({
            "user_request": user_request
        }).content.strip()
        
        print(f"ğŸ‘¨â€ğŸ’¼ ë³€í™˜ëœ ë¶„ì„ ìš”ì²­: {request_summary}")

        
        prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_SUPERVISOR),
                ("user", " user_request:\n{user_request}\n\n")
        ])
        chain = prompt | self.llm.with_structured_output(Router)
        response = chain.invoke({"user_request": state['messages'][-1].content})
        print(f"ğŸ‘¨â€ğŸ’¼ ë‹¤ìŒ ë‹¨ê³„(Analytics or General or Knowledge): {response.next}")
        return Command(update={"q_category": response.next, "request_summary": request_summary}, goto=response.next)
    
    def handle_analytics(self, state: State) -> Command:
        """ë¶„ì„ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ"""
        print("ğŸ‘¨â€ğŸ’¼ [handle_analytics] ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘")
        return Command(goto="Generate_Code")

    def handle_general(self, state: State) -> Command:
        """ì¼ë°˜ì ì¸ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ"""
        print("\nğŸ’¬ [handle_general] ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬")
        prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_GENERAL),
                ("user", " user_request:\n{user_request}\n\n")
        ])
                
        chain = prompt | self.llm
        # user_request = state['messages'][0].content
        user_request = self.original_query
        response = chain.invoke({"user_request": user_request})
        print(f"ğŸ’¬ ì¼ë°˜ ì‘ë‹µ: {response.content}")
        return Command(update={"general_response": response.content}, goto=END)

    def handle_knowledge(self, state: State) -> Command:
        """ì§€ì‹ ê¸°ë°˜ ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ"""
        print("\nğŸ“š [handle_knowledge] ì§€ì‹ ê¸°ë°˜ ì§ˆë¬¸ ì²˜ë¦¬")

        # FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
        vectorstore = load_vectorstore('./vectordb/analysis')
        if vectorstore is None:
            print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì‹¤íŒ¨: FAISS ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLMìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤.")
            # ì¼ë°˜ LLM ì‘ë‹µ ìƒì„±
            prompt = ChatPromptTemplate.from_messages([
                    ("system", "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¼ë°˜ì ì¸ ê´€ì ì—ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”. í˜„ì¬ íŠ¹ì • ë¬¸ì„œë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì°¸ì¡° ì—†ì´ ì‘ë‹µí•©ë‹ˆë‹¤."),
                    ("user", "{user_question}")
            ])
            chain = prompt | self.llm
            user_request = self.original_query
            response = chain.invoke({"user_question": user_request})
            return Command(update={"knowledge_response": response.content}, goto=END)

        # Retriever ìƒì„±
        retriever = vectorstore.as_retriever()

        # ì‚¬ìš©ì ì§ˆë¬¸ ê²€ìƒ‰
        user_question = state['messages'][-1].content
        retrieved_docs = retriever.get_relevant_documents(user_question)

        if not retrieved_docs:
            response = "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            # ê²€ìƒ‰ëœ ë¬¸ì„œ ìƒìœ„ 3ê°œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©
            context = "\n".join([doc.page_content for doc in retrieved_docs[:3]])
            prompt = ChatPromptTemplate.from_messages([
                    ("system", "ì‚¬ìš©ìì˜ 'ì§ˆë¬¸'ì— ë‹µë³€í•´ì£¼ì„¸ìš”. document ë‚´ìš©ì€ ì°¸ê³ í•˜ì‹œë˜, ì§ˆë¬¸ê³¼ ìƒê´€ì´ ì—†ë‹¤ë©´ ì°¸ê³ í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤."),
                    ("user", "\nì§ˆë¬¸:\n{user_question}"),
                    ("user", "\ndocument:\n{context}")
            ])
            chain = prompt | self.llm
            response = chain.invoke({"user_question": user_question, "context": context})
        print(f"ğŸ“– ì§€ì‹ ê¸°ë°˜ ì‘ë‹µ: {response.content}")

        return Command(update={"knowledge_response": response.content}, goto=END)

    ###########################################################################################################
    ###########################################################################################################

    def generate_python_code(self, state):
        """
        ì‚¬ìš©ìì˜ ìš”ì²­ì„ ê¸°ë°˜ìœ¼ë¡œ Python ì½”ë“œ ìƒì„±
        IF í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŒ -> END ë…¸ë“œë¡œ ì´ë™
        ELSE ë°ì´í„°í”„ë ˆì„ ì •ë³´ ìƒì„± ë° ì½”ë“œ ìƒì„± -> Execute_Sample ë…¸ë“œë¡œ ì´ë™
        """
        print("="*100)
        print("ğŸ¤– ì½”ë“œ ìƒì„± ë‹¨ê³„:")
        user_request = self.context_query
        
        # í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not self.active_marts:
            print("âŒ í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë§ˆíŠ¸ë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”.")
            return Command(update={"error_message": "âŒ í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë§ˆíŠ¸ë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”."}, goto='__end__')
        
        # ë§ˆíŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì¤‘ê´„í˜¸ ì´ìŠ¤ì¼€ì´í”„ ì ìš©)
        mart_info = ""
        if hasattr(self, 'active_marts') and self.active_marts:
            for mart_name in self.active_marts.keys():
                if mart_name in self.mart_info_df:
                    mart_info += f"\n- ë°ì´í„°í”„ë ˆì„ : {mart_name}ì˜ ì»¬ëŸ¼ ë° ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ##\n"
                    mart_info += self.mart_info_df[mart_name].to_markdown().replace("{", "{{").replace("}", "}}")  # ì´ìŠ¤ì¼€ì´í”„ ì ìš©
                    mart_info += "\n"
                else:
                    mart_info += f"\n## {mart_name} ë§ˆíŠ¸ ì •ë³´ ì—†ìŒ ##\n"
        else:
            mart_info = "ë°ì´í„°í”„ë ˆì„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

        # í”„ë¡¬í”„íŠ¸ ìƒì„± (format í™œìš©)
        prompt_text = PROMPT_GENERATE_CODE.format(mart_info=mart_info)

        prompt = ChatPromptTemplate.from_messages([
            ("system", prompt_text),
            ("user", "\nuser_request:\n{user_request}")
        ])

        chain = prompt | self.llm
        response = chain.invoke({
            "user_request": user_request,
        })
        print(f"ğŸ¤– ìƒì„±ëœ ì½”ë“œ:\n{response.content}\n")
        return Command(update={
            "generated_code": response.content,
            "regenerated_code": None,  # ì´ˆê¸°í™”
            "validated_code": None     # ì´ˆê¸°í™”
        }, goto="Execute_Sample")
    

    def execute_sample_code(self, state):
        """ìƒ˜í”Œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ Python ì½”ë“œ ì‹¤í–‰"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ğŸ§ª ìƒ˜í”Œ ì‹¤í–‰ ë‹¨ê³„")
        
        # ê° ë§ˆíŠ¸ë³„ë¡œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_marts = {}
        for mart_name, df in self.active_marts.items():
            sample_size = min(50, len(df))
            sample_marts[mart_name] = df.sample(n=sample_size)
            print(f"ğŸ§ª {mart_name}: {sample_size}ê°œ ìƒ˜í”Œ ì¶”ì¶œ")
    
        # print(f"ğŸ§ª ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ ì§ì „ ê¸€ë¡œë²Œ í‚¤ í™•ì¸(ì ‘ê·¼ ê°€ëŠ¥ ë°ì´í„°í”„ë ˆì„) \n {globals().keys()} ")

        try:
            # ì¬ìƒì„±ëœ ì½”ë“œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ì´ˆê¸° ìƒì„± ì½”ë“œ ì‚¬ìš©
            code_to_execute = self._extract_code_from_llm_response(
                state.get("regenerated_code") or state["generated_code"]
            )
            
            # ì‹¤í–‰ í™˜ê²½ì— ìƒ˜í”Œ ë°ì´í„°í”„ë ˆì„ ì¶”ê°€
            exec_globals = {}

            # ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„(df) ìë™ í• ë‹¹
            if len(sample_marts) == 1:
                exec_globals["df"] = list(sample_marts.values())[0]  # ìœ ì¼í•œ ë§ˆíŠ¸ë¥¼ dfë¡œ í• ë‹¹
            elif len(sample_marts) > 1:
                exec_globals["df"] = list(sample_marts.values())[0]  # ì²« ë²ˆì§¸ ë§ˆíŠ¸ë¥¼ ê¸°ë³¸ dfë¡œ ì„¤ì •

            # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì„ exec_globalsì— ì¶”ê°€
            exec_globals.update(sample_marts)

            # print(f"ğŸ”¹ ì‹¤í–‰ í™˜ê²½ì— ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„ ëª©ë¡: {list(exec_globals.keys())}")

            # ì¶”ì¶œëœ ì½”ë“œ ì‹¤í–‰
            self._execute_code_with_capture(code_to_execute, exec_globals, is_sample=True)
            # exec(code_to_execute, exec_globals)
            
            print(f"âœ… ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ ì„±ê³µ")
            self.retry_count = 0  # ì„±ê³µ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={
                "error_message": None
            }, goto="Execute_Full")

        except Exception as e:
            print(f"âŒ ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨")
            print(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            print(f"ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
            print(f"ì—ëŸ¬ ë°œìƒ ìœ„ì¹˜:")
            print(traceback.format_exc())
            error_details = {
                "error_type": type(e).__name__,
                "error_message": str(e),
                "traceback": traceback.format_exc()
            }
            self.retry_count += 1
            if self.retry_count >= MAX_RETRIES:
                print("âš ï¸ ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ 3íšŒ ì‹¤íŒ¨ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
                return Command(update={"error_message": error_details}, goto=END)
            return Command(update={"error_message": error_details}, goto="Regenerate_Code")


    def regenerate_code(self, state):
        """ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ ì‹œ LLMì„ í™œìš©í•˜ì—¬ ì½”ë“œ ì¬ìƒì„±"""
        from_full_execution = state.get("from_full_execution", False)  # í”Œë˜ê·¸ í™•ì¸

        if self.retry_count >= MAX_RETRIES:  # âœ… 3íšŒ ì´ˆê³¼ ì‹œ ì¢…ë£Œ
            return Command(goto=END)
        
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("âš’ï¸ ì½”ë“œ ì¬ìƒì„± ë‹¨ê³„")
        user_request = self.context_query or self.original_query
        error_message = state["error_message"]
        original_code = state["generated_code"]

        # í† í° ì´ˆê³¼ ì‹œ ì½”ë“œ ì¬ìƒì„±
        if state.get("from_token_limit", False):
            print(f"âš’ï¸ í† í° ì´ˆê³¼ ì‹œì˜ ì½”ë“œ ì¬ìƒì„± ì§„í–‰")
            prompt = ChatPromptTemplate.from_messages([
                    ("system", PROMPT_REGENERATE_CODE_WHEN_TOKEN_OVER),
                    ("user", "\nuser_request:\n{user_request}"),
            ])
        # ì¼ë°˜ ì½”ë“œ ì¬ìƒì„±
        else:
            prompt = ChatPromptTemplate.from_messages([
                        ("system", PROMPT_REGENERATE_CODE),
                        ("user", "\nuser_request:\n{user_request}"),
                        ("user", "\noriginal_code:\n{original_code}"),
                        ("user", "\nerror_message:\n{error_message}"),
                ])
        
        chain = prompt | self.llm
        
        # ì½”ë“œ ì¬ìƒì„±
        response = chain.invoke({
            "user_request": user_request,
            "original_code": original_code,
            "error_message": error_message
        })
        print(f"âš’ï¸ ì¬ìƒì„±ëœ ì½”ë“œ:\n{response.content}\n")
        next_step = "Execute_Full" if from_full_execution else "Execute_Sample"
        
        return Command(update={
            "regenerated_code": response.content,  # ì¬ìƒì„±ëœ ì½”ë“œ ì €ì¥
            "validated_code": None,  # validated_code ì´ˆê¸°í™”
            "from_full_execution": from_full_execution
        }, goto=next_step)


    def execute_full_data(self, state):
        """ì „ì²´ ë°ì´í„°ë¡œ Python ì½”ë“œ ì‹¤í–‰"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ğŸ”„ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ë‹¨ê³„")

        # ì „ì²´ ë°ì´í„°í”„ë ˆì„ ì„¤ì •
        full_marts = self.active_marts  # ì „ì²´ ë°ì´í„°í”„ë ˆì„ ì‚¬ìš©

        # ì‹¤í–‰ í™˜ê²½ì— ì „ì²´ ë°ì´í„°í”„ë ˆì„ ì¶”ê°€
        exec_globals = {}

        # ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„(df) ìë™ í• ë‹¹
        if len(full_marts) == 1:
            exec_globals["df"] = list(full_marts.values())[0]  # ìœ ì¼í•œ ë§ˆíŠ¸ë¥¼ dfë¡œ í• ë‹¹
        elif len(full_marts) > 1:
            exec_globals["df"] = list(full_marts.values())[0]  # ì²« ë²ˆì§¸ ë§ˆíŠ¸ë¥¼ ê¸°ë³¸ dfë¡œ ì„¤ì •

        # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì„ exec_globalsì— ì¶”ê°€
        exec_globals.update(full_marts)

        print(f"ğŸ”„ ì „ì²´ ë°ì´í„° ì‹¤í–‰ í™˜ê²½ì— ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„ ëª©ë¡: {list(exec_globals.keys())}")

        # LLM ìƒì„± ì½”ë“œì—ì„œ ```python ë¸”ë¡ ì œê±°
        code_to_execute = self._extract_code_from_llm_response(
            state.get("regenerated_code") or state["generated_code"]
        )
        try:
            # ì „ì²´ ì½”ë“œ ì‹¤í–‰
            output, analytic_results = self._execute_code_with_capture(code_to_execute, exec_globals, is_sample=False)
            token_count = self._calculate_tokens(str(analytic_results))
            
            # âœ… í† í° ì œí•œ ì„¤ì • (ì˜ˆ: 5000 í† í° ì´ˆê³¼ ì‹œ ì°¨ë‹¨)
            TOKEN_LIMIT = 5000
            print(f"ğŸ”„ ê²°ê³¼ ë°ì´í„° í† í° ìˆ˜: {token_count}")
            
            if token_count > TOKEN_LIMIT:
                print(f"âš ï¸ í† í° ìˆ˜ ì´ˆê³¼: {token_count} > {TOKEN_LIMIT}")
                self.retry_count += 1
                return Command(update={
                    "error_message": f"ê²°ê³¼ ë°ì´í„° analytic_resultsì˜ ì ì • í† í° ìˆ˜ë¥¼ ì´ˆê³¼í•˜ì˜€ìŠµë‹ˆë‹¤. analytic_resultsì— Raw ë°ì´í„° í˜¹ì€ ë¶ˆí•„ìš”í•œ ë°˜ë³µ ì ì¬ë¥¼ í”¼í•´ì£¼ì„¸ìš”: {token_count} > {TOKEN_LIMIT}",
                    "from_full_execution": True,  # í”Œë˜ê·¸ ì¶”ê°€
                    "from_token_limit": True
                }, goto="Regenerate_Code")
            
            print(f"ğŸ”„ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì„±ê³µ")
            print(f'ğŸ”„ analytic_results\n {analytic_results}')
            # print(f'ğŸ”„ : output\n {output}')

            # ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
            if analytic_results is not None:
                unique_id = self.generate_unique_id()
                # ì „ì²´ ì‹¤í–‰ ì„±ê³µ ì‹œ validated_code ì„¤ì •
                current_code = state.get("regenerated_code") or state["generated_code"]
                return Command(update={
                    "analytic_result": analytic_results,
                    "execution_output": output,
                    "data_id": unique_id,
                    "validated_code": current_code  # ì„±ê³µí•œ ì½”ë“œë¥¼ validated_codeë¡œ ì €ì¥
                }, goto="Save_Data")
            # ë¶„ì„ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
            else:
                print("âš ï¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                self.retry_count += 1
                return Command(update={
                    "error_message": "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "execution_output": output,
                    "from_full_execution": True  # í”Œë˜ê·¸ ì¶”ê°€
                }, goto="Regenerate_Code")

        except Exception as e:
            print(f"âŒ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì‹¤íŒ¨\n {code_to_execute}")
            print(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            print(f"ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
            print(f"ì—ëŸ¬ ë°œìƒ ìœ„ì¹˜:")
            print(traceback.format_exc())
            error_details = {
                "error_type": type(e).__name__,
                "error_message": str(e),
                "traceback": traceback.format_exc()
            }
            self.retry_count += 1
            return Command(update={
                "error_message": error_details,
                "from_full_execution": True  # í”Œë˜ê·¸ ì¶”ê°€
            }, goto="Regenerate_Code")


    def save_data(self, state):
        """ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì €ì¥ (ID ë¶€ì—¬)"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ğŸ“‚ ì²˜ë¦¬ ë°ì´í„° ì €ì¥ ë‹¨ê³„")
        # data_idê°€ ì—†ëŠ” ê²½ìš° ìƒì„±
        data_id = state.get("data_id", self.generate_unique_id())
        analytic_result = state["analytic_result"]
        execution_output = state["execution_output"]
        # ë¶„ì„ ê²°ê³¼ì™€ ì‹¤í–‰ ì¶œë ¥ì„ í•¨ê»˜ ì €ì¥
        save_data = {
            'analytic_result': analytic_result,
            'execution_output': execution_output
        }

        # ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
        os.makedirs("../output", exist_ok=True)
        with open(f"../output/data_{data_id}.pkl", 'wb') as f:
            pickle.dump(save_data, f)

        print(f"ğŸ“‚ ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ê²½ë¡œ: ../output/data_{data_id}.pkl")
        return Command(update={"data_id": data_id}, goto="Insight_Builder")
    
    
    def generate_insights(self, state):
        """ì €ì¥ëœ ë°ì´í„°ì—ì„œ ìë™ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ë° ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ ê²°ì •"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ğŸ’¡ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ë‹¨ê³„")
        dict_result = state["analytic_result"]
        user_question = state["messages"][0].content

        # âœ… ì§‘ê³„ ë°ì´í„°ë©´ ì „ì²´ ë°ì´í„° ì „ë‹¬
        string_of_result = str(dict_result)

        ############################################################
        # 1. ì¸ì‚¬ì´íŠ¸ ìƒì„±
        ############################################################
        prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_INSIGHT_BUILDER),
            ("user", "user_question:\n{user_question}\n\n"),
            ("user", "analytic_result:\n{analytic_result}\n\n")
        ])

        chain = prompt | self.llm
        insight_response = chain.invoke({
            "user_question": user_question,
            "analytic_result": string_of_result
        })

        print(f"ğŸ’¡ ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸\n{insight_response.content}")
        
        ############################################################
        # 2. ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ ê²°ì •
        ############################################################
        prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_CHART_NEEDED),
            ("user", "user_question:\n{user_question}\n\n"),
            ("user", "analytic_result:\n{analytic_result}\n\n"),
            ("user", "insight:\n{insight}\n\n")
        ])
        
        # ì°¨íŠ¸ í™œìš© ì—¬ë¶€ 'yes' ë˜ëŠ” 'no' ë°˜í™˜
        chart_decision_messages = prompt | self.llm
        chart_needed = chart_decision_messages.invoke({
            "user_question": user_question,
            "analytic_result": string_of_result,
            "insight": insight_response.content
        }).content.strip().lower()
        print(f"ğŸ’¡ ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ (yes/no): {chart_needed}")
        
        # ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ì— ë”°ë¼ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
        next_step = "Chart_Builder" if chart_needed == "yes" else "Report_Builder"
        
        return Command(update={
            "insights": insight_response.content,
            "chart_needed": chart_needed == "yes"
        }, goto=next_step)  # Supervisor ëŒ€ì‹  ì ì ˆí•œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
        

    def generate_chart(self, state):
        """ì°¨íŠ¸ ìƒì„± ë¡œì§ (ìµœëŒ€ 3íšŒ ì¬ì‹œë„)"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ğŸ“Š ì°¨íŠ¸ ìƒì„± ë‹¨ê³„")

        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì°¨íŠ¸ ìƒì„± 3íšŒ ì‹¤íŒ¨. ì°¨íŠ¸ ì—†ì´ ë¦¬í¬íŠ¸ ìƒì„±ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            self.retry_count = 0  # ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={"chart_filename": None}, goto="Report_Builder")
        
        try:
            analytic_result = state.get("analytic_result", {})
            string_of_result = str(analytic_result)
            insights = state.get('insights', 'ì¸ì‚¬ì´íŠ¸ ì—†ìŒ')
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", PROMPT_CHART_GENERATOR),
                ("user", """
Here are the analytic_result and insights to visualize:

Analysis Results Summary:
{analytic_result}

Key Insights:
{insights}

Please create an appropriate visualization that supports these insights.
Do not hardcode any values - use the analytic_result dictionary directly.
                """)            
            ])

            chain = prompt | self.llm
            chart_code = chain.invoke({
                "analytic_result": string_of_result,
                "insights": insights
            }).content
            
            print(f"ğŸ’¡ ìƒì„±ëœ ì°¨íŠ¸ ì½”ë“œ\n{chart_code}")
            
            
            # âœ… ì°¨íŠ¸ ì½”ë“œ ë¸”ë¡ì´ ìˆëŠ” ê²½ìš° ì½”ë“œ ì¶”ì¶œ
            extracted_code = self._extract_code_from_llm_response(chart_code)
            
            # ğŸ”¹ ê¸°ì¡´ì— LLMì´ ìƒì„±í•œ ì½”ë“œì—ì„œ `plt.show()` ì œê±°
            extracted_code = extracted_code.replace("plt.show()", "").strip()

            # ğŸ”¹ ì°¨íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs("../img", exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            filename = f"../img/chart_{timestamp}.png"

            # ğŸ”¹ `plt.savefig()`ë¥¼ ë¨¼ì € ì‹¤í–‰í•œ í›„ `plt.show()` ì¶”ê°€
            extracted_code += f"\nplt.savefig('{filename}', dpi=300)\nplt.show()"

            # âœ… ë””ë²„ê¹…ìš© ì¶œë ¥ (ìƒì„±ëœ ì½”ë“œ í™•ì¸)
            # print(f"ğŸ“Š ìƒì„±ëœ ì°¨íŠ¸ ì½”ë“œ\n{extracted_code}")
            
            # ì‹¤í–‰ í™˜ê²½ ì„¤ì •
            exec_globals = {
                'plt': plt,
                'np': np,
                'analytic_result': analytic_result,
            }
            
            # ì½”ë“œ ì‹¤í–‰
            exec(extracted_code, exec_globals)
            plt.close()

            print(f"âœ… ì°¨íŠ¸ ìƒì„± ì„±ê³µ: {filename}")
            self.retry_count = 0  # ì„±ê³µ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={
                "chart_filename": filename,
                "chart_error": None
            }, goto="Report_Builder")

        except Exception as e:
            print(f"âŒ ì°¨íŠ¸ ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            plt.close()
            error_info = {
                "error_message": str(e),
                "previous_code": extracted_code,
                "traceback": traceback.format_exc()
            }
            # âŒ ì‹¤íŒ¨ ì‹œ Regenerate_Chartë¡œ
            self.retry_count += 1
            return Command(
                update={
                    "chart_filename": None,
                    "chart_error": error_info
                },
                goto="Regenerate_Chart"
            )

    def regenerate_chart(self, state):
        """ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì°¨íŠ¸ ì¬ìƒì„±"""
        print("="*100)
        print("ğŸ”„ ì°¨íŠ¸ ì¬ìƒì„± ë‹¨ê³„")
        
        dict_result = state["analytic_result"]
        string_of_result = str(dict_result)
        previous_error = state.get("chart_error", {})
        retry_cnt = state.get("retry_chart", 0)

        if retry_cnt >= MAX_RETRIES:
            print("âš ï¸ ì°¨íŠ¸ ì¬ìƒì„± 3íšŒ ì‹¤íŒ¨. ì°¨íŠ¸ ì—†ì´ ë¦¬í¬íŠ¸ ìƒì„±ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            self.retry_count = 0  # ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={
                "chart_filename": None,
                "chart_error": None
            }, goto="Report_Builder")

        prompt = ChatPromptTemplate.from_messages([
            ("system", "Python ì½”ë“œì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”."),  # ì°¨íŠ¸ ì¬ìƒì„± ì „ìš© í”„ë¡¬í”„íŠ¸
            ("user", """
    ì´ì „ ì°¨íŠ¸ ìƒì„± ì‹œë„ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:
    ì—ëŸ¬ ë©”ì‹œì§€: {error_message}

    ì´ì „ ì½”ë“œ:
    {previous_code}

    ì „ì²´ ì—ëŸ¬ ë‚´ìš©:
    {error_traceback}

    ë¶„ì„í•  ë°ì´í„°:
    {analytic_result}

    ì¸ì‚¬ì´íŠ¸:
    {insights}

    ìœ„ì˜ ì—ëŸ¬ë¥¼ í•´ê²°í•œ ìƒˆë¡œìš´ ì°¨íŠ¸ ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            """)
        ])

        chain = prompt | self.llm
        chart_code = chain.invoke({
            "error_message": previous_error.get("error_message", "ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬"),
            "previous_code": previous_error.get("previous_code", "ì´ì „ ì½”ë“œ ì—†ìŒ"),
            "error_traceback": previous_error.get("traceback", "íŠ¸ë ˆì´ìŠ¤ë°± ì—†ìŒ"),
            "analytic_result": string_of_result,
            "insights": state.get('insights', 'ì¸ì‚¬ì´íŠ¸ ì—†ìŒ')
        }).content

        extracted_code = self._extract_code_from_llm_response(chart_code)
        if not extracted_code:
            print("ğŸ“Š [regenerate_chart] ìœ íš¨í•œ Python ì½”ë“œ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ì¬ì‹œë„í•©ë‹ˆë‹¤.")
            error_info = {
                "error_message": "ìœ íš¨í•œ Python ì½”ë“œ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤",
                "previous_code": chart_code
            }
            self.retry_count += 1
            return Command(update={
                "retry_chart": retry_cnt + 1,
                "chart_error": error_info
            }, goto="Regenerate_Chart")

        extracted_code = extracted_code.replace("plt.show()", "").strip()
        
        os.makedirs("../img", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        filename = f"../img/chart_{timestamp}.png"
        
        extracted_code += f"\nplt.savefig('{filename}', dpi=300)\nplt.show()"
        
        print(f"ğŸ“Š ì‹¤í–‰í•  ì°¨íŠ¸ ì½”ë“œ:\n{extracted_code}")

        try:
            exec(extracted_code, globals())
            print(f"âœ… ì°¨íŠ¸ ì¬ìƒì„± ì„±ê³µ: {filename}")
            plt.close()
            self.retry_count = 0  # ì„±ê³µ ì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
            return Command(update={
                "chart_filename": filename,
                "chart_error": None
            }, goto="Report_Builder")

        except Exception as e:
            print(f"âŒ ì°¨íŠ¸ ì¬ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            plt.close()
            error_info = {"error_message": str(e),"previous_code": extracted_code,"traceback": traceback.format_exc()}
            self.retry_count += 1
            return Command(update={
                "chart_filename": None,
                "chart_error": error_info
            }, goto="Regenerate_Chart")


    def generate_report(self, state):
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print("ğŸ“‘ ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„")
        dict_result = state["analytic_result"]
        string_of_result = str(dict_result)
        insights = state.get('insights', 'ì¸ì‚¬ì´íŠ¸ ì—†ìŒ')
        user_request = self.original_query
        prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_REPORT_GENERATOR),
            ("user", "1. ë¶„ì„ ê²°ê³¼ ë°ì´í„°\n{analytic_result}\n\n"),
            ("user", "2. ì‚¬ìš©ì ìš”ì²­\n{user_request}\n\n"),
            ("user", "3. ë„ì¶œëœ ì¸ì‚¬ì´íŠ¸\n{insights}\n\n"),
        ])

        chain = prompt | self.llm
        response = chain.invoke({
            "user_request": user_request,
            "analytic_result": string_of_result,
            "insights": insights,
        })
        print("âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        print(f"{response.content}")
        return Command(update={"report": response.content, "error_message": None}, goto=END)
    
    
    def set_active_mart(self, data_mart: Union[pd.DataFrame, Dict[str, pd.DataFrame]], mart_name: Union[str, List[str], None] = None) -> None:
        """ë¶„ì„í•  ë°ì´í„°í”„ë ˆì„ê³¼ ë§ˆíŠ¸ ì •ë³´ë¥¼ ì„¤ì •"""
        if isinstance(data_mart, pd.DataFrame):
            # ë‹¨ì¼ ë°ì´í„°í”„ë ˆì„ ì„¤ì •
            mart_key = mart_name if mart_name else "default_mart"
            self.active_marts = {mart_key: data_mart}
        elif isinstance(data_mart, dict):
            # ë‹¤ì¤‘ ë°ì´í„°í”„ë ˆì„ ì„¤ì •
            self.active_marts = data_mart
        else:
            raise TypeError("ì…ë ¥ëœ ë°ì´í„°ê°€ pandas DataFrame ë˜ëŠ” DataFrame ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")

        # ë§ˆíŠ¸ ì •ë³´ ì„¤ì • (ì—‘ì…€ íŒŒì¼ì˜ sheetì—ì„œ ê°€ì ¸ì˜´)
        mart_info_list = []
        for mart_key in self.active_marts.keys():
            if mart_key in self.mart_info_df:
                mart_info_list.append(f"## {mart_key} ë§ˆíŠ¸ ì •ë³´\n{self.mart_info_df[mart_key].to_markdown()}")
        
        self.mart_info = "\n\n".join(mart_info_list) if mart_info_list else None

        # ë°ì´í„°í”„ë ˆì„ ê°œìˆ˜ ë° ì •ë³´ ì¶œë ¥
        print(f"ğŸ”¹ {len(self.active_marts)}ê°œì˜ ë°ì´í„°í”„ë ˆì„ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        for name, df in self.active_marts.items():
            print(f"ğŸ”¹ ë°ì´í„°ë§ˆíŠ¸ ì´ë¦„: {name}")
            print(f"ğŸ”¹ ë°ì´í„° í¬ê¸°: {df.shape[0]}í–‰ x {df.shape[1]}ì—´")
            if self.mart_info and name in self.mart_info_df:
                print(f"ğŸ”¹ ë§ˆíŠ¸ ì •ë³´ ë¡œë“œë¨")


    def route_after_generate_code(self, state: State):
        """ì½”ë“œ ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        print("â¡ï¸ [route_after_generate_code] ì½”ë“œ ìƒì„± í›„ ê²½ë¡œ ê²°ì •")

        if state.get("generated_code"):
            print("â¡ï¸ [route_after_generate_code] ìƒ˜í”Œ ì‹¤í–‰ ì§„í–‰")
            return "Execute_Sample"
        else:
            print("â¡ï¸ [route_after_generate_code] ë§ˆíŠ¸ í™œì„±í™” í•„ìš” -> [í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ]")
            return END


    def route_after_sample(self, state: State):
        """ìƒ˜í”Œ ì‹¤í–‰ í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        print("â¡ï¸ [route_after_sample] ìƒ˜í”Œ ì‹¤í–‰ í›„ ê²½ë¡œ ê²°ì •")
        
        if not self.active_marts or self.active_marts is None:
            print("â¡ï¸ [route_after_sample] í™œì„±í™”ëœ ë§ˆíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë§ˆíŠ¸ë¥¼ í™œì„±í™”í•´ì£¼ì„¸ìš”.")
            return END
        
        if not state.get("error_message"):  # ì—ëŸ¬ê°€ ì—†ìœ¼ë©´
            print("â¡ï¸ [route_after_sample] ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì§„í–‰")
            return "Execute_Full"
        else:
            if self.retry_count >= MAX_RETRIES:
                print("âš ï¸ ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ 3íšŒ ì‹¤íŒ¨ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
                self.retry_count = 0
                return END
            print(f"âš ï¸ ìƒ˜í”Œ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ â†’ ì½”ë“œ ì¬ìƒì„± í•„ìš” | ì¬ì‹œë„ íšŸìˆ˜: {self.retry_count}")
            return "Regenerate_Code"


    def route_after_insights(self, state: State) -> str:
        """ì¸ì‚¬ì´íŠ¸ ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        print("="*100)  # êµ¬ë¶„ì„  ì¶”ê°€
        print(f"â¡ï¸ [route_after_insights] ì¸ì‚¬ì´íŠ¸ ìƒì„± í›„ ê²½ë¡œ ê²°ì •(ì°¨íŠ¸ or ë³´ê³ ì„œ)")
        
        if state.get("chart_needed", False):
            print("â¡ï¸ [route_after_insights] ì°¨íŠ¸ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤")
            return "Chart_Builder"
        print("â¡ï¸ [route_after_insights] ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤")
        return "Report_Builder"
    
    def route_after_chart(self, state: State) -> str:
        """ì°¨íŠ¸ ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        print(f"â¡ï¸ [route_after_chart] ì°¨íŠ¸ ìƒì„± í›„ ê²½ë¡œ ê²°ì •(ì°¨íŠ¸ ì¬ìƒì„± or ë³´ê³ ì„œ)")

        if state.get("chart_filename"):
            print("â¡ï¸ [route_after_chart] ì°¨íŠ¸ ìƒì„± ì„±ê³µ â†’ ë¦¬í¬íŠ¸ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰")
            return "Report_Builder"
        
        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì°¨íŠ¸ ìƒì„± 3íšŒ ì‹¤íŒ¨ â†’ ì°¨íŠ¸ ì—†ì´ ë¦¬í¬íŠ¸ ìƒì„±ìœ¼ë¡œ ì§„í–‰")
            self.retry_count = 0  # ì¹´ìš´í„° ì´ˆê¸°í™”
            return "Report_Builder"
        
        print(f"â¡ï¸ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ â†’ ì¬ìƒì„± ì‹œë„ (Regenerate_Chart) ({self.retry_count + 1}/3)")
        return "Regenerate_Chart"


    def route_after_regenerate(self, state: State) -> str:
        """ì½”ë“œ ì¬ìƒì„± í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
        from_full_execution = state.get("from_full_execution", False)
        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì½”ë“œ ì¬ìƒì„± 3íšŒ ì‹¤íŒ¨ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
            return END
        
        if from_full_execution:
            print("â¡ï¸ [route_after_regenerate] ì „ì²´ ë°ì´í„° ì‹¤í–‰ìœ¼ë¡œ ì§„í–‰")
            return "Execute_Full"
        else:
            print("â¡ï¸ [route_after_regenerate] ìƒ˜í”Œ ì‹¤í–‰ìœ¼ë¡œ ì§„í–‰")
            return "Execute_Sample"
        

    def route_after_full_execution(self, state: State) -> str:
        """ì „ì²´ ë°ì´í„° ì‹¤í–‰ í›„ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°
        
        Returns:
            str: ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œì˜ ì´ë¦„
        """
        print("â¡ï¸ [route_after_full_execution] ì „ì²´ ë°ì´í„° ì‹¤í–‰ í›„ ê²½ë¡œ ê²°ì •")
        
        if state.get("validated_code"):  # validated_codeê°€ ìˆìœ¼ë©´ ì„±ê³µ
            print("â¡ï¸ [route_after_full_execution] ë°ì´í„° ì €ì¥ ë‹¨ê³„ë¡œ ì§„í–‰")
            return "Save_Data"
        
        if self.retry_count >= MAX_RETRIES:
            print("âš ï¸ ì „ì²´ ë°ì´í„° ì‹¤í–‰ 3íšŒ ì‹¤íŒ¨ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
            return END
        
        print(f"âš ï¸ ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì‹¤íŒ¨ â†’ ì½”ë“œ ì¬ìƒì„± í•„ìš” | ì¬ì‹œë„ íšŸìˆ˜: {self.retry_count}")
        return "Regenerate_Code"

    def generate_unique_id(self):
        """ê³ ìœ  ID ìƒì„±"""
        return datetime.now().strftime("%Y%m%d%H%M%S")
    
    
    # ìƒì„±í˜• AIê°€ ìƒì„±í•œ ì½”ë“œë¥¼ ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ì¶œë ¥ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    def _execute_code_with_capture(self, code, exec_globals, is_sample=False):
        
        # í‘œì¤€ ì¶œë ¥ì„ ê°€ë¡œì±„ê¸° ìœ„í•´ StringIO ì‚¬ìš©
        captured_output = io.StringIO()
        original_stdout = sys.stdout  # ì›ë˜ í‘œì¤€ ì¶œë ¥ ì €ì¥

        # âœ… ì‹¤í–‰ ì „, exec_globals ì´ˆê¸°í™” (ì´ì „ ê°’ ìœ ì§€ ë°©ì§€)
        safe_locals = {}

        try:
            sys.stdout = captured_output  # í‘œì¤€ ì¶œë ¥ ë³€ê²½
            exec(code, exec_globals, safe_locals)  # **ì œí•œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì‹¤í–‰**
            sys.stdout = original_stdout # í‘œì¤€ ì¶œë ¥ì„ ì›ë˜ëŒ€ë¡œ ë³µì›
            
            print(f"ğŸ”„ [_execute_code_with_capture] ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ ê°ì²´ : {safe_locals.keys()}")

            # ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
            results = None
            analytic_results = None
            
            # ì „ì²´ ë°ì´í„° ì‹¤í–‰ ì‹œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
            if not is_sample:
                if "result_df" in safe_locals:
                    results = safe_locals["result_df"]
                elif "analytic_results" in safe_locals:
                    results = safe_locals["analytic_results"]
                
                # ê²°ê³¼ íƒ€ì…ì— ë”°ë¥¸ í‘œì¤€í™” ì²˜ë¦¬
                if results is not None:
                    if isinstance(results, pd.DataFrame):
                        # DataFrameì„ dictionaryë¡œ ë³€í™˜
                        analytic_results = results.to_dict('records') if not results.empty else {}
                    elif isinstance(results, dict):
                        # DictionaryëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        analytic_results = results
                    elif isinstance(results, list):
                        # ListëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        analytic_results = results
                    else:
                        # ê¸°íƒ€ íƒ€ì…ì€ dictionaryë¡œ ë³€í™˜
                        analytic_results = {"result": str(results)}
            
            # ì¶œë ¥ ë° ë¶„ì„ ê²°ê³¼ ë°˜í™˜
            return captured_output.getvalue(), analytic_results
            
        except Exception as e:
            captured_output.write(f"Error: {str(e)}\n")  # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
            sys.stdout = original_stdout
            raise e


    def _calculate_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë©”ì†Œë“œ
        
        Args:
            text (str): í† í° ìˆ˜ë¥¼ ê³„ì‚°í•  í…ìŠ¤íŠ¸
            
        Returns:
            int: í† í° ìˆ˜
        """
        try:
            enc = tiktoken.get_encoding("cl100k_base")
            tokens = enc.encode(text)
            return len(tokens)
        except Exception as e:
            print(f"âš ï¸ í† í° ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return 0
        

    def _extract_code_from_llm_response(self, response: str) -> str:
        """LLM ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡ì„ ì¶”ì¶œí•˜ëŠ” ë©”ì†Œë“œ
        
        Args:
            response (str): LLMì´ ìƒì„±í•œ ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            str: ì¶”ì¶œëœ ì½”ë“œ (ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš° ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ì—¬ ë°˜í™˜)
        """
        try:
            if "```python" in response:
                return response.split("```python")[1].split("```")[0].strip()
            elif "```" in response:
                return response.split("```")[1].strip()
            return response.strip()
        except Exception as e:
            print(f"âš ï¸ ì½”ë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return response.strip()
