from datetime import datetime
import traceback
import streamlit as st
from typing import Dict, Any, Optional, Union
from langchain.memory import ConversationBufferMemory
from pymongo import MongoClient

# ì‚¬ìš©ì íŒ¨í‚¤ì§€
from utils.vector_handler import save_chat_to_vector_db, search_similar_questions

# âœ… MongoDB ì—°ê²° ì„¤ì •
client = MongoClient("mongodb://localhost:27017")
db = client["chat_history"]
collection = db["conversations"]

# âœ… ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (thread_idë³„ë¡œ ê´€ë¦¬)
memory_store = {}

def get_memory(thread_id: str) -> ConversationBufferMemory:
    """
    íŠ¹ì • thread_idì— ëŒ€í•œ ConversationBufferMemoryë¥¼ ë°˜í™˜.
    ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±.
    """
    if thread_id not in memory_store:
        memory_store[thread_id] = ConversationBufferMemory(memory_key=f"history_{thread_id}", return_messages=True)
    
        # âœ… MongoDBì—ì„œ ì´ì „ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
        existing_messages = collection.find_one({"thread_id": thread_id})
        if existing_messages:
            for msg in existing_messages.get("messages", []):
                if msg["role"] == "user":
                    memory_store[thread_id].chat_memory.add_user_message(msg["content"])
                elif msg["role"] == "assistant":
                    memory_store[thread_id].chat_memory.add_ai_message(msg["content"])

    return memory_store[thread_id]

# âœ… ì±„íŒ… ì‘ë‹µ ì²˜ë¦¬
def handle_chat_response(
    assistant: Any,
    query: str,
    thread_id: str
) -> tuple[Optional[Dict[str, Any]], ConversationBufferMemory]:
    """
    ì±„íŒ… ì‘ë‹µ ì²˜ë¦¬ (ê¸°ì¡´ ì§ˆë¬¸ê³¼ AI ì‘ë‹µì„ ê¸°ì–µ)
    
    Args:
        assistant: ì±—ë´‡ ì–´ì‹œìŠ¤í„´íŠ¸ ì¸ìŠ¤í„´ìŠ¤
        query: ì‚¬ìš©ì ì§ˆë¬¸
        thread_id: ìŠ¤ë ˆë“œ ID

    Returns:
        tuple[ì‘ë‹µ ë°ì´í„° ë”•ì…”ë„ˆë¦¬, ì—…ë°ì´íŠ¸ëœ ë©”ëª¨ë¦¬ ê°ì²´]
    """
    try:
        print(f"ğŸ” ì§ˆë¬¸ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # âœ… thread_idë³„ memory ê°€ì ¸ì˜¤ê¸°
        memory = get_memory(thread_id)

        # âœ… ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
        messages = memory.load_memory_variables({}).get(f"history_{thread_id}", "")

        # ë©”ì‹œì§€ ê°ì²´ë¥¼ ì½ê¸° ì‰¬ìš´ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        previous_context = ""
        if messages:
            for msg in messages:
                if msg.type == 'human':
                    previous_context += f"ì‚¬ìš©ì: {msg.content}\n"
                elif msg.type == 'ai':
                    previous_context += f"ì–´ì‹œìŠ¤í„´íŠ¸: {msg.content}\n"

        print(f"[DEBUG] [handle_chat_response] ì´ì „ ëŒ€í™” ê¸°ë¡:\n{previous_context}")

        # âœ… ë²¡í„°DBì—ì„œ ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
        retrieved_context = search_similar_questions(thread_id, query)

        # âœ… ì§ˆì˜ ìƒì„± (ì´ì „ ëŒ€í™”ì´ë ¥ ë° ë²¡í„°DB ê²€ìƒ‰ ê²°ê³¼ ë°˜ì˜)
        full_query = f"""
ì‚¬ìš©ìì˜ ì´ì „ ëŒ€í™” ê¸°ë¡:
{previous_context}

ë²¡í„°DB ê²€ìƒ‰ì„ í†µí•´ ì°¾ì€ ê´€ë ¨ ë¬¸ë§¥:
{retrieved_context}

ì‚¬ìš©ì ì§ˆë¬¸:
{query}
        """
        result = assistant.ask(full_query)
        print(f"ğŸ¤µ ê²°ê³¼:\n{result}")
        
        # âœ… UI ë Œë”ë§ì„ ìœ„í•´ ë‹µë³€ ê²°ê³¼(result)ë¥¼ messages ë¦¬ìŠ¤íŠ¸ì— ë°ì´í„° ì €ì¥
        response_data = {
            "role": "assistant",
            "content": "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",  # ê¸°ë³¸ ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
            "validated_code": result.get("validated_code"),
            "analytic_result": result.get("analytic_result"),
            "chart_filename": result.get("chart_filename"),
            "insights": result.get("insights"),
            "report": result.get("report"),
            "request_summary": result.get("request_summary"),
        }

        # âœ… ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µì¼ ê²½ìš° ì²˜ë¦¬
        if "analytic_result" not in result:
            if "error_message" in result:
                response_data = {
                    "role": "assistant",
                    "content": result["error_message"]
                }
                st.error(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {result['error_message']}")
            else:
                response_data = {
                    "role": "assistant",
                    "content": (
                        result.get("general_response") or 
                        result.get("knowledge_response") or 
                        result.get("response", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    ),
                    "request_summary": result.get("request_summary")
                }

        # âœ… ë©”ëª¨ë¦¬ì— ì§ˆë¬¸ ë° ì‘ë‹µ ì €ì¥ (ì—ëŸ¬ê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
        if "error_message" not in response_data:
            if isinstance(query, str):
                memory.chat_memory.add_user_message(query)
            if isinstance(response_data["content"], str):
                memory.chat_memory.add_ai_message(response_data["content"])

            # âœ… MongoDBì—ë„ ëŒ€í™” ì´ë ¥ ì €ì¥
            collection.update_one(
                {"thread_id": thread_id},
                {
                    "$push": {
                        "messages": {"role": "user", "content": query},
                        "messages": {"role": "assistant", "content": response_data["content"]}
                    }
                },
                upsert=True
            )

            # âœ… ì—ëŸ¬ê°€ ì—†ëŠ” ê²½ìš° ë²¡í„°DBì—ë„ ì €ì¥
            save_chat_to_vector_db(thread_id, query, response_data)

        return response_data, memory

    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ [handle_chat_response] : {traceback.format_exc()}")
        return None, None
